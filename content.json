{"meta":{"title":"Just Hack Fun","subtitle":"","description":"Focusing on Linux kernel and OS","author":"Lv Ying","url":"https://system-thoughts.github.io","root":"/"},"pages":[{"title":"","date":"2023-01-18T05:32:06.172Z","updated":"2023-01-18T05:32:06.172Z","comments":true,"path":"about/index.html","permalink":"https://system-thoughts.github.io/about/index.html","excerpt":"","text":""},{"title":"","date":"2022-08-26T01:25:11.000Z","updated":"2023-01-18T05:32:06.172Z","comments":true,"path":"changelog/index.html","permalink":"https://system-thoughts.github.io/changelog/index.html","excerpt":"","text":"Changelog 2022-11-11 🔗 申请了域名justhack.fun，更加个性了 2022-08-20 💬 看中了基于giscus的评论系统，在inside主题中折腾了很久无果。转向volantis主题 2020-10-15 🥳 搭建基于inside主题的hexo博客，并利用Travis-CI构建、发布博客，让我养成更新博客的习惯Travis-CI持续集成Hexo博客"},{"title":"Open Source contribution","date":"2020-12-29T20:32:19.000Z","updated":"2023-01-18T05:32:06.172Z","comments":true,"path":"contribution/index.html","permalink":"https://system-thoughts.github.io/contribution/index.html","excerpt":"","text":""},{"title":"Slides and Talks","date":"2022-08-02T02:29:41.000Z","updated":"2023-01-18T05:32:06.176Z","comments":true,"path":"slide_talk/index.html","permalink":"https://system-thoughts.github.io/slide_talk/index.html","excerpt":"","text":"Slides[1] Programmer’s Self-Cultivation - compilation overview Paper Share[1] [OSDI’2020] Predictive and Adaptive Failure Mitigation to Avert Production Cloud VM Interruptions"},{"title":"Translation Collection","date":"2020-12-29T20:29:41.000Z","updated":"2023-01-18T05:32:06.176Z","comments":true,"path":"traslation/index.html","permalink":"https://system-thoughts.github.io/traslation/index.html","excerpt":"","text":"What does Translation Collection include?本页面收集了当前博客的所有译文，我会翻译那些我感兴趣或者对我学习、工作有帮助的文章。并不会对某一系列的文章进行跟踪翻译，如LWN，其文章质量较高，但并非所有文章都在我工作领域之内。对不熟悉的文章进行翻译于我无益，甚至会误解读者。 博客中的所有译文会包含引文(Citation)、正文(text)、尾声(coda)。引文介绍了我翻译本篇文章的原因，正文是原文的翻译，尾声部分是我对这篇文章的些许感想。并非每篇译文都会包含尾声部分，毕竟我不想狗尾续貂🙃。正文部分基本上是原文的中译文，除非英文原文表述非常精彩，亦或我无法用准确的中文对其进行翻译，我才会在正文部分通过“引用”显示英文原文。上述三部分通过分割线(dividing line)进行区分。 ContentLinux tools 【译文】 Becoming friends with NetworkManager"}],"posts":[{"title":"APEI故障上报","slug":"APEI故障上报","date":"2023-01-17T01:56:55.000Z","updated":"2023-01-18T05:32:06.128Z","comments":true,"path":"posts/f776b7e3/","link":"","permalink":"https://system-thoughts.github.io/posts/f776b7e3/","excerpt":"","text":"APEI(ACPI Platform Error Interfaces)为硬件平台提供了一种将故障信息传递给OS的方法。APEI扩展了现有的硬件故障上报机制(e.g. Intel MCA, PCIe AER etc)，并将他们组合到一起以提供统一的硬件故障上报框架。由于固件离硬件更近，访问硬件设备更为方便，APEI中固件的作用也更为明显，提出了Firmware First机制。 硬件故障源(Hardware error source)APEI的核心概念是硬件故障源(Hardware error source)，硬件故障源是OS感知到硬件故障的先决条件，典型的硬件故障源包含以下几个方面： 一个或多个硬件故障状态寄存器(Hardware error status registers) 一个或多个硬件故障配置/控制寄存器(Hardware error configuration or control registers) 通知OS当前硬件发生硬件故障的通知机制 由此可见，硬件故障源指的是硬件中记录硬件故障信息、配置硬件故障部分以及通知OS当前硬件发生硬件故障的通知机制。了解Intel MCA(Machine Check Architecture)机制的朋友可以将上面三点对应上。如下图所示，左侧是全局的硬件故障配置/控制寄存器，右侧是记录硬件故障信息的寄存器，硬件故障通过MCE异常通知OS： 如果是CE故障，硬件故障源可以不包括硬件故障通知机制，可以由OS自主轮询(poll)故障状态寄存器以检查是否存在硬件故障。轮询机制不适用于UCE故障，UCE故障需要立即处理，硬件需要立刻通知OS。Intel MCA机制中，CE故障是通过CMCI中断通知OS，当发生CE风暴时，为了降低大量CMCI中断对系统性能的影响，OS将中断通知机制转换为轮询机制进行CE风暴抑制。 APEI采用固件优先(Firmware First mode, FFM)的故障上报机制，即硬件单元出现故障，先通知BIOS(Firmware)，BIOS进行预处理之后，然后将故障通知给OS。APEI中BIOS和OS合作进行故障处理，这种模式也给硬件平台供应商(Hardware platform vendor)很大的灵活性进行设计来确定是BIOS还是OS拥有关键的硬件错误资源。APEI允许BIOS将硬件错误源的控制权让渡给OS。一个典型的例子，Intel EMCA2即便采用FFM故障上报，OS进入MCE故障处理流程也是能够访问硬件故障状态寄存器、硬件故障控制寄存器；然而，ARM实现的FFM，OS无法拥有关键的硬件错误资源，所有的故障信息均来源于BIOS预处理之后的故障信息上报。 ACPI错误源(ACPI error source)ACPI错误源指的是BIOS通过一种标准化的机制向OS描述硬件故障源。APEI通过一套标准化的表格描述硬件故障源，这是一种平台和处理器架构无关的接口。表格中不仅包含确定的硬件故障信息，还包括关于错误源的可操作参数(operational parameters)，例如故障级别、masking bits、阈值，这些可操作参数可以视为BIOS和OS之间沟通过程中的可调节参数。ACPI规范定义了HEST表(Hardware Error Source Table)用于BIOS向OS描述硬件故障源。HEST表结构如下图所示： 我人为地将HEST表结构分为两部分： HEST header，包含ACPI表格头的常用信息，如表格头签名、表格长度，还包含OEM的些许信息，最重要的是“Error Source Count”，说明BIOS报告给OS的错误源个数 错误源结构，实际描述硬件故障错误源，上图中给出的是GHES错误源的结构 前面提到过ACPI错误源，相应的存在非ACPI错误源(Non-ACPI error source)。非ACPI错误源表示可以通过非ACPI标准化的表格描述硬件故障源，例如Intel MCA报告UCE故障的MCE异常使用上文提及的MSRs描述硬件故障以及配置/控制故障源，可以通过MCE异常直接通知OS。APEI定义了多种类型的错误源结构，可以将这些错误源结构可以总结为两类： 兼容非ACPI错误源，即便这些错误源能够直接通知OS，ACPI也支持标准化的表格描述该故障源，如x86架构通过MCE上报的UCE、x86架构通过MCE上报的Deferred error、x86架构通过correceted machine check上报的CE、x86架构通过NMI上报的UCE、PCIe root prot的AER故障、PCIe设备的AER故障、PCI Express/PCI-X Bridge的AER故障 GHES(Generic Hardware Error Source)，通用故障错误源，不受限于任何故障源类型，提供一种统一描述故障源的方法，若要实现架构无关的故障源描述，GHES是绝佳选择。平台支持多个通知类型的GHES故障源，例如使用SCI通知类型的GHES故障源处理异步错误；使用SEA/MCE通知类型处理同步错误。 兼容非ACPI错误源大概特征总结如下： Error source structure Flags Max entry in HEST IA-32 Architecture Machine Check Exception FIRMWARE_FIRST|GHES_ASSIST 1 IA-32 Architecture Deferred Machine Check FIRMWARE_FIRST|GHES_ASSIST 1 IA-32 Architecture Corrected Machine Check FIRMWARE_FIRST|GHES_ASSIST 1 IA-32 Architecture Non-Maskable Interrupt N/A 1 PCI Express Root Port AER Structure FIRMWARE_FIRST|GLOBAL &gt;= 1 (none GLOBAL flag set); 1 (GLOBAL flag set) PCI Express Device AER Structure FIRMWARE_FIRST|GLOBAL &gt;= 1 (none GLOBAL flag set); 1 (GLOBAL flag set) PCI Express/PCI-X Bridge AER Structure FIRMWARE_FIRST|GLOBAL &gt;= 1 (none GLOBAL flag set); 1 (GLOBAL flag set) “Max entry in HEST”表示HEST表格中允许该类型的错误源的最大数目。”Flags”是错误源结构体中的一个字段，只有IA-32 Architecture Non-Maskable Interrupt不存在该字段。直接引用APEI规范对Flags字段的bit进行解释： Bit [0] - FIRMWARE_FIRST: If set, this bit indicates to the OSPM that system firmware will handle errors from this source first.Bit [1] - GLOBAL: If set, indicates that the settings contained in this structure apply globally to all PCI Express DevicesBit [2] - GHES_ASSIST: If set, this bit indicates that although OSPM is responsible for directly handling the error (as expected when FIRMWARE_FIRST is not set), system firmware reports additional information in the context of an interrupt generated by the error. The additional information is reported in a Generic Hardware Error Source structure with a matching Related Source Id. 上述包含Flags字段的错误源结构体，都包含FIRMWARE_FIRST bit，该位如果设置，表示该类故障源采用Firmware First的故障处理模式。IA-32 MCA的CE/UCE/Deferred错误源还使用了GHES_ASSIST bit，如果该位设置了，即便是OS直接处理故障(FIRMWARE_FIRST不设置，非FFM)，也可以让BIOS生成中断，通过GHES报告故障信息，GHES结构体中的Related Source Id可以将二者关联起来。PCIe AER故障还会使用GLOBAL bit，该位与FIRMWARE_FIRST bit互斥。如果GLOBAL bit设置，表示此故障源的所有设置适用于系统中的所有PCIe设备，若设置FIRMWARE_FIRST bit，则可以为每个PCIe设备进行故障源配置。 GHES(Generic Hardware Error Source)GHES作为通用故障源，可以做到平台无关地描述故障源，因此被会被多个架构用来描述故障。我接触到的ARM服务器基本上都使用GHES(v2 or higher)故障源描述硬件故障。GHES结构体中最重要的字段是Error Status Address，其指定了一个寄存器的位置，该寄存器保存了该错误源的(Generic) Error Status Block的起始物理地址。Error Status Block Length指定了(Generic) Error Status Block的长度，两者构成了(Generic) Error Status Block的实际物理地址空间，该物理地址空间位于BIOS预留的地址区间（由于BIOS需要对该区间进行读/写操作），OS为了读取该错误源的故障信息，需要先将该预留地址空间映射到OS的系统地址空间。 (Generic) Error Status Block包含错误源的实际错误状态信息(error status information)，HEST、GHES故障源、error status block的关联关系如下图所示，在图中标明了相应的Linux kernel数据结构。 Generic Error Status Block(Generic) Error Status Block包含两级信息，顶级是Generic Error Status Block结构，随后的是Generic Error Data Entry结构，可以将顶级信息理解为(Generic) Error Status Block头部信息。Generic Error Data Entry实际保存硬件故障信息，(Generic) Error Status Block可能包含多个Generic Error Data Entry以保存与同一硬件故障相关的多个硬件组件信息。例如，使用GHES故障源描述发生在PCI Express/PCI-X bridge的次级设备上的硬件故障，则可以使用两个Generic Error Data Entry分别描述PCI Express Bridge的硬件故障信息和PCI-X设备上的硬件故障信息。Generic Error Data Entry在整个HEST、GHES层级结构的位置如下图所示： Generic Error Status Block结构中最重要的域是Error Severity，表示的是硬件故障事件整体的故障级别。Generic Error Status Block之后是连续的一个或多个Generic Error Data Entry。其中的Section Type字段可以区分出硬件故障的硬件类型[1]，Error Severity表示硬件故障事件中的该硬件组件的故障级别，该故障级别不能超过整体的故障级别，Generic error data是实际保存硬件故障的字段，根据不同的硬件类型(Section Type)，其采用UEFI规范中“Common Platform Error Record(CPER)”的相应硬件类型表格记录硬件故障信息。 GHESv2(Generic Hardware Error Source version 2)上报GHES故障源的固件可能会与OS并行运行（例如固件运行在单独/专有处理器上，或者固件运行在从处理器上(application processor)）。为了防止固件和OS并发访问error status block，或者OS尚未读取error status block便被固件覆写了故障信息。GHESv2作为GHES的扩展解决了上述问题，GHESv2新增了”Read Ack Register”，仅在OS读取完error status block中的信息之后，回写Read Ack Register之后，固件才能写error status block，具体流程如下图所示： GHESv2在GHES表格尾部新增了三个字段： Read Ack Register：保存Read Ack Register的GAS地址 Read Ack Preserve：写Read Ack Register时，其中原有的内容的bit必须保留的mask bits Read Ack Write：写Read Ack Register时，必须设置的bit的mask bits 因此OS回写Read Ack Register分为两步： 读取Read Ack Register的值为X OS写入(( X &amp; ReadAckPreserve) | ReadAckWrite)到Read Ack Register的值","categories":[{"name":"RAS","slug":"ras","permalink":"https://system-thoughts.github.io/categories/ras/"}],"tags":[{"name":"APEI","slug":"apei","permalink":"https://system-thoughts.github.io/tags/apei/"}]},{"title":"github page定制域名","slug":"github page定制域名","date":"2022-11-12T09:31:31.000Z","updated":"2023-01-18T05:32:06.156Z","comments":true,"path":"posts/9803af4d/","link":"","permalink":"https://system-thoughts.github.io/posts/9803af4d/","excerpt":"","text":"本文主要讲解为github page搭建的博客申请域名的过程，以及在这个过程中的一些经验之谈。本文主要涉及到以下几个方面： 域名注册商的选择方法 域名申请过程中是否需要实名认证、是否需要进行ICP备案 如何为github page博客配置DNS记录，以便通过新域名可以访问github page 域名申请所谓的域名申请（购买），并不意味着你能够永久地拥有域名，实际上只能够租用一定期限的域名。用户一般通过域名注册商(registrar)/域名分销商(reseller)申请域名。域名一般是付费申请，不同的域名注册商/分销商对同一域名的定价、续费不同。也存在免费的域名注册商Freenom提供.TK、.ML、.GA、.CF、.GQ顶级域名的注册。如果要选择心仪的TLD，还是选择付费域名进行注册。 选择域名注册商主要考虑三个维度： 价格 隐私保护 注册商服务 用户选购域名时，需要不仅考虑当前的注册价格还需要考虑后期续费价格。很多域名注册商会提供域名注册优惠，但往往只能注册1年，注册价格极低，但后期续费价格较高。我对比了国内腾讯云、阿里万网以及国外的几家域名注册商，最终了选择了国内的域名注册商，国外的域名注册商如Namesilo的续费价格较高。 隐私保护可能你经常听到注册域名要提交身份信息、对网站要进行备案，实际上真的如此吗？ 我国境内的域名注册服务商、域名注册管理机构遵守工信部2017年《中国互联网络域名管理办法》的域名实名认证的要求： 域名注册申请者应提交域名持有者真实、准确、完整的域名注册信息进行实名认证，若域名在规定时间内未通过实名审核，会被注册局暂停解析(Serverhold)。对于不符合规定的域名，将依法予以注销。 因此，选择国内域名注册服务商需要提交身份证信息进行实名认证。 根据国务院令第292号《互联网信息服务管理办法》和《非经营性互联网信息服务备案管理办法》规定，国家对经营性互联网信息服务实行许可制度，对非经营性互联网信息服务实行备案制度。未获取许可或者未履行备案手续的，不得从事互联网信息服务，否则属于违法行为[1]: 第二条 在中华人民共和国境内从事互联网信息服务活动，必须遵守本办法。 本办法所称互联网信息服务，是指通过互联网向上网用户提供信息的服务活动。 因此，使用中国大陆境内的服务器提供web服务必须进行ICP备案，像github page服务器在国外，则不需要进行ICP备案。如果用户的网站服务器在中国大陆，建议（非必须）选择国内的域名注册商，如阿里云、腾讯云，他们有辅助ICP备案的流程，方便用户进行备案。当然，用户也可以选择国外域名注册商，只是ICP备案会麻烦一点。 通常，无需担心实名认证的身份信息被泄露。根据 ICANN 《通用顶级域名注册数据临时政策细则（Temporary Specification for gTLD Registration Data）》和欧盟《通用数据保护条例》合规要求，域名注册商保证whois查询结果中域名管理人员的相关个人数据，包括姓名、邮箱、电话、街道地址等。 但国内某些注册商并不能完全做到这一点，我在腾讯云注册的.fun域名通过whois查询到的Registrant Organization字段包含注册人的英文名（默认为姓名拼音）。v2ex的网友对这个情况也有讨论，腾讯云对此答复： 通过腾讯云注册的域名，除 .com / .net 等 Verisign 域名的 WHOIS 信息由腾讯云直接按调整后的规则提供外，其他腾讯云域名的 WHOIS 信息均由相应的注册局提供，并由各注册商自行决定在其 WHOIS 平台的显示信息内容。由于各注册局、注册商对于 GDPR 和 WHOIS 显示信息调整的落实方案与进度暂不统一，因此相关域名在第三方 WHOIS 平台如何显示，取决于对应的注册局和注册商政策。通过腾讯云注册的 .com / .net 等 Verisign 域名，目前通过第三方 WHOIS 平台所能查询到的腾讯云域名注册联系人信息均为缓存信息，最新查询结果中，已不再包括腾讯云域名的注册联系人信息。[2] 建议在国内注册域名的朋友，填写英文名时特意做好规避。如果要检查你的注册信息是否能被whois查询到，建议通过以下两个网站进行查询： https://whois.chinaz.com/ https://whois.gandi.net/ 国内域名注册商的whois查询服务确实隐藏了个人信息。即便隐藏了英文名，仍然会泄露注册人所在的省份。 注册商服务选择域名注册商也需要考虑注册商服务，这里简单罗列下： 域名转入/转出限制：有的域名注册服务商对于域名转入/转出有较为严格的限制，影响用户体验，可以事先进行调研 支付方式：若选择国外域名服务商，则需要考虑支付的便捷性（是否支持支付宝/微信支付），国外几家比较大的域名注册商如namesilo、name.com、GoDaddy都支持支付宝 SSL证书申请：如果网站需要支持https，域名服务商能免费支持SSL证书申请则会相对便捷，github page本身会提供https服务，可忽略这点 当然，根据自身的实际需求，对注册商的服务要求也大不相同，欢迎在评论区交流。 github page关联域名github page支持设置的自定义域类型： 自定义域类型 范例 www子域(subdomain) www.justhack.fun 自定义子域 blog.justhack.fun 顶点域(apex domain) justhack.com Github建议同时配置顶点域和www子域： When using an apex domain, we recommend configuring your GitHub Pages site to host content at both the apex domain and that domain’s www subdomain variant. apex domain vs www subdomainwww子域能让人一眼看出域名是一个浏览器可以打开的URL。直接采用顶点域的方式可以让域名更加简洁，如github、twitter都采用顶点域。Github也支持github page仅设置顶点域/www子域/自定义子域。 使用顶点域存在”cookie污染”的问题：即顶点域的cookie作用范围包括其所有子域。即访问justhack.fun产生的cookie，在访问foo.justhack.fun或者bar.justhack.fun都会带上。对访问的安全、性能都有影响。 HTTP Cookie（也叫 Web Cookie 或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据。浏览器会存储 cookie 并在下次向同一服务器再发起请求时携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器——如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。[3] cookie主要用在三个方面[3]： 会话状态管理: 如用户登录状态、购物车、游戏分数或其它需要记录的信息 个性化设置: 如用户自定义设置、主题和其他设置 浏览器行为跟踪: 如跟踪分析用户行为等 服务器收到 HTTP 请求后，服务器可以在响应标头里面添加一个或多个 Set-Cookie选项。浏览器收到响应后通常会保存下Cookie，并将其放在 HTTP Cookie 标头内，向同一服务器发出请求时一起发送。http响应头中的Set-Cookie格式如下： 1Set-Cookie: &lt;cookie-name&gt;=&lt;cookie-value&gt; 下图是用户通过浏览器请求www.example.com传输cookie示例： 浏览器作为用户代理发送https请求访问www.example.com 服务器告知客户端存储一对cookie：foo_cookie、bar_cookie。 接着访问www.example.com域名下的sample_page.html页面会带上两个cookie。 可以通过两种方式确定访问域名是否带有cookie： 在浏览器(以chrome)为例，按F12进入开发者工具 -&gt; 点击Application/Cookies即可查看相应域名的Cookie，可见justhack.fun并不包含任何cookie 执行curl -I https://justhack.fun命令，该命令仅返回http(s)头部信息，但不返回页面内容，检查头部信息中的set-cookie字段，同样发现访问justhack.fun并不包含任何cookie：123456789101112131415161718192021222324❯ curl -I https://justhack.funHTTP/1.1 200 Connection establishedHTTP/2 200 server: GitHub.comcontent-type: text/html; charset=utf-8last-modified: Sat, 12 Nov 2022 16:57:25 GMTaccess-control-allow-origin: *etag: &quot;636fd075-207c0&quot;expires: Mon, 14 Nov 2022 05:24:54 GMTcache-control: max-age=600x-proxy-cache: MISSx-github-request-id: BA4C:4119:22EE90:2983D9:6371CECEaccept-ranges: bytesdate: Mon, 14 Nov 2022 05:14:55 GMTvia: 1.1 varnishage: 0x-served-by: cache-hkg17935-HKGx-cache: MISSx-cache-hits: 0x-timer: S1668402895.753872,VS0,VE260vary: Accept-Encodingx-fastly-request-id: a144f45239faaabca10c759cae386e23e310938bcontent-length: 133056 因为github page是静态页面，不带任何cookie，所以github page建议同时设置apex domain和www subdomain的方式既能便于访问，同时也不存在cookie泄露的风险。 配置apex domain和www subdomain如果github page配置了www.justhack.fun作为域名，且配置了正确的www子域和apex域的DNS记录，则访问justhack.fun时会重定向到www.justhack.fun。自动重定向仅适用于www子域，其他子域不适用。下面介绍如何为github page同时配置www subdomain和apex domain： 在github page代码仓中配置域名，以我本人的github page为例：打开github page代码仓 -&gt; 点击settings -&gt; 点击“Code and automation/Pages”，在”Custom domain”处输入域名，此处输入www subdomain：www.justhack.fun,也可以输入apex domain:justhack.fun。这个动作会在github page的发布分支生成一个”Update CNAME”的提交，由于我的github page发布分支是gh-pages分支，则会在该分支生提交。我是通过travis-ci自动部署博客内容，每当更新master分支，travis-ci会覆盖更新gh-pages分支，该分支只有一次提交。需要在master分支的source目录下手动添加CNAME文件，文件中仅包含www.justhack.fun。如果没有此步操作，后续更新master分支，访问域名会404。 对apex domain和www subdomain添加domain record: apex domain：添加A记录或者AAAA记录，apex domain不建议添加CNAME记录，虽然部分DNS provider并未对此做了严格限制，但该行为极度不推荐。1234567891011A record:185.199.108.153185.199.109.153185.199.110.153185.199.111.153AAAA record:2606:50c0:8000::1532606:50c0:8001::1532606:50c0:8002::1532606:50c0:8003::153 www subdomain: 添加CNAME记录，指向github page的github.io域名。 出于安全考虑，需要先执行完步骤1再执行步骤2。先配置DNS记录，再配置github page的域名会导致其他github用户的github page使用你的一个子域名[4] Make sure you add your custom domain to your GitHub Pages site before configuring your custom domain with your DNS provider. Configuring your custom domain with your DNS provider without adding your custom domain to GitHub could result in someone else being able to host a site on one of your subdomains. 添加DNS记录成功之后，步骤1中”Custom domain”下方的“DNS check”会成功，点击下面的”Enforce HTTPS”让github page支持https。 域验证(verify a custom domain)，进行域验证能够阻止其他github用户接管您的自定义域，用其发布自己的github page。删除你的github page代码仓、github付费服务被取消等场景会出现这种情况。验证域会包含其任何直接子域。 例如，如果已验证 github.com 自定义域，docs.github.com、support.github.com 和任何其他直接子域也将受到保护，以防止被接管[5]。具体步骤如下： 点击github个人资料照片 -&gt; 选择settings 点击”Code, planning, and automation/Pages” -&gt; 添加”Add domain”填写apex domain 会生成一条DNS TXT记录，按照提示，在DNS provider中添加该DNS TXT记录 可以退出之后，再进入该页面，查看域名是否已经验证 经过上述步骤后，已经完成了github page自定义域名。当前可以通过www subdomain和apex domain访问github page。步骤1配置github page域名是www subdomain，这里表示通过www subdomain访问github page能够直接获取到页面内容；通过apex domain访问github page会进行301重定向。 12345678❯ curl https://justhack.fun&lt;html&gt;&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 使用301跳转能够帮助SEO优化，因为www subdomain和apex domain实际上访问的是同一网站资源，如果不进行apex domain到www subdomain的301跳转，搜索引擎会认为这是两个不同的域名，导致域名的权重分散，不利于SEO排名。可以将github page的域名配置为apex domain，则是www subdomain 301跳转至apex domain。我个人更加倾向将github page域名配置为www subdomain，因为其会产生一条CNAME记录，这和配置www subdomain的DNS记录一致。","categories":[{"name":"blog","slug":"blog","permalink":"https://system-thoughts.github.io/categories/blog/"}],"tags":[{"name":"domain","slug":"domain","permalink":"https://system-thoughts.github.io/tags/domain/"},{"name":"github page","slug":"github-page","permalink":"https://system-thoughts.github.io/tags/github-page/"}]},{"title":"程序员的自我修养 -- ELF剖析","slug":"程序员的自我修养 -- ELF剖析","date":"2022-07-14T11:24:32.000Z","updated":"2023-01-18T05:32:06.168Z","comments":true,"path":"posts/7de7c201/","link":"","permalink":"https://system-thoughts.github.io/posts/7de7c201/","excerpt":"编译生成的中间目标文件、可执行文件都是按照特定的目标文件格式进行组织。各个系统的目标文件格式不太一样，如Unix a.out格式、Windows可移植可执行程序(Portable Executable, PE)、MacOS-X使用Mach-O格式。现代Linux/Unix都是用可执行可链接格式(Eexcutable Linkable Format, ELF)。PE和ELF格式都是COFF(Common File Format)格式的变种。","text":"编译生成的中间目标文件、可执行文件都是按照特定的目标文件格式进行组织。各个系统的目标文件格式不太一样，如Unix a.out格式、Windows可移植可执行程序(Portable Executable, PE)、MacOS-X使用Mach-O格式。现代Linux/Unix都是用可执行可链接格式(Eexcutable Linkable Format, ELF)。PE和ELF格式都是COFF(Common File Format)格式的变种。 Linux上不仅中间目标文件、可执行文件采用ELF格式。采用ELF格式的文件类型可分为下表中的四类： ELF文件类型 说明 举例 可重定位文件(Relocatable File) 编译产生的中间目标文件，可以被用来链接成可执行文件或者共享目标文件，静态链接库也属于这一类 Linux的.o文件Windows中的.obj文件 可执行文件(Executable File) 静态/动态链接的可执行程序 Linux中的可执行程序无后缀Windows中的.exe 共享目标文件(Shared Object File) 链接器可以使用这类文件和其他可重定位文件和共享目标文件链接生成新的共享目标文件；与可执行文件进行动态链接，作为进程映像的一部分 Linux的.soWindows的DLL 核心转储文件(Core Dump File) 程序意外终止时，系统保留进程地址空间的内容以及终止时的一些其他信息到核心转储文件 Linux下的core dump 通过file命令查看相应的文件格式，上面的几种文件在file命令中会显示出相应类型： 12345678# file hello.ohello.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped# file hellohello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=5c4bc53a7f316d2e95cbb40b395ff72b2f1e87fb, not stripped# file /lib64/ld-2.28.so /lib64/ld-2.28.so: ELF 64-bit LSB shared object, x86-64, version 1 (GNU/Linux), dynamically linked, BuildID[sha1]=523b1c63a3f4b12da75660bf483d63560694d81f, not stripped# file core-test_c-11-0-0-98197-1658125608 core-test_c-11-0-0-98197-1658125608: ELF 64-bit LSB core file, x86-64, version 1 (SYSV), SVR4-style, from &#x27;./test_c&#x27;, real uid: 0, effective uid: 0, real gid: 0, effective gid: 0, execfn: &#x27;./test_c&#x27;, platform: &#x27;x86_64&#x27; ELF文件格式有两种不同的视角：参与链接的Linking view；加载、运行ELF文件的Execution view。 ELF文件头部是ELF header，作为road map描述ELF文件组织。链接视角下，ELF文件中的信息按照section来组织；执行视角下，ELF文件中的信息按照segment来组织。一般来说，将section翻译成“节”，将segment翻译成“段”，但是在处理ELF文件过程中，往往将二者都翻译成“段”，可以根据实际的视角上下文，便能区分出“段”指的是section还是segment。不论section还是segment，都是ELF将相同属性的数据组织到一起的方式。 我们以simpleElf.c编译出的可重定位文件simpleElf.o开启ELF结构剖析之旅。 1234567891011121314151617181920212223# cat simpleElf.c int printf(const char *format, ...);int global_init_var = 8;int global_uninit_var;void func(int i)&#123; printf(&quot;hello %d\\n&quot;, i);&#125;int main(void)&#123; static int static_init_var = 4; static int static_uninit_var; int a = 1; int b; func(static_init_var + static_uninit_var + a + b); return 0;&#125;# gcc -c simpleElf.c -o simpleElf.o ELF headerELF header结构体及相关参数定义在/usr/include/elf.h，由于ELF文件在32bit和64bit下都通用，因此存在32bit版本和64bit版本，两个版本的内容一致，只是某些成员大小不一样。elf.h使用typedef定义了一套自己的变量体系，如表所示： 自定义类型 描述 原始类型 长度(字节) Elf32_Half 32bit版本的无符号短整形 uint16_t 2 Elf32_Word 32bit版本无符号整形 uint32_t 4 Elf32_Sword 32bit版本有符号整形 int32_t 4 Elf32_Xword 32bit版本64bit无符号整形 uint64_t 8 Elf32_Sxword 32bit版本64bit有符号整形 int64_t 8 Elf32_Addr 32bit版本地址 uint32_t 4 Elf32_Off 32bit版本偏移 uint32_t 4 Elf64_Half 64bit版本的无符号短整形 uint16_t 2 Elf64_Word 64bit版本无符号整形 uint32_t 4 Elf64_Sword 64bit版本有符号整形 int32_t 4 Elf64_Xword 64bit版本64bit无符号整形 uint64_t 8 Elf64_Sxword 64bit版本64bit有符号整形 int64_t 8 Elf64_Addr 64bit版本地址 uint64_t 8 Elf64_Off 64bit版本偏移 uint64_t 8 本文以64bit版本的相关数据结构进行介绍，相应ELF header的数据结构是Elf64_Ehdr： 12345678910111213141516171819#define EI_NIDENT (16)typedef struct&#123; unsigned char e_ident[EI_NIDENT]; /* Magic number and other info */ Elf64_Half e_type; /* Object file type */ Elf64_Half e_machine; /* Architecture */ Elf64_Word e_version; /* Object file version */ Elf64_Addr e_entry; /* Entry point virtual address */ Elf64_Off e_phoff; /* Program header table file offset */ Elf64_Off e_shoff; /* Section header table file offset */ Elf64_Word e_flags; /* Processor-specific flags */ Elf64_Half e_ehsize; /* ELF header size in bytes */ Elf64_Half e_phentsize; /* Program header table entry size */ Elf64_Half e_phnum; /* Program header table entry count */ Elf64_Half e_shentsize; /* Section header table entry size */ Elf64_Half e_shnum; /* Section header table entry count */ Elf64_Half e_shstrndx; /* Section header string table index */&#125; Elf64_Ehdr; 使用readelf -h读取ELF文件的ELF header信息： 123456789101112131415161718192021# readelf -h simpleElf.oELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2&#x27;s complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: REL (Relocatable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x0 Start of program headers: 0 (bytes into file) Start of section headers: 1072 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 0 (bytes) Number of program headers: 0 Size of section headers: 64 (bytes) Number of section headers: 13 Section header string table index: 12 ELF格式可以支持32bit/64bit处理器，也支持不同字节序(大端/小端)处理器。ELF header开头的ELF Identification(e_ident)字段指定了底层硬件信息：最开始的4字节是ELF文件的标识码，也叫做magic number，分别是0x7f、0x45、0x4c、0x46，第一个字节对应的是ASCII字符集中的DEL控制符，其余三个字节刚好是ELF这三个字母的ASCII编码。 字节e_ident[EI_CLASS]表示file class，区分ELF文件是64bit还是32bit。1表示32bit，2表示64bit。字节e_ident[EI_DATA]表示数据编码方式，1表示补码的小端表示，2表示补码的大端表示。字节e_ident[EI_VERSION]表示ELF文件主版本，当前为1，即EV_CURRENT，若ELF规范继续演进，不排除EV_CURRENT会取更大的值，该字节和后面的e_version字段一致。字节e_ident[EI_VERSION]、e_ident[EI_VERSION]表示OS/ABI ELF扩展，0表示未定义，看来默认遵循Unix System V ABI标准。 接下来的e_type字段区分ELF文件类型： e_machine字段指定了ELF文件的平台架构属性，该字段的详细取值范围参考[1]，EM_X86_64表示x86_64平台、EM_AARCH64表示ARM64平台。e_entry字段指定的是系统加载ELF文件后，系统跳转执行的第一条命令，可以理解为程序的入口。可重定位文件不会被加载执行，所以此处为0。e_flags字段指定ELF文件处理器相关的flag，当前没有flag被定义，此处为0。e_ehsize字段保存ELF header的大小，可见simpleElf.o的ELF header大小为64 byte。e_shstrndx字段表示section header string table在section header table中的索引，section header string table是段名表： 12345678910111213# readelf -p .shstrtab simpleElf.oString dump of section &#x27;.shstrtab&#x27;: [ 1] .symtab [ 9] .strtab [ 11] .shstrtab [ 1b] .rela.text [ 26] .data [ 2c] .bss [ 31] .rodata [ 39] .comment [ 42] .note.GNU-stack [ 52] .rela.eh_frame 第一列表示段名在section header string table数组中的索引，第二列表示相应的段名。section header string table数组中的字符串以’\\0’分隔，第0位也是’\\0’： offset 0 1 2 3 4 5 6 7 8 9 +0 \\0 . s y m t a b \\0 . +10 s t r t a b \\0 . s h readelf -p .shstrtab simpleElf.o显示的.shstrtab段的内容中包含10个段的名字，少了两个段.text和.eh_frame，是不是工具的问题呢？并不是，这两个段的名称复用了”.rela.text”、”.rela.eh_frame”字符串，.text和.eh_frame的section header的sh_name字段指向的是上述段名中间的”.”的偏移🙃 section header tableELF header中有三个字段与section header table相关： e_shoff：section header table在文件中的偏移(单位：byte)，如果不存在section header table，则为0 e_shentsize：section header table表项大小(单位：byte) e_shnum：section header table表项数目，如果不存在section header table，此项为0 显而易见，section header table是数组类型，数组项(entry)描述相应的section，section header table entry类型的数据结构Elf64_Shdr，也称作段描述符： 12345678910111213typedef struct&#123; Elf64_Word sh_name; /* Section name (string tbl index) */ Elf64_Word sh_type; /* Section type */ Elf64_Xword sh_flags; /* Section flags */ Elf64_Addr sh_addr; /* Section virtual addr at execution */ Elf64_Off sh_offset; /* Section file offset */ Elf64_Xword sh_size; /* Section size in bytes */ Elf64_Word sh_link; /* Link to another section */ Elf64_Word sh_info; /* Additional section information */ Elf64_Xword sh_addralign; /* Section alignment */ Elf64_Xword sh_entsize; /* Entry size if section holds table */&#125; Elf64_Shdr; 使用readelf查看section header table: 12345678910111213141516171819202122232425262728293031323334353637# readelf -S simpleElf.oThere are 13 section headers, starting at offset 0x430:Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 0000000000000000 00000040 0000000000000057 0000000000000000 AX 0 0 1 [ 2] .rela.text RELA 0000000000000000 00000320 0000000000000078 0000000000000018 I 10 1 8 [ 3] .data PROGBITS 0000000000000000 00000098 0000000000000008 0000000000000000 WA 0 0 4 [ 4] .bss NOBITS 0000000000000000 000000a0 0000000000000004 0000000000000000 WA 0 0 4 [ 5] .rodata PROGBITS 0000000000000000 000000a0 000000000000000a 0000000000000000 A 0 0 1 [ 6] .comment PROGBITS 0000000000000000 000000aa 000000000000002d 0000000000000001 MS 0 0 1 [ 7] .note.GNU-stack PROGBITS 0000000000000000 000000d7 0000000000000000 0000000000000000 0 0 1 [ 8] .eh_frame PROGBITS 0000000000000000 000000d8 0000000000000058 0000000000000000 A 0 0 8 [ 9] .rela.eh_frame RELA 0000000000000000 00000398 0000000000000030 0000000000000018 I 10 8 8 [10] .symtab SYMTAB 0000000000000000 00000130 0000000000000180 0000000000000018 11 11 8 [11] .strtab STRTAB 0000000000000000 000002b0 000000000000006c 0000000000000000 0 0 1 [12] .shstrtab STRTAB 0000000000000000 000003c8 0000000000000061 0000000000000000 0 0 1Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), l (large), p (processor specific) section header table的第一项是无效的段描述符，默认值为0。第一项的sh_size字段在一种情况下也是有意义的：ELF文件段数目大于等于SHN_LORESERVE(0xff00)时，ELF header中的e_shnum字段存储SHN_UNDEF(0)，实际的段数目保存在无效段的sh_size字段中。由于e_shnum字段是Elf64_Half类型，sh_size字段的类型为Elf64_Xword类型，能够保存的数据范围大的多。这种实际索引超过当前字段类型的表示范围时，ELF规范会在当前字段存放保留值(reserved value)，并不表示实际大小。如符号表项的st_shndx成员，ELF header中的e_shstrndx：当.shstrtab字符串表中的索引大于等于SHN_LORESERVE(0xff00)，e_shstrndx保存SHN_XINDEX(0xffff)，实际的索引保存在无效段的sh_link字段中。 section header table entry各个字段含义如下表所示: Name Description sh_name 段名，存储在.shstrtab字符串表中的偏移 sh_type 段类型，见Section type章节 sh_flags 段的标志位，见Section flag章节 sh_addr 若该段被加载，字段表示段在进程虚拟地址空间的起始地址，否则为0。由于可充定位目标文件不会被加载，所有段的该字段都为0 sh_offset 该段在ELF文件中的偏移，SHT_NOBITS段不占文件空间，该字段是个概念值，无意义 sh_size 段的文件长度，即便SHT_NOBITS段不占文件空间，也会有个非0值 sh_link 保存section header table entry索引，取决于段类型，见sh_link and sh_info章节 sh_info 和sh_link一起使用，取决于段类型，见sh_link and sh_info章节 sh_addralign 段地址对齐(2^sh_addralign)，取值0或1，例如该段无对齐要求。假设该段最开始是doule变量，则该段必须按照8字节对齐 sh_entsize 有些段是由固定大小的项组成，比如符号表。sh_entsize表示每项大小，0表示该段并不包含固定大小的项 Section type下表列举了simpleElf.o的段类型，更为详细的描述参考[2]： Name Value Description SHT_NULL 0 无效段 SHT_PROGBITS 1 段保存的信息由程序定义，如代码段、数据段 SHT_SYMTAB|SHT_DYNSYM 2 符号表 SHT_STRTAB 3 字符串表 SHT_RELA 4 重定位表，该段包含重定位信息 SHT_NOBITS 8 段在ELF文件中不占存储空间，其他方面类似于SHT_PROGBITS段，如.bss段 SHT_SYMTAB和SHT_DYNSYM同作为符号表类型，区别如下: These sections hold a symbol table. Currently, an object file may have only one section of each type, but this restriction may be relaxed in the future. Typically, SHT_SYMTAB provides symbols for link editing, though it may also be used for dynamic linking. As a complete symbol table, it may contain many symbols unnecessary for dynamic linking. Consequently, an object file may also contain a SHT_DYNSYM section, which holds a minimal set of dynamic linking symbols, to save space. 简要总结下： SHT_SYMTAB包含的符号比较全，包含静态链接(link editing)和动态链接(dynamic linking) SHT_DYNSYM包含的符号用于动态链接(dynamic linking)，符号表较小 Section flag下表列举了simpleElf.o的段的标志位，readelf -S输出的最后一行是各flag的简称。更为详细的描述参考[2]： Name Value Description SHF_WRITE 0x1 该段在进程地址空间中可写 SHF_ALLOC 0x2 该段会在进程地址空间中分配空间，有些包含指示或者控制信息的段无需在进程地址空间中分配空间。代码段、数据段、.bss段会包含这个flag SHF_EXECINSTR 0x4 该段在进程地址空间中可执行 SHF_MERGE 0x10 仅有可重定位目标文件SHT_PROGBITS类型的section可以使用该flag，用于静态链接时合并相同数据[3] SHF_STRINGS 0x20 该段包含以空字符结尾的字符串，空字符只能作为字符串结束符，而不能出现在任何字符串的中间位置 SHF_INFO_LINK 0x40 该段对应的section header table entry的sh_info字段保存了section header table index The data in the section may be merged to eliminate duplication. Unless the SHF_STRINGS flag is also set, the data elements in the section are of a uniform size. The size of each element is specified in the section header’s sh_entsize field. If the SHF_STRINGS flag is also set, the data elements consist of null-terminated character strings. The size of each character is specified in the section header’s sh_entsize field. Each element in the section is compared against other elements in sections with the same name, type and flags. GNU ld当前仅支持SHF_MERGE|SHF_STRINGS都设置的段的合并。 sh_link and sh_infosh_link与sh_info存储的内容取决于section类型： 由上表可见，sh_link和sh_info存储的都是section header index，只是根据section类型，存储的是不同的section的索引。对于，不在上表的section type，其sh_link和sh_info字段为SHN_UNDEF(0)。 符号链接过程中，目标文件之间相互拼合实际上是目标文件之间对地址的引用，即对函数和变量的引用。每个函数或者变量都有自己独特的名字，才能避免链接过程中不同变量和函数之间的混淆。在链接过程中，我们将变量和函数统称为符号(Symbol)，函数名或者变量名就是符号名(Symbol Name)。 链接过程很关键的一部分是符号的管理，每一个目标文件都会有一个相应的符号表(symbol table)，这个表中记录了目标文件用到的所有符号。每个定义的符号有一个对应的值，叫做符号值(symbol value)，对于变量和函数来说，符号值就是它们的地址。使用readelf -s查看ELF文件的符号表： 1234567891011121314151617181920# readelf -s simpleElf.oSymbol table &#x27;.symtab&#x27; contains 16 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FILE LOCAL DEFAULT ABS simpleElf.c 2: 0000000000000000 0 SECTION LOCAL DEFAULT 1 3: 0000000000000000 0 SECTION LOCAL DEFAULT 3 4: 0000000000000000 0 SECTION LOCAL DEFAULT 4 5: 0000000000000000 0 SECTION LOCAL DEFAULT 5 6: 0000000000000004 4 OBJECT LOCAL DEFAULT 3 static_init_var.1965 7: 0000000000000000 4 OBJECT LOCAL DEFAULT 4 static_uninit_var.1966 8: 0000000000000000 0 SECTION LOCAL DEFAULT 7 9: 0000000000000000 0 SECTION LOCAL DEFAULT 8 10: 0000000000000000 0 SECTION LOCAL DEFAULT 6 11: 0000000000000000 4 OBJECT GLOBAL DEFAULT 3 global_init_var 12: 0000000000000004 4 OBJECT GLOBAL DEFAULT COM global_uninit_var 13: 0000000000000000 34 FUNC GLOBAL DEFAULT 1 func 14: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND printf 15: 0000000000000022 53 FUNC GLOBAL DEFAULT 1 main 符号表项的数据结构Elf64_Sym： 123456789typedef struct&#123; Elf64_Word st_name; /* Symbol name (string tbl index) */ unsigned char st_info; /* Symbol type and binding */ unsigned char st_other; /* Symbol visibility */ Elf64_Section st_shndx; /* Section index */ Elf64_Addr st_value; /* Symbol value */ Elf64_Xword st_size; /* Symbol size */&#125; Elf64_Sym; 符号表项的各个字段含义如下： Name Description st_name 符号名在字符串表.strtab中的索引 st_info 符号类型与绑定属性 st_other 符号的可视性(visibility)，C语言编译的重定位文件/动态库/可执行文件，该项都是STV_DEFAULT st_shndx 符号所在段在section header table的索引，参考符号所在段 st_value 符号对应的值与符号有关，参考符号值 st_size 符号大小，对于包含数据的符号，如数据对象或者函数，表示该对象的大小。大小为0，表示符号不存在大小或者大小未知 可见，符号表中的第一个符号，即下标为0的符号，永远是一个未定义的符号。 符号类型与绑定属性成员低4位表示符号类型(symbol type)，符号高4位表示符号绑定属性(symbol binding)，相应提取/组合的C代码： 123#define ELF64_ST_BIND(i) ((i)&gt;&gt;4)#define ELF64_ST_TYPE(i) ((i)&amp;0xf)#define ELF64_ST_INFO(b,t) (((b)&lt;&lt;4)+((t)&amp;0xf)) 符号类型如下表所示，完整的symbol type见[4] Name Value Description STT_NOTYPE 0 未知类型符号 STT_OBJECT 1 符号关联的是数据对象，如变量或者数组等 STT_FUNC 2 符号关联的是函数或者其他可执行代码 STT_SECTION 3 符号关联的是段，绑定属性必须是STB_LOCAL，用于重定位场景，能够通过此种形式制定符号：“修改段xxx偏移yyy处的值”[5] STT_FILE 4 符号关联的是当前ELF文件的源文件名，该符号的绑定属性必须是STB_LOCAL，并且它的st_shndx一定是SHN_ABS STT_COMMON 5 该符号标记一个未初始化的公共块 符号绑定属性如下表所示，完整的symbol binding见[4] Name Value Description STB_LOCAL 0 局部符号，仅在定义符号的目标文件中可见 STB_GLOBAL 1 全局符号，所有目标文件都可见 STB_WEAK 2 弱符号类似于全局符号，当有同名的弱符号和全局符号，全局符号的优先级更高 符号所在段如果符号在当前ELF文件中，st_shndx存储符号在section header table中的索引，对于一些特殊符号，st_shndx的取值有些特殊： SHN_ABS(0xfff1): 简写为ABS，表示符号包含了一个绝对值，不会因为重定位改变。源文件名符号就是该类型 SHN_COMMON(0xfff2): 简写为COM，表示符号是尚未分配的公共块(commom block)，该符号值中存储的是对齐约束，链接器将按照st_value对齐分配地址，SHN_COMMON类型的符号仅出现在可重定位文件中 SHN_UNDEF(0): 简写为UND,该类型的符号在本ELF文件中引用，定义在其他目标文件中 SHN_XINDEX(0xffff)：表示索引值太大，实际的section header table索引存储在SHT_SYMTAB_SHNDX段中 SHT_SYMTAB_SHNDX段的结构： The section is an array of Elf32_Word values. Each value corresponds one to one with a symbol table entry and appear in the same order as those entries. The values represent the section header indexes against which the symbol table entries are defined. Only if the corresponding symbol table entry’s st_shndx field contains the escape value SHN_XINDEX will the matching Elf32_Word hold the actual section header index; otherwise, the entry must be SHN_UNDEF (0). 符号值不同的符号的st_value有不同含义： 可重定位文件中，符号所在段为SHN_ABS的符号，st_value中保存的是符号对齐要求 可重定位文件中，st_value保存定义符号的段偏移(section offset)，符号所在的段由st_shndx确定 可执行文件、动态库中，st_value保存符号的虚拟地址 符号总结上述小节介绍了ELF文件的符号表，对simpleElf.o的符号总结如下： 文件名(FILE)类型符号，局部绑定属性，SHN_ABS表示符号包含的是绝对值，即该符号不会被重定位，其符号值保存其对齐要求，此处为0，无对齐要求；符号不存在大小，故符号大小为0。 段类型(SECTION)符号用来引用段本身，局部绑定属性，根据st_shndx排查段头表，仅.rela.text、.rela.eh_frame、.symtab、.strtab、.shstrtab段无响应的符号，这些段有个特点：辅助重定位，段内的信息并不会被重定位。符号不存在大小，故符号大小为0。 数据类型(OBJECT)符号表示目标文件中的静态变量和全局变量，符号大小都是int类型大小(4)，静态变量是局部绑定属性，全局变量是全局绑定属性。初始化的静态变量和全局变量保存在.data段，未初始化的全局变量保存在.bss段，未初始化的全局变量保存在common block。其符号值表示符号的段内偏移。这些符号名与其定义在函数中的变量名并不相同，特别是静态符号，不仅有static_前缀，更有.&lt;num&gt;后缀，用于解决符号名冲突问题，即程序中的符号名必须唯一，这种行为成为名字改编(name mangling)[6]。静态变量的改编规则更为复杂也是因为静态变量的局部绑定属性允许不同目标模块存在同名变量，因此通过更为复杂的改编规则保证符号名的唯一。 函数类型(FUNC)符号对应目标文件中定义的两个函数，它们都在.text段，相应的符号值表示段内偏移，即func在段首，main在段内偏移0x22字节处，它们都是全局绑定属性，两个函数的大小分别是34(0x22)byte和53(0x35)byte，下面的objdump对.text段的反汇编可以验证。 未知类型符号(NOTYPE)printf，SHN_UNDEF表示其不是在当前目标文件中定义，其绑定属性为全局，引用符号的符号值和符号大小均未定义 1234567891011121314151617181920212223242526272829303132333435363738objdump -d -j .text simpleElf.osimpleElf.o: file format elf64-x86-64Disassembly of section .text:0000000000000000 &lt;func&gt;: 0: 55 push %rbp 1: 48 89 e5 mov %rsp,%rbp 4: 48 83 ec 10 sub $0x10,%rsp 8: 89 7d fc mov %edi,-0x4(%rbp) b: 8b 45 fc mov -0x4(%rbp),%eax e: 89 c6 mov %eax,%esi 10: bf 00 00 00 00 mov $0x0,%edi 15: b8 00 00 00 00 mov $0x0,%eax 1a: e8 00 00 00 00 callq 1f &lt;func+0x1f&gt; 1f: 90 nop 20: c9 leaveq 21: c3 retq 0000000000000022 &lt;main&gt;: 22: 55 push %rbp 23: 48 89 e5 mov %rsp,%rbp 26: 48 83 ec 10 sub $0x10,%rsp 2a: c7 45 fc 01 00 00 00 movl $0x1,-0x4(%rbp) 31: 8b 15 00 00 00 00 mov 0x0(%rip),%edx # 37 &lt;main+0x15&gt; 37: 8b 05 00 00 00 00 mov 0x0(%rip),%eax # 3d &lt;main+0x1b&gt; 3d: 01 c2 add %eax,%edx 3f: 8b 45 fc mov -0x4(%rbp),%eax 42: 01 c2 add %eax,%edx 44: 8b 45 f8 mov -0x8(%rbp),%eax 47: 01 d0 add %edx,%eax 49: 89 c7 mov %eax,%edi 4b: e8 00 00 00 00 callq 50 &lt;main+0x2e&gt; 50: b8 00 00 00 00 mov $0x0,%eax 55: c9 leaveq 56: c3 retq 强符号与弱符号我们经常碰到符号重复定义，多个目标文件中包含同名全局符号的定义，这些目标文件链接时会报符号重复定义的错误： 12345678910111213141516171819202122# cat lib.cvoid foo(int *p)&#123; *p = 1;&#125;# cat main.cvoid foo(double *p)&#123; *p = 2.0;&#125;int main()&#123; return 0;&#125;# gcc -c lib.c # gcc -c main.c # gcc main.o lib.o -o mainlib.o: In function `foo&#x27;:lib.c:(.text+0x0): multiple definition of `foo&#x27;main.o:main.c:(.text+0x0): first defined herecollect2: error: ld returned 1 exit status 可见，gcc在处理C语言的函数符号时，链接器是不支持识别符号类型的，即两个foo函数的返回值不同。然而在C++中，这两个函数的函数签名(Function Signature)是不同的，函数签名包含了一个函数的信息，包含函数名、它的参数类型，其所在的类和命名空间等其他信息。C++的名字改编机制保证不同的函数签名对应不同的符号，因此这两个foo函数在C++中是两个不同的符号： 1234567# g++ -c main.c# g++ -c lib.c# g++ main.o lib.o -o main# readelf -s lib.o | grep foo 8: 0000000000000000 21 FUNC GLOBAL DEFAULT 1 _Z3fooPi# readelf -s main.o | grep foo 9: 0000000000000000 27 FUNC GLOBAL DEFAULT 1 _Z3fooPd 可见，使用C++编译器编译、链接上述文件，由于foo函数的符号不同，可以链接成功。 言归正传，上面的链接报错由于定义了两个同名的符号，而且这两个符号都是强符号(strong symbol)，与之相应的也有弱符号(weak symbol)。弱符号是在链接ELF目标文件过程中使用的特殊注释(specially annotated)符号，默认情况下都是强符号。链接期间，强符号可以覆盖同名弱符号，比如库中定义的弱符号可以被用户自定义的强符号所覆盖，从而使用自定义版本的库函数[7]。弱符号并不在C/C++规范中，本文主要讨论gcc扩展的弱符号。链接过程中会按照下面的规则处理同名强/弱符号： 不允许强符号被多次定义，否则链接器报告重复定义错误 不同目标文件中定义同名的强符号、弱符号，链接器选择强符号 CSAPP、《程序员的自我修养》将未初始化的全局变量称为弱符号，我认为这种说法是不严谨的。前面的global_uninit_var变量是全局绑定属性的符号，该符号属于common block。更为严格的区分，global_uninit_var被称为”common symbol”而非weak symbol[8]。我也更加倾向将绑定属性为global的符号称为强符号，将绑定属性为weak的符号称为弱符号，若将common symbol也称为弱符号，符号的绑定属性的意义就会比较模糊。 gcc中定义弱符号有两种方式：#pragma预处理和gcc扩展weak属性__attribute__((weak))。简要介绍线下#pragma预处理： 1234// function declaration#pragma weak power2int power2(int x); 我们主要关注gcc扩展weak属性定义弱符号的方式： 以内核的arch_report_meminfo函数为例，在架构无关的文件fs/proc/meminfo.c中定义了arch_report_meminfo的弱符号，是空函数。在具体架构如powerpc、x86中实际实现了arch_report_meminfo函数。这些架构相关的arch_report_meminfo是强符号，从而完成了特定架构函数的实现，也能保证无关架构链接arch_report_meminfo时不出错（空函数）。 123456789101112131415161718192021fs/proc/meminfo.c:void __attribute__((weak)) arch_report_meminfo(struct seq_file *m) &#123;&#125;arch/x86/mm/pat/set_memory.c:void arch_report_meminfo(struct seq_file *m)&#123; seq_printf(m, &quot;DirectMap4k: %8lu kB\\n&quot;, direct_pages_count[PG_LEVEL_4K] &lt;&lt; 2);#if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE) seq_printf(m, &quot;DirectMap2M: %8lu kB\\n&quot;, direct_pages_count[PG_LEVEL_2M] &lt;&lt; 11);#else seq_printf(m, &quot;DirectMap4M: %8lu kB\\n&quot;, direct_pages_count[PG_LEVEL_2M] &lt;&lt; 12);#endif if (direct_gbpages) seq_printf(m, &quot;DirectMap1G: %8lu kB\\n&quot;, direct_pages_count[PG_LEVEL_1G] &lt;&lt; 20);&#125; 以glibc中的strdup库函数的实现为例，也定义了strdup的弱符号，允许用户实现同名强符号，覆盖库函数的弱符号： 123456789101112131415161718192021string/strdup.c:char *__strdup (const char *s) &#123; size_t len = strlen (s) + 1; void *new = malloc (len); if (new == NULL) return NULL; return (char *) memcpy (new, s, len);&#125;libc_hidden_def (__strdup)weak_alias (__strdup, strdup)include/libc-symbols.h:/* Define ALIASNAME as a weak alias for NAME. If weak aliases are not available, this defines a strong alias. */# define weak_alias(name, aliasname) _weak_alias (name, aliasname)# define _weak_alias(name, aliasname) \\ extern __typeof (name) aliasname __attribute__ ((weak, alias (#name))); 这个例子主要介绍weak attribute结合weak attribute的情况。先看alias attribute格式: 123456789101112131415161718192021222324252627# cat alias.cint a[8] = &#123;0&#125;;extern __attribute__((alias (&quot;a&quot;))) int b[8];void bar(int *p)&#123; *p = 1;&#125;extern __attribute__((alias (&quot;bar&quot;))) void foo(int *p);# gcc -c alias.c# readelf -s alias.oSymbol table &#x27;.symtab&#x27; contains 12 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FILE LOCAL DEFAULT ABS alias.c 2: 0000000000000000 0 SECTION LOCAL DEFAULT 1 3: 0000000000000000 0 SECTION LOCAL DEFAULT 2 4: 0000000000000000 0 SECTION LOCAL DEFAULT 3 5: 0000000000000000 0 SECTION LOCAL DEFAULT 5 6: 0000000000000000 0 SECTION LOCAL DEFAULT 6 7: 0000000000000000 0 SECTION LOCAL DEFAULT 4 8: 0000000000000000 32 OBJECT GLOBAL DEFAULT 3 a 9: 0000000000000000 32 OBJECT GLOBAL DEFAULT 3 b 10: 0000000000000000 21 FUNC GLOBAL DEFAULT 1 bar 11: 0000000000000000 21 FUNC GLOBAL DEFAULT 1 foo the attribute alias tells the compiler that the declared symbol provides an alias, or alternate identity, for the symbol being named. The named symbol is known as the alias target. The target must be defined in the same translation unit as the alias; the alias itself can only be declared, it cannot be defined. The alias declaration is a definition even when also declared extern. [9] 简要总结下alias属性： alias属性用来给已经定义的符号提供一个别名符号(alias target)，将已经定义的符号称为target target和alias target必须在同一编译单元，且target必须在该编译单元定义。注意上面例子中的数组a显示初始化，如果显示不初始化，编译报错：Error: b&#39; can&#39;t be equated to common symbol a&#39;，我猜想未初始化的全局变量a属于common block，编译器认为这种情况属于“未定义” alias target只能以声明的方式出现，而不能被定义，如上面例子中的extern的声明方式。由于alias target是target的别名，两者实际是一样的，因此alias target已经定义 由readelf输出结果可知，target和alias target都是符号，除了符号名不同，其他符号属性都相同 weak_alias (__strdup, strdup)预处理之后是extern __typeof(__strdup) strdup __attribute__ ((weak, alias (__strdup)));，这条语句定义了别名符号strdup，其target是strdup符号，而且别名符号strdup是弱符号。 当前，我们看到的链接过程在查找符号引用，未找到符号定义时会报错，这种被称为强引用(strong reference)。相对应也存在弱引用(weak reference)，链接处理弱引用和强引用的过程几乎一样，只是对于未定义的符号，链接器处理弱引用不会报错，将未定义的符号值默认为0。gcc的扩展弱引用属性有两种表示方式： static __attribute__ ((weakref (&quot;target&quot;))) alias_target，声明的弱引用符号为target，在当前程序中使用alias_target符号引用target。别名的weakref必须采用static修饰符，否则会编译报错：1234567891011121314151617181920212223242526272829303132333435# cat lib.c #include &lt;stdio.h&gt;void bar()&#123; printf(&quot;%s\\n&quot;,__func__);&#125;# cat main.cstatic __attribute__((weakref(&quot;bar&quot;))) void foo();int main()&#123; if (foo) foo(); return 0;&#125;# gcc main.c -o main &amp;&amp; ./main # echo $?0# gcc -c main.c lib.c# gcc -o main main.o lib.o &amp;&amp; ./main bar# readelf -s main.oSymbol table &#x27;.symtab&#x27; contains 10 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FILE LOCAL DEFAULT ABS main.c 2: 0000000000000000 0 SECTION LOCAL DEFAULT 1 3: 0000000000000000 0 SECTION LOCAL DEFAULT 3 4: 0000000000000000 0 SECTION LOCAL DEFAULT 4 5: 0000000000000000 0 SECTION LOCAL DEFAULT 6 6: 0000000000000000 0 SECTION LOCAL DEFAULT 7 7: 0000000000000000 0 SECTION LOCAL DEFAULT 5 8: 0000000000000000 31 FUNC GLOBAL DEFAULT 1 main 9: 0000000000000000 0 NOTYPE WEAK DEFAULT UND bar 可见，main.c定义了弱引用符号bar，无论bar是否定义，程序链接都不会出错。 __attribute__((weakref)) symbol，无target的情况，即非别名的情况下，weakref也可用weak表示[10]：1234567891011121314151617181920212223# cat pthread.c#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg) __attribute__((weak));int main()&#123; if (pthread_create) &#123; printf(&quot;This is a multi-thread version\\n&quot;); &#125; else &#123; printf(&quot;This is a single-thread version\\n&quot;); &#125; return 0;&#125;# gcc pthread.c -o pt# ./ptThis is a single-thread version# gcc pthread.c -lpthread -o pt# ./ptThis is a multi-thread version 有无链接libpthread.so，链接过程都不会报错。pthread_create在当前程序中是弱符号，弱链接了libpthread.so，则有符号pthread_create实际定义。 弱符号和弱引用在工程实现中具有如下作用： 库中定义的弱符号，可以被具体实现(用户定义/架构定义)的强符号覆盖，无强符号的情况下，弱符号的定义具有通用性，有强符号的情况下又具有特定性 程序可以将扩展功能模块的引用定义为弱引用，当扩展模块和程序链接在一起时，扩展功能可以正常使用，反之则缺少扩展功能 common block符号的st_shndx字段为SHN_COMMON是common symbol，有时候，可以通过符号的st_type字段为STT_COMMON判断符号为common symbol。并不要求common symbol同时满足SHN_COMMON、STT_COMMON。现在的编译器和链接器都支持common block机制，这种机制最早来源于Fortran。早期的Fortran没有动态分配空间的机制，程序员必须实现声明它所需空间大小。Fortran把这种空间叫做common block，当不同的目标文件需要的common block空间不一致时，以最大的空间为准。未定义的全局变量是commcon symbol,前面章节提及的global_uninit_var就是一个典型例子。链接器链接同名的强符号、common符号、弱符号遵循如下规则： IWhen the link editor combines several relocatable object files, it does not allow multiple definitions of STB_GLOBAL symbols with the same name. On the other hand, if a defined global symbol exists, the appearance of a weak symbol with the same name will not cause an error. The link editor honors the global definition and ignores the weak ones. Similarly, if a common symbol exists (that is, a symbol whose st_shndx field holds SHN_COMMON), the appearance of a weak symbol with the same name will not cause an error. The link editor honors the common definition and ignores the weak ones.[11] 简而言之，符号优先级：STB_GLOBAL &gt; COMMON &gt; STB_WEAK，更多关于common symbol的介绍也请参考[11]。 gcc的-fno-common编译选项允许将所有未初始化的全局变量不以common block的形式处理，或者使用__attritute__扩展: 1int global __attribute__((nocommon)); 此时这些未定义的全局变量便是强符号。GCC和Clang之前的版本默认使用-fcommon编译C文件，自GCC 10/Clang 11默认采用-fno-common[11]。","categories":[{"name":"compilation","slug":"compilation","permalink":"https://system-thoughts.github.io/categories/compilation/"}],"tags":[{"name":"ELF","slug":"elf","permalink":"https://system-thoughts.github.io/tags/elf/"}]},{"title":"程序员的自我修养 -- 编译和链接","slug":"程序员的自我修养 -- 编译和链接","date":"2022-07-10T14:28:33.000Z","updated":"2023-01-18T05:32:06.168Z","comments":true,"path":"posts/78679aea/","link":"","permalink":"https://system-thoughts.github.io/posts/78679aea/","excerpt":"近期重读《程序员的自我修养》总结程序的编译、链接、装载过程。书中的第二章《编译和链接》十分清楚地描述了编译和链接的整体工作，本文在此简要总结，算是一篇读书笔记。","text":"近期重读《程序员的自我修养》总结程序的编译、链接、装载过程。书中的第二章《编译和链接》十分清楚地描述了编译和链接的整体工作，本文在此简要总结，算是一篇读书笔记。 gcc编译过程全貌介绍编译过程也不能免俗，以hello world程序开始编译之旅： 12345678# cat hello.c#include &lt;stdio.h&gt;int main(void)&#123; printf(&quot;Hello World\\n&quot;); return 0;&#125; 使用gcc编译并运行hello world程序： 1234567891011121314151617181920# gcc --verbose hello.c -o hello// 预编译&amp;编译/usr/libexec/gcc/x86_64-redhat-linux/8/cc1 -quiet -v hello.c -quiet -dumpbase hello.c -mtune=generic -march=x86-64 -auxbase hello -version -o /tmp/ccXBOY9N.s// 头文件搜索路径#include &quot;...&quot; search starts here:#include &lt;...&gt; search starts here: /usr/lib/gcc/x86_64-redhat-linux/8/include /usr/local/include /usr/includeEnd of search list.// 汇编as -v --64 -o /tmp/ccnma4VO.o /tmp/ccXBOY9N.sGNU assembler version 2.30 (x86_64-redhat-linux) using BFD version version 2.30-73.el8COMPILER_PATH=/usr/libexec/gcc/x86_64-redhat-linux/8/:/usr/libexec/gcc/x86_64-redhat-linux/8/:/usr/libexec/gcc/x86_64-redhat-linux/:/usr/lib/gcc/x86_64-redhat-linux/8/:/usr/lib/gcc/x86_64-redhat-linux/LIBRARY_PATH=/usr/lib/gcc/x86_64-redhat-linux/8/:/usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/:/lib/../lib64/:/usr/lib/../lib64/:/usr/lib/gcc/x86_64-redhat-linux/8/../../../:/lib/:/usr/lib/// 链接COLLECT_GCC_OPTIONS=&#x27;-v&#x27; &#x27;-o&#x27; &#x27;hello&#x27; &#x27;-mtune=generic&#x27; &#x27;-march=x86-64&#x27; /usr/libexec/gcc/x86_64-redhat-linux/8/collect2 -plugin /usr/libexec/gcc/x86_64-redhat-linux/8/liblto_plugin.so -plugin-opt=/usr/libexec/gcc/x86_64-redhat-linux/8/lto-wrapper -plugin-opt=-fresolution=/tmp/ccs52rzN.res -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s -plugin-opt=-pass-through=-lc -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s --build-id --no-add-needed --eh-frame-hdr --hash-style=gnu -m elf_x86_64 -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o hello /usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/crt1.o /usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/crti.o /usr/lib/gcc/x86_64-redhat-linux/8/crtbegin.o -L/usr/lib/gcc/x86_64-redhat-linux/8 -L/usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64 -L/lib/../lib64 -L/usr/lib/../lib64 -L/usr/lib/gcc/x86_64-redhat-linux/8/../../.. /tmp/ccnma4VO.o -lgcc --as-needed -lgcc_s --no-as-needed -lc -lgcc --as-needed -lgcc_s --no-as-needed /usr/lib/gcc/x86_64-redhat-linux/8/crtend.o /usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/crtn.o# ./hello Hello World 上述编译过程分为四个阶段：预编译(preprocessing)、编译(compilation)、汇编(assembly)和链接(linking)。如图所示： 预编译(preprocessing)预编译过程是处理源代码中以”#”开头的预编译命令，gcc的预处理命令是gcc -E或者cpp，预处理后的文件扩展名以.i结尾： 12# cpp hello.c &gt; hello.i# gcc -E hello.c -o hello.i 所有的预编译命令的处理规则如下： 展开所有#define宏定义 处理所有条件预编译指令，如#if、#ifdef、#elif、#else、#endif 处理#include预编译指令，将所有包含的头文件都插入到该预编译指令的位置，这个过程是递归的 删除所有的注释//和/* */ 添加行号和文件名标识，如main函数上的# 3 &quot;hello.c&quot;，以便编译器产生调试用的行号信息以及编译过程中产生告警、报错能够提示行号 保留所有#pragma编译器指令，编译器会用到它 编译(compilation)编译过程是将预处理完的文件经过一系列的词法分析、语法分析、语义分析及优化生成相应的汇编代码。gcc的编译过程相当于： 12# gcc -S hello.c# gcc -S hello.i -o hello.s 汇编代码以.s后缀结尾，实际版本的gcc将预编译和编译在一个步骤中完成，上面的/usr/libexec/gcc/x86_64-redhat-linux/8/cc1程序完成这个过程。整个编译过程可以分为6步：扫描、语法分析、语义分析、源代码优化、代码生成和目标代码优化：以简单程序CompilerExpression.c为例，分析其中的赋值语句的编译过程（这个程序显然没有任何意义，且未对入参进行边界检查）： 1234567# cat CompilerExpression.cint array[4];void func(int index)&#123; array[index] = (index + 4) * (2 + 6);&#125; 词法分析(lexical analysis)源码首先会被词法分析器(lexical analyzer，简称lexer)，也称扫描器(scanner)进行词法分析，运用一种类似有限状态机(Finite State Machine)的算法将源代码的字符序列分割成一系列记号(token)。赋值语句经过扫描后，产生了17个记号： 记号 类型 array 标识符 [ 左方括号 index 标识符 ] 右方括号 = 赋值 ( 左圆括号 index 标识符 + 加号 4 数字 ) 右圆括号 * 乘号 ( 左圆括号 2 数字 + 加号 6 数字 ) 右圆括号 ; 语句结束 词法分析产生的记号可以分为以下几类： 字面量：数字、字符、字符串等 操作符：算术运算符、赋值运算符等 分隔符：分号、括号、逗号等 标识符：变量名、函数名等 关键字：int、switch、break等 gcc支持C、C++、fortran等编程语言的编译，那么gcc内部是否为每种编程语言都实现了一个词法解析器呢？答案并非如此，flex(The Fast Lexical Analyzer)用于生成词法分析器，编译器设计者提供相应的词法规则作为输入。以下是简单的flex词法规则文件(.l后缀)： 1234567# cat simpleLex.l%%&quot;good&quot; &#123; printf(&quot;bad&quot;); &#125;%%# lex simpleLex.l flex读取词法规则文件默认生成lex.yy.c文件，其中定义了C代码格式函数yylex()用作词法解析，该函数可以看做有限状态机。%%必须在本行最前面，即之前不允许有任何空格，flex词法文件的结构[1]: 12345definitions %% rules %% user code definitions和user code参考flex官方文档，最重要的是rules，其结构如下： 1pattern action pattern不能有缩进，action必须和pattern在同一行。pattern可以是正则表达式，参考flex文档[2]。匹配模式，则会执行相应动作，action以C语言代码描述，可以使用return向yylex函数的调用者返回一个值[3]。 将lex.yy.c文件与flex运行时库链接，生成的可执行程序运行时会分析输入中出现的正则表达式，若匹配则执行相应的C代码，上面的示例会将字符串中的”good”替换为”bad”: 12345# yum install flex-devel -y# cc lex.yy.c -lfl -o simpleLexer# ./simpleLexer hello good boyhello bad boy 输入”hello good boy”会替换输出为”hello bad boy”，反汇编simpleLexer: 12345678910111213# objdump -d simpleLexerDisassembly of section .text:00000000004009b0 &lt;main&gt;: 4009b0: f3 0f 1e fa endbr64 4009b4: 48 83 ec 08 sub $0x8,%rsp 4009b8: 0f 1f 84 00 00 00 00 nopl 0x0(%rax,%rax,1) 4009bf: 00 4009c0: e8 f1 00 00 00 callq 400ab6 &lt;yylex&gt; 4009c5: 85 c0 test %eax,%eax 4009c7: 75 f7 jne 4009c0 &lt;main+0x10&gt; 4009c9: 31 ff xor %edi,%edi 4009cb: e8 b0 ff ff ff callq 400980 &lt;exit@plt&gt; simpleLexer程序调用yylex进行词法分析，该函数扫描文件（默认为标准输入），当扫描到一个完整、最长的、可以和正则表达式匹配的字符串时，则执行规则后的C代码，如果C代码中没有return语句，则执行完这些C代码之后，yylex会继续运行，开始下一轮的扫描[4]。 gcc源码中有相应的.l词法规则文件，依赖flex生成词法分析器[5]: Similarly, when building from the source repository or snapshots, or if you modify *.l files, you need the Flex lexical analyzer generator installed. If you do not modify *.l files, releases contain the Flex-generated files and you do not need Flex installed to build them. There is still one Flex-based lexical analyzer (part of the build machinery, not of GCC itself) that is used even if you only build the C front end. 语法分析(syntactic analysis)语法分析器(grammar parser)对扫描器产生的记号进行语法分析以产生语法树(syntax tree)。整个分析过程采用上下文无关语法(context-free grammar)的分析手段，由语法分析器产生的语法树就是以表达式(expression)为节点的树。C语言的一条语句就是一个表达式，复杂语句是多个表达式的组合。上面语句由赋值表达式、加法表达式、乘法表达式、数组表达式、括号表达式组成，形成的语法树如图所示：语法树构建过程中，运算符的优先级和含义已经确定下来。*在C语言中可以表示乘法运算，也可以表示取指针运算。语法分析阶段必须对这些内容进行区分，如果出现了表达式不合法，如括号不匹配、缺少操作符，编译器在语法分析阶段就报错。同flex，gcc也是利用相应工具根据语法规则生成相应的语法分析器，而无需为每种编程语言都写一个语法分析器。yacc(Yet Another Compiler Compiler)用来生成语法解析器，被称为“编译器的编译器”，最初由AT&amp;T的Steven C. Johnson在Unixs上实现[6]，yacc已经成为POSIX标准的一部分。yacc在开源软件领域有两个替代实现：Berkeley Yacc (byacc)、GNU Bison。前者以public domain许可证发行，后者以GPL许可证发行[7]，两者都兼容yacc。 语义分析(semantic analysis)语法分析仅能够完成对表达式语法层面的分析，但它并不了解这个语句是否真的有意义。比如C语言里两个指针做乘法运算是没有意义的，但是这个语句是符合语法的。编译器所能分析的语义是静态语义(static semantic)，静态语义是在编译期可以确定的语义，相对应的是动态语义(dynamic semantic)，即运行时才能确定的语义，如除0操作是个运行期的语义错误。静态语义分析包括声明和类型匹配，类型转换等。比如，将浮点类型表达式赋值给整形表达式时，隐含了一个浮点型到整型的转换过程，语义分析需要完成这个步骤。将浮点类型赋值给一个指针的时候，语义分析过程会检查出类型不匹配，编译器会报错。经过语义分析后，整个语法树的表达式都标识了类型，如果有些类型需要做隐式转换，语义分析过程会在语法树中插入相应的转换节点。经过语义分析阶段后的语法树如图所示： 中间语言生成现代编译器有多个层次的优化，源码级优化器(source code optimizer)完成源代码级别的优化，如2 + 6表达式会被优化掉，直接计算得到8，更多源码级优化可以参考编译器设计相关的资料。优化之后的语法树如图所示：直接在语法树上做优化比较困难，源码级优化器先将语法树转换成中间代码(intermediate code)，它是语法树的顺序表示，已经很接近目标代码，但是与目标机器和运行时环境无关，如它不包含数据尺寸、变量地址寄存器的名字等。中间代码有多种类型，比较常见的有三地址码(Three-adress Code)和P代码(P-Code)。gcc使用GIMPLE的三地址表示中间代码[8]，最基本的三地址码是这样的: 1x = y op z 因为一个三地址语句中有三个变量地址，三地址码得名于此。这个三地址码表示将变量y和z进行op操作以后赋值给x。上面的语法树翻译成三地址码是这样的： 1234t1 = 2 + 6t2 = index + 4t3 = t2 * t1array[index] = t3 这里利用了几个临时变量t1、t2、t3，在三代码的基础进行性优化，可以将t1计算出来，将后面的t1都替换掉： 123t2 = index + 4t3 = t2 * 8array[index] = t3 这里t3临时变量也可以优化掉： 12t2 = index + 4array[index] = t2 * 8 中间代码使得编译器被分为前端和后端，编译器的前端负责产生与构建机器无关的中间代码，编译器后端将中间代码转换成目标机器代码。对一些跨平台的编译器而言，可以针对不同的平台使用同一个前端，针对不同机器平台设计不同的后端。 目标代码生成与优化(object code generate &amp; optimize)生成中间代码之后的编译工作都属于编译器后端，主要包括代码生成器(code generator)和目标代码优化器(target code optimizer)。代码生成器将中间代码转换为目标机器汇编代码，这个过程依赖于目标机器，不同的目标机器有着不同的字长、寄存器、指令等。示例代码生成的x86_64的汇编代码如下所示: 1234567movl %edi, -4(%rbp)movl -4(%rbp), %eaxaddl $4, %eaxleal 0(,%rax,8), %edxmovl -4(%rbp), %eaxcltqmovl %edx, array(,%rax,4) 最后，目标代码优化器对上述目标代码进行优化，这个级别的优化回合目标机器相关，如选择合适的寻址方式、使用位移代替乘法运算、删除多余指令等。源码级优化和目标代码优化，可以参考[9][10]。 汇编(assembly)汇编器将汇编代码转换成机器可以执行的机器指令，每条汇编语句几乎都对应一条机器指令。所以汇编器的汇编过程相对比较简单，没有语法、语义，也不涉及指令优化，仅仅根据汇编指令和机器指令的对照表一一翻译即可，“汇编”这个名字就源于此。gcc的汇编过程由汇编器as来完成： 123# as hello.s -o hello.o# gcc -c hello.c -o hello.o# gcc -c hello.s -o hello.o 汇编器输出的目标文件(object file)以.o结尾。 链接(linking)原始链接的概念在高级编程语言发明之前已经存在。最开始的纸带打孔编码都无需经过编译、汇编过程，而是直接编写的二进制机器码在计算机上运行。就在打孔编码的蛮荒时代也会遇到“软件工程问题”，如在第1条指令和第5条指令之间插入指令，则第5条指令及后面的指令的位置都会相应往后移动，原先指令中存在指向这些调整位置指令的地址就需要调整。若编码工作由多个团队协作，甚至存在跨纸带的地址调整。重新计算各个目标地址的工程称作重定位(relocation)**，最开始这个工作认为完成，不仅枯燥、繁琐，还容易出错。显然，重定位工作交给程序完成才是最合适的，汇编语言应运而生。汇编语言引入了一套助记符，如跳转指令使用jmp表示，不仅方便程序员阅读代码，还引入了符号(symbol)** 的概念。符号用来表示一个地址，可能是一段子程序，也可能是一个变量的起始地址。如第1条指令是jmp foo，第5条指令开始的子程序命名为foo。不管foo这个符号所在的地址如何变化，汇编器每次汇编程序时都会重新计算foo符号地址。有了汇编语言之后，开发效率极大提升，随之软件规模扩大。人们开始考虑将不同功能的代码按照一定的方式组织起来，便于阅读、开发、维护。自然而然，人们按照代码功能或者性质划分，形成了不同的功能模块，模块之间按照层次结构或者其他结构组织起来。程序被分割成不同的模块之后，将不同的模块组合成单一程序的过程称为链接。链接问题归根结底是模块间的通信问题，C程序的模块间通信方式有两种： 模块间的函数调用 模块间的变量访问 两种方式都是模块间的符号引用，因此链接就是解决模块间的符号引用问题。从原理上讲，链接过程是多模块场景下，对其他符号的地址的引用加以修正。链接过程主要包括了地址和空间分配(Address and Storage Allocation)、符号决议(Symbol Resolution)和重定位(Relocation)等步骤。地址和空间分配：目标文件中的代码和数据信息以section的方式组织，结果目标文件中代码、数据section由参与链接的目标文件相应的section组成。地址和空间分配是组合成结果目标文件section时考虑其虚拟地址以及存储空间。符号决议：将符号的引用与符号定义建立关联重定位：修正符号引用处符号地址，每个要被修正的地方叫做重定位入口(relocation entry)。 链接分为静态链接和动态链接，静态链接的空间分配、符号决议、重定位在编译过程中完成，输出的可执行程序已经确定了所有符号的地址。动态链接的最终符号重定位步骤完成可能发生在可执行程序加载时，或者程序运行时，故得名动态链接。 gcc默认采用动态链接，上述gcc编译过程最后的collect2执行的是链接过程，collect2可以看做是对链接器ld的封装，ld源于binutils项目。可见动态链接也会有ld链接器完成目标文件的组装。 Reference[1] https://westes.github.io/flex/manual/Format.html#Format[2] https://westes.github.io/flex/manual/Patterns.html#Patterns[3] https://tldp.org/HOWTO/GCC-Frontend-HOWTO-3.html[4] https://pandolia.net/tinyc/ch8_flex.html[5] https://gcc.gnu.org/install/build.html[6] https://en.wikipedia.org/wiki/Yacc[7] https://tomassetti.me/why-you-should-not-use-flex-yacc-and-bison/[8] https://gcc.gnu.org/wiki/GIMPLE[9] https://www.geeksforgeeks.org/code-optimization-in-compiler-design/?ref=lbp[10] https://www.tutorialspoint.com/compiler_design/compiler_design_code_optimization.htm","categories":[{"name":"compilation","slug":"compilation","permalink":"https://system-thoughts.github.io/categories/compilation/"}],"tags":[{"name":"compilation","slug":"compilation","permalink":"https://system-thoughts.github.io/tags/compilation/"},{"name":"link","slug":"link","permalink":"https://system-thoughts.github.io/tags/link/"}]},{"title":"启动过程分析--initramfs阶段","slug":"启动过程分析--initramfs阶段","date":"2022-06-23T04:16:09.000Z","updated":"2023-01-18T05:32:06.164Z","comments":true,"path":"posts/e06690ff/","link":"","permalink":"https://system-thoughts.github.io/posts/e06690ff/","excerpt":"kernel version: 5.18(4b0986a3613c) 本文中的大部分代码段都有代码删除 系统启动过程的最后一个阶段：挂载根文件系统、执行根文件系统中的init程序完成到用户空间的切换。然而根文件系统可能是在不同的硬件设备上，如SCSI硬盘、SATA硬盘、Flash设备等，后续会出现更多的硬件设备；根文件系统可以是xfs、ext4、NFS等不同的文件系统；为了成功挂载根文件系统，内核需要具备相应的设备驱动、文件系统驱动，如果为了兼容所有的根文件系统，将所有相关驱动编译进内核，会增大内核大小，并在实际环境中引入一些无用的驱动。","text":"kernel version: 5.18(4b0986a3613c) 本文中的大部分代码段都有代码删除 系统启动过程的最后一个阶段：挂载根文件系统、执行根文件系统中的init程序完成到用户空间的切换。然而根文件系统可能是在不同的硬件设备上，如SCSI硬盘、SATA硬盘、Flash设备等，后续会出现更多的硬件设备；根文件系统可以是xfs、ext4、NFS等不同的文件系统；为了成功挂载根文件系统，内核需要具备相应的设备驱动、文件系统驱动，如果为了兼容所有的根文件系统，将所有相关驱动编译进内核，会增大内核大小，并在实际环境中引入一些无用的驱动。 initramfs作为一个过渡文件系统解决了挂载根文件系统的兼容性。其中包含了必要的硬件设备、文件系统驱动以及驱动的加载工具及其运行环境。initramfs可以编译进内核也可以作为单独文件由bootloader加载入内存，在内核初始化的最后阶段，会解压initramfs，运行其中的init程序完成根文件系统挂载，并执行根文件系统中的init程序，完成内核空间到用户空间的切换。 Linux kernel 2.6引入initramfs机制，之前使用initrd完成上述工作。当前主流Linux发行版采用initramfs机制，内核仍兼容initrd。人们还是习惯将initramfs称作initrd，本文会对二者进行严格的区分。 initramfs vs initrdinitrd与initramfs之间的主要区别是initrd基于ramdisk机制，而initramfs基于ramfs。内核文档&lt;ramfs, rootfs and initramfs&gt;很好地介绍、对比了两种机制，本文在后面几小节简要总结。 ramdisk ramfs tmpfs rootfsramdisk是将固定大小的内存模拟成块设备，需要文件系统(如ext2)格式化块设备以存取数据。同块设备一样，ramdisk的数据读取也会用到磁盘缓存机制(disk caching mechanisms, “page cache” for file data, “dentry cache” for directory entries)。显然，ramdisk有些多此一举，文件实际存储在内存中，但文件读取还要通过基于内存的磁盘缓存。ramdisk机制的缺点原文概括的十分精准： this wastes memory (and memory bus bandwidth), creates unnecessary work for the CPU, and pollutes the CPU caches. (There are tricks to avoid this copying by playing with the page tables, but they’re unpleasantly complicated and turn out to be about as expensive as the copying anyway. 既然访问文件都要经过磁盘cache，为何不直接将文件保存在磁盘cache？Linus实现了一个伪文件系统(dummy filesystem)ramfs，完成了最低限度的VFS接口实现，即文件创建时能够在inode cache中创建相应的inode和dentry，并将文件直接保存在磁盘cache中。存储文件的页面不会被标记为clean，因此保存在磁盘cache中的文件页面不会被回收，除非文件被删除。 ramfs有两个显著的缺点： 内存占用无限制，只要愿意往ramfs存储数据，文件便会占用内存，而不受限 基于上一点，只有root用户能够在ramfs中读/写数据 社区在ramfs的基础上开发了tmpfs，tmpfs增加了size limits，不能无限制地往内存中写文件；并支持将磁盘缓存中的文件数据写入swap空间。因此，tmpfs支持普通用户访问其挂载点。 initramfs的文件类型是cpio归档件的gzip压缩类型，即cpio.gz。rootfs是ramfs（或者tmpfs）的一个特殊示例，initramfs中的文件会被解压到rootfs中。当CONFIG_TMPFS配置时，默认使用tmpfs代替ramfs作为rootfs。若需要强制使用ramfs作为rootfs，可以通过内核启动项参数rootfstype=ramfs指定。 rootfs挂载1234567891011start_kernel|-&gt; vfs_caches_init | -&gt; mnt_init | -&gt; init_rootfs // 判断rootfs类型是否为tmpfs -&gt; init_mount_tree // 挂载rootfs-&gt; arch_call_rest_init | -&gt; rest_init // 创建1号进程、2号进程 init_rootfs同时满足如下条件时便以tmpfs作为rootfs: CONFIG_TMPFS配置 未通过root内核启动项参数指定根文件系统所在的设备 未通过rootfstype内核启动项参数指定rootfs类型或者指定类型就是tmpfs 12345678910111213141516171819202122232425static int rootfs_init_fs_context(struct fs_context *fc)&#123; if (IS_ENABLED(CONFIG_TMPFS) &amp;&amp; is_tmpfs) return shmem_init_fs_context(fc); return ramfs_init_fs_context(fc);&#125;struct file_system_type rootfs_fs_type = &#123; .name = &quot;rootfs&quot;, .init_fs_context = rootfs_init_fs_context, .kill_sb = kill_litter_super,&#125;;static void __init init_mount_tree(void)&#123; ... struct vfsmount *mnt = vfs_kern_mount(&amp;rootfs_fs_type, 0, &quot;rootfs&quot;, NULL); struct mnt_namespace *ns = alloc_mnt_ns(&amp;init_user_ns, false); m = real_mount(mnt); m-&gt;mnt_ns = ns; ns-&gt;root = m; init_task.nsproxy-&gt;mnt_ns = ns; ...&#125; init_mount_tree完成rootfs挂载，若rootfs为tmpfs，则使用shmem_init_fs_context初始化文件系统上下文。并初始化0号进程init_task的mnt_namespace(mnt命名空间)为rootfs。 rest_init创建1号进程和2号进程，1号进程是init进程，完成后续的系统初始化工作，最终完成内核空间到用户空间的切换；2号进程是kthreadd进程，负责完成内核kernel_thread创建进程的工作。 12345ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 Jun17 ? 00:00:40 /usr/lib/systemd/systemd --switched-root --system --droot 2 0 0 Jun17 ? 00:00:01 [kthreadd]... ps命令查看到的1号进程是切换到用户空间之后的systemd进程，并非当前rest_init创建的1号进程。 123456789noinline void __ref rest_init(void)&#123; ... pid = kernel_thread(kernel_init, NULL, CLONE_FS); pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES); ... complete(&amp;kthreadd_done); ...&#125; kernel_init process covers allkernel_init在执行之处调用wait_for_completion(&amp;kthreadd_done)，即等待2号进程创建并初始化成功之后才开始后续工作： 12345678910111213kernel_init|-&gt; kernel_init_freeable | -&gt; do_basic_setup | -&gt; do_initcalls -&gt; wait_for_initramfs -&gt; console_on_rootfs // 打开/dev/console，创建标准输入(0)、标准输出(1)、标准错误(2)文件描述符 -&gt; init_eaccess(ramdisk_execute_command) // 检查当前rootfs中是否存在&#x27;/init&#x27; \\_ (NO) prepare_namespace // 通过initrd完成实际根文件系统的挂载至rootfs根目录/-&gt; run_init_process(ramdisk_execute_command|execute_command|CONFIG_DEFAULT_INIT)-&gt; try_to_run_init_process(&quot;/sbin/init&quot;|&quot;/etc/init&quot;|&quot;/bin/init&quot;|&quot;/bin/sh&quot;) kernel_init_freeable完成内核部分子系统初始化，如workqueue、启动其他CPU、SMP初始化等操作。待所有CPU上线、进程、内存核心子系统初始化完成，调用do_basic_setup完成其他初始化操作，其中包括do_initcalls执行init段中的函数即调用initcall回调函数，populate_rootfs调用do_populate_rootfs完成initramfs解压到rootfs的工作，或者通过prepare_namespace通过initrd完成实际根文件系统的挂载。通过run_init_process启动可执行程序，完成从内核空间到用户空间的切换，可以是如下程序： var initial value kernel cmdline/CONFIG description ramdisk_execute_command “/init” “rdinit=” Run specified binary instead of /init from the ramdisk,used for early userspace startup. execute_command NULL “init=” Run specified binary instead of /sbin/init as init process. CONFIG_DEFAULT_INIT “” CONFIG_DEFAULT_INIT Default init path 如果上述路径的init程序未成功执行，则依次尝试运行如下程序：/sbin/init、/etc/init、/bin/init、/bin/sh。通过initramfs过渡和通过initrd过渡获得的init程序职责是不同的。通过initrd过渡，由于已经完成了实际根文件系统的挂载，这里运行的init程序是实际根文件系统的init程序。然而，initramfs过渡得到的init程序还肩负着挂载实际根文件系统的责任！ initramfs unpack123456789101112131415161718void wait_for_initramfs(void)&#123; if (!initramfs_cookie) return; async_synchronize_cookie_domain(initramfs_cookie + 1, &amp;initramfs_domain);&#125;EXPORT_SYMBOL_GPL(wait_for_initramfs);static int __init populate_rootfs(void)&#123; initramfs_cookie = async_schedule_domain(do_populate_rootfs, NULL, &amp;initramfs_domain); usermodehelper_enable(); if (!initramfs_async) wait_for_initramfs(); return 0;&#125;rootfs_initcall(populate_rootfs); async_schedule_domain、async_synchronize_cookie_domain是内核的异步执行机制，通过并行化initramfs的解压工作加快内核启动： async_schedule_domain：调度函数异步执行，返回异步执行函数的async cookie async_synchronize_cookie_domain: 同步小于async cookie的异步函数执行 默认情况下，initramfs解压操作do_populate_rootfs会被异步执行；调用wait_for_initramfs函数等待initramfs解压操作完成。也可以通过内核启动项参数initramfs_async=false将initramfs解压流程变更为顺序执行。 12345678910111213141516171819202122232425static void __init do_populate_rootfs(void *unused, async_cookie_t cookie)&#123; /* Load the built in initramfs */ char *err = unpack_to_rootfs(__initramfs_start, __initramfs_size); if (!initrd_start || IS_ENABLED(CONFIG_INITRAMFS_FORCE)) goto done; err = unpack_to_rootfs((char *)initrd_start, initrd_end - initrd_start); if (err) &#123;#ifdef CONFIG_BLK_DEV_RAM populate_initrd_image(err);#else printk(KERN_EMERG &quot;Initramfs unpacking failed: %s\\n&quot;, err);#endif &#125;done: if (!do_retain_initrd &amp;&amp; initrd_start &amp;&amp; !kexec_free_initrd()) free_initrd_mem(initrd_start, initrd_end); initrd_start = 0; initrd_end = 0; flush_delayed_fput();&#125; do_populate_rootfs将initramfs/initrd解压到rootfs中： 将链接进内核的initramfs解压至rootfs中，链接到内核的initramfs在内存中的起始地址是__initramfs_start，大小是__initramfs_size 若内核未配置CONFIG_INITRAMFS_FORCE（忽略bootloader传入的initramfs）且(通过initrd=&lt;path&gt;或者initrdmem=&lt;physical addr&gt;)指定了initramfs地址(initrd_start不为0)，则将指定的initramfs解压至rootfs中，否则直接跳至4 若2中的initramfs解压失败，则认为2中解压的image不是initramfs，而是initrd。调用populate_initrd_image在rootfs中创建/initrd.image文件，并将initrd的内容写入到文件 如果没配置内核启动项参数retain_initrd、keepinitrd，而且指定了initramfs地址，则调用kexec_free_initrd释放initramfs与crashkernel不重叠部分的内存区域，若两者无重叠，则完全释放指定的initramfs内存区域 __initramfs_start在include/asm-generic/vmlinux.lds.h中定义，在include/linux/initrd.h中对外声明，内核包含include/linux/initrd.h文件，即可访问__initramfs_start变量： 123456789101112131415161718192021222324252627282930include/linux/initrd.h:extern char __initramfs_start[];include/asm-generic/vmlinux.lds.h:#ifdef CONFIG_BLK_DEV_INITRD#define INIT_RAM_FS \\ . = ALIGN(4); \\ __initramfs_start = .; \\ KEEP(*(.init.ramfs)) \\ . = ALIGN(8); \\ KEEP(*(.init.ramfs.info))#else#define INIT_RAM_FS#endifarch/x86/kernel/vmlinux.lds.S:#include &lt;asm-generic/vmlinux.lds.h&gt;arch/x86/boot/compressed/vmlinux.lds.S:#include &lt;asm-generic/vmlinux.lds.h&gt;scripts/Makefile.build:# Linker scripts preprocessor (.lds.S -&gt; .lds)# ---------------------------------------------------------------------------quiet_cmd_cpp_lds_S = LDS $@ cmd_cpp_lds_S = $(CPP) $(cpp_flags) -P -U$(ARCH) \\ -D__ASSEMBLY__ -DLINKER_SCRIPT -o $@ $&lt;$(obj)/%.lds: $(src)/%.lds.S FORCE $(call if_changed_dep,cpp_lds_S) vmlinux.lds是内核构建过程所使用的链接脚本，这里vmlinux.lds通过vmlinux.lds.S预编译生成，这样可以利用条件编译，根据不同的内核配置生成不同的链接脚本。参考内核文档Documentation/kbuild/makefiles.rst When the vmlinux image is built, the linker script arch/$(SRCARCH)/kernel/vmlinux.lds is used. The script is a preprocessed variant of the file vmlinux.lds.S located in the same directory. kbuild knows .lds files and includes a rule `*lds.S` -&gt; `*lds`. Example:: #arch/x86/kernel/Makefile extra-y := vmlinux.lds The assignment to extra-y is used to tell kbuild to build the target vmlinux.lds. The assignment to $(CPPFLAGS_vmlinux.lds) tells kbuild to use the specified options when building the target vmlinux.lds. When building the `*.lds` target, kbuild uses the variables:: KBUILD_CPPFLAGS : Set in top-level Makefile cppflags-y : May be set in the kbuild makefile CPPFLAGS_$(@F) : Target-specific flags. Note that the full filename is used in this assignment. The kbuild infrastructure for `*lds` files is used in several architecture-specific files. Documentation/kbuild/makefiles.rst连接脚本定义了符号__initramfs_start所在地址： special symbol ‘.’, which is the location counter. 链接脚本定义的符号与普通符号（在程序中定义的符号）的区别是链接脚本中的符号仅代表一个地址，而普通符号不仅代表一个地址，还有该地址的内存空间。 关于initrd内核启动项参数可能会带来一些困惑，先查看内核文档中的介绍： 123456789Documentation/admin-guide/initrd.rst: initrd=&lt;path&gt; (e.g. LOADLIN) Loads the specified file as the initial RAM disk. When using LILO, you have to specify the RAM disk image file in /etc/lilo.conf, using the INITRD configuration variable.Documentation/admin-guide/kernel-parameters.txt: initrd= [BOOT] Specify the location of the initial ramdisk 相应内核启动项参数的代码： 1234567891011121314151617181920212223init/do_mounts_initrd.c:static int __init early_initrdmem(char *p) &#123; phys_addr_t start; unsigned long size; char *endp; start = memparse(p, &amp;endp); if (*endp == &#x27;,&#x27;) &#123; size = memparse(endp + 1, NULL); phys_initrd_start = start; phys_initrd_size = size; &#125; return 0;&#125;early_param(&quot;initrdmem&quot;, early_initrdmem);static int __init early_initrd(char *p) &#123; return early_initrdmem(p);&#125;early_param(&quot;initrd&quot;, early_initrd); 内核代码中的initrd内核启动项参数就是initrdmem内核启动项参数，指定initramfs的物理地址。那么Documentation/admin-guide/initrd.rst中描述initrd=&lt;path&gt;的内核启动项参数是不是错误呢？ 非也，从x86_64和arm64中initrd_start赋值进行排查，应该能发现端倪： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667x86_64:static u64 __init get_ramdisk_image(void)&#123; u64 ramdisk_image = boot_params.hdr.ramdisk_image; ramdisk_image |= (u64)boot_params.ext_ramdisk_image &lt;&lt; 32; if (ramdisk_image == 0) ramdisk_image = phys_initrd_start; return ramdisk_image;&#125;static void __init reserve_initrd(void)&#123; /* Assume only end is not page aligned */ u64 ramdisk_image = get_ramdisk_image(); u64 ramdisk_size = get_ramdisk_size(); u64 ramdisk_end = PAGE_ALIGN(ramdisk_image + ramdisk_size); if (!boot_params.hdr.type_of_loader || !ramdisk_image || !ramdisk_size) return; /* No initrd provided by bootloader */ initrd_start = 0; printk(KERN_INFO &quot;RAMDISK: [mem %#010llx-%#010llx]\\n&quot;, ramdisk_image, ramdisk_end - 1); if (pfn_range_is_mapped(PFN_DOWN(ramdisk_image), PFN_DOWN(ramdisk_end))) &#123; /* All are mapped, easy case */ initrd_start = ramdisk_image + PAGE_OFFSET; initrd_end = initrd_start + ramdisk_size; return; &#125; relocate_initrd(); memblock_phys_free(ramdisk_image, ramdisk_end - ramdisk_image);&#125;arm64:static void __init early_init_dt_check_for_initrd(unsigned long node)&#123; ... prop = of_get_flat_dt_prop(node, &quot;linux,initrd-start&quot;, &amp;len); start = of_read_number(prop, len/4); prop = of_get_flat_dt_prop(node, &quot;linux,initrd-end&quot;, &amp;len); end = of_read_number(prop, len/4); __early_init_dt_declare_initrd(start, end); phys_initrd_start = start; phys_initrd_size = end - start;&#125;void __init arm64_memblock_init(void)&#123; ... if (IS_ENABLED(CONFIG_BLK_DEV_INITRD) &amp;&amp; phys_initrd_size) &#123; /* the generic initrd code expects virtual addresses */ initrd_start = __phys_to_virt(phys_initrd_start); initrd_end = initrd_start + phys_initrd_size; &#125; ...&#125; x86_64平台下，bootloader启动内核遵循Linux/x86 Boot Protocol，约束了加载到内核的内存布局，也规定了bootloader与内核交互接口。x86 64bit boot protocol规定，bootloader加载内核会初始化清零boot parameters（struct boot_params，也称为zero page）；随后读取内核的Real-Mode kernel header(struct setup_header，内核镜像0x01f1偏移处)至zero page的setup_header，这个过程中，bootloader完成initramfs地址的设置。arm64平台通过FDT(flatten device tree)中的chosen节点设置内核启动项参数(bootargs)以及initramfs(initrd-start、initrd-end)[1]。 Compatible with initrdinitramfs解压完成之后，检查rootfs中是否存在early userspace startup init程序。内核变量ramdisk_execute_command指定init程序路径，默认是/init，也可以通过rdinit=&lt;full_path&gt;内核启动项参数指定程序路径。若rootfs中不存在init程序，则认为指定的是initrd，而非initramfs。之前通过解压initramfs的方式解压initrd不成功，则当前rootfs中自然不存在init程序，见do_populate_rootfs中的流程3。需要调用prepare_namespace通过initrd完成实际根文件系统的挂载。 1234567891011121314151617181920212223242526272829303132void __init prepare_namespace(void)&#123; ... wait_for_device_probe(); // 等待设备初始化完成 md_run_setup(); // 初始化MD设备（软raid） if (saved_root_name[0]) &#123; root_device_name = saved_root_name; if (!strncmp(root_device_name, &quot;mtd&quot;, 3) || !strncmp(root_device_name, &quot;ubi&quot;, 3)) &#123; mount_block_root(root_device_name, root_mountflags); goto out; &#125; ROOT_DEV = name_to_dev_t(root_device_name); if (strncmp(root_device_name, &quot;/dev/&quot;, 5) == 0) root_device_name += 5; &#125; // 通过initrd挂载实际根文件系统成功，则返回true if (initrd_load()) goto out; // 通过initrd挂载实际根文件系统不成功，或者ramdisk就是实际根文件系统，则直接尝试对根文件系统挂载 mount_root();out: // 挂载devtmpfs devtmpfs_mount(); // 将实际根文件系统中的内容移动到rootfs的根目录/下 init_mount(&quot;.&quot;, &quot;/&quot;, NULL, MS_MOVE, NULL); init_chroot(&quot;.&quot;);&#125; saved_root_name变量保存根文件系统所在的设备，由内核启动项参数root=指定，默认为空。saved_root_name存在两种情况: 若根文件系统存在于mtd/ubi设备，驱动程序在内核初始化阶段已经安装，可以直接挂载，无需initrd过渡文件系统 根文件系统存在于其他设备，则需先挂载先挂载initrd过渡，插入存储在initrd文件系统中的根文件系统所在存储设备的驱动，最后再挂载实际根文件系统。这个过程由initrd_load完成。 initrd_load可以拆分为如下两步： rd_load_image将initrd解压/读入到ramdisk中(/dev/ram设备节点) handle_initrd完成实际根文件系统挂载12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788int __init rd_load_image(char *from)&#123; ... out_file = filp_open(&quot;/dev/ram&quot;, O_RDWR, 0); in_file = filp_open(from, O_RDONLY, 0); // 通过内核启动项参数ramdisk_start指定ramdisk在initrd image中的起始地址(offset)，默认值为0 in_pos = rd_image_start * BLOCK_SIZE; nblocks = identify_ramdisk_image(in_file, in_pos, &amp;decompressor); if (nblocks &lt; 0) goto done; if (nblocks == 0) &#123; if (crd_load(decompressor) == 0) goto successful_load; goto done; &#125; // rd_blocks表示/dev/ram ramdisk实际大小 rd_blocks = nr_blocks(out_file); // initrd image中要读入的大小超过了ramdisk的大小 if (nblocks &gt; rd_blocks) &#123; printk(&quot;RAMDISK: image too big! (%dKiB/%ldKiB)\\n&quot;, nblocks, rd_blocks); goto done; &#125; buf = kmalloc(BLOCK_SIZE, GFP_KERNEL); for (i = 0; i &lt; nblocks; i++) &#123; kernel_read(in_file, buf, BLOCK_SIZE, &amp;in_pos); kernel_write(out_file, buf, BLOCK_SIZE, &amp;out_pos); &#125; ...&#125;static void __init handle_initrd(void)&#123;... // real_root_dev编码保存实际根设备 real_root_dev = new_encode_dev(ROOT_DEV); // 创建Root_RAM0的设备文件/dev/root.old create_dev(&quot;/dev/root.old&quot;, Root_RAM0); // 将initrd挂载到rootfs的root目录 mount_block_root(&quot;/dev/root.old&quot;, root_mountflags &amp; ~MS_RDONLY); // 创建/root/old目录 init_mkdir(&quot;/old&quot;, 0700); init_chdir(&quot;/old&quot;); // 执行用户态程序/root/linuxrc加载驱动模块 info = call_usermodehelper_setup(&quot;/linuxrc&quot;, argv, envp_init, GFP_KERNEL, init_linuxrc, NULL, NULL); call_usermodehelper_exec(info, UMH_WAIT_PROC);... /* move initrd to rootfs&#x27; /old */ // 将/root挂载点下的文件移动到/root/old目录下：mount --move olddir newdir init_mount(&quot;..&quot;, &quot;.&quot;, NULL, MS_MOVE, NULL); // 将/root目录切换为系统的根目录 init_chroot(&quot;..&quot;); // 实际根文件系统所在的设备是否是Root_RAM0 if (new_decode_dev(real_root_dev) == Root_RAM0) &#123; // 切换到/old目录，因为/old目录就是/dev/ram设备存储的内容 init_chdir(&quot;/old&quot;); return; &#125; init_chdir(&quot;/&quot;); ROOT_DEV = new_decode_dev(real_root_dev); // 将实际根设备挂载到/root目录 mount_root(); // 将/old挂载点的内容移动到/root/initrd目录下显示 error = init_mount(&quot;/old&quot;, &quot;/root/initrd&quot;, NULL, MS_MOVE, NULL);&#125;bool __init initrd_load(void)&#123; if (mount_initrd) &#123; // 创建/dev/ram设备节点，代表设备编号Root_RAM0 create_dev(&quot;/dev/ram&quot;, Root_RAM0); // 如果/initrd.image中存在initrd，将其装载到/dev/ram中，且/dev/ram不是最终的根文件系统 if (rd_load_image(&quot;/initrd.image&quot;) &amp;&amp; ROOT_DEV != Root_RAM0) &#123; init_unlink(&quot;/initrd.image&quot;); handle_initrd(); return true; &#125; &#125; init_unlink(&quot;/initrd.image&quot;); // 删除文件/initrd.image return false;&#125; mount_initrd初始值为1，表示是否加载initrd。通过noinitrd内核启动项参数设置mount_initrd为0，表示内核不加载任何配置的initrd。rd_load_image将initrd读入到内存虚拟的ramdisk中。initrd可能被压缩处理，根据identify_ramdisk_image返回值initrd是否被压缩： -1, initd中的magic number有误 0，initrd被压缩，随后调用crd_load(decompressor)解压initrd到/dev/ram nblocks(&gt; 0)，initrd未被压缩，nblocks表示initrd的大小，以block(1024byte)为单位表示，随后直接从/initrd.image读入到/dev/ram initrd可以是minix、ext2、romfs、cramfs、squashfs文件系统。压缩算法支持gzip、bzip2、lzma、xz、lzo、lz4。 handle_initrd首先将载有initrd的ramdisk挂载到rootfs的/root目录，随后执行用户态程序/root/linuxrc加载最终根文件系统所需的驱动模块。内核文档Documentation/driver-api/early-userspace/early_userspace_support.rst说明了linuxrc程序的作用: some device and filesystem drivers built as modules and stored in an initrd. The initrd must contain a binary ‘/linuxrc’ which is supposed to load these driver modules. It is also possible to mount the final root filesystem via linuxrc and use the pivot_root syscall. The initrd is mounted and executed via prepare_namespace(). 最后调用mount_root挂载实际根文件系统，上述步骤完成之后，rootfs中的目录结构如下: 123456最终根文件系统不在/dev/ram/root //最终的根文件系统/root/initrd // initrd中的内容最终根文件系统在/dev/ram/root/old // initrd中的内容，也是最终的根文件系统 如果根文件系统在块设备上，mount_root调用mount_block_root完成文件系统的挂载： 123456789101112131415161718192021222324252627282930void __init mount_block_root(char *name, int flags)&#123; struct page *page = alloc_page(GFP_KERNEL); char *fs_names = page_address(page); if (root_fs_names) // 将内核启动项参数&quot;rootfstype=&quot;中的文件系统类型保存到fs_names num_fs = split_fs_names(fs_names, PAGE_SIZE, root_fs_names); else // 将系统中当前支持的文件系统类型保存到fs_names num_fs = list_bdev_fs_names(fs_names, PAGE_SIZE);... // root_mount_data保存内核启动项参数&quot;rootflags=&quot;设置的根文件系统选项 for (i = 0, p = fs_names; i &lt; num_fs; i++, p += strlen(p)+1) err = do_mount_root(name, p, flags, root_mount_data);...&#125;static int __init do_mount_root(const char *name, const char *fs, const int flags, const void *data)&#123;... // 将设备节点挂载到/root目录 ret = init_mount(name, &quot;/root&quot;, fs, flags, data_page); init_chdir(&quot;/root&quot;); s = current-&gt;fs-&gt;pwd.dentry-&gt;d_sb; // ROOT_DEV的设备即挂载设备 ROOT_DEV = s-&gt;s_dev;...&#125; Summary and example内核启动过程的initramfs阶段兼容了initrd启动方式，流程总结如下: 挂载rootfs 创建1号进程kernel_init，启动过程的initramfs阶段的初始化工作由1号进程完成 执行内核初始化函数populate_rootfs，解压initramfs至rootfs 若步骤3未配置initramfs，则认为使用的是legacy initrd，调用prepare_namespace通过initrd完成实际根文件系统的挂载 调用rootfs中的init程序完成后续初始化工作，并切换到用户空间，成为实际根文件系统的1号进程。由于initrd的过渡方式已经挂载实际根文件系统，此时执行的是实际根文件系统的init程序。而initramfs的过渡方式，执行的是initramfs中的init程序，还需要完成挂载实际根文件系统的工作。 解压CentOS8的initramfs，发现initramfs的init程序是systemd程序的软连接： 123456789$ mkdir -p ~/centos-initramfs &amp;&amp; cd ~/centos-initramfs$ /usr/lib/dracut/skipcpio initramfs-3.10.0-229.el7.x86_64.img | zcat | cpio -ivd$ llinit -&gt; usr/lib/systemd/systemd./usr/lib/systemd/system/default.target -&gt; initrd.targetsysroot/$ ll /usr/lib/systemd/system/default.target/usr/lib/systemd/system/default.target -&gt; graphical.target 下图[3]总结了systemd在启动阶段的工作： 实际根文件系统尚未挂载，相关的systemd程序以及target源于initramfs1.1. sysinit.target: 读系统环境做初始化1.2. basic.target: 完成早期开机自启动的初始化工作1.3. default.target是一个软链接，指向initrd.target，为后续切换到实际根文件系统做初始化准备1.4 将实际根文件系统挂载到/sysroot目录，将/sysroot目录挂载到当前的根目录，实际根文件系统完成挂载。exec实际根文件系统中的systemd，完成到用户空间进程的切换 实际根文件系统挂载后，执行的systemd及target源于根文件系统。同样会经历sysinit.target、basic.target阶段，不论是initramfs，还是根文件系统，这两个阶段都是为default.target阶段做准备。default.target也是个软链接,决定相应的“运行级别”，当前系统指向graphical.target表示进入的是图形终端。也可以指向multi-user.target进入无图形化终端[4]。 以 “.target” 为后缀的单元文件， 封装了一个由 systemd 管理的启动目标， 用于在启动过程中将一组单元汇聚到一个众所周知的同步点。 Reference[1] https://stackoverflow.com/questions/64877292/how-does-the-bootloader-pass-the-kernel-command-line-to-the-kernel[2] https://zhuanlan.zhihu.com/p/489819324[3] https://www.junmajinlong.com/linux/systemd/systemd_bootup/[4] https://unix.stackexchange.com/questions/404667/systemd-service-what-is-multi-user-target","categories":[{"name":"boot","slug":"boot","permalink":"https://system-thoughts.github.io/categories/boot/"}],"tags":[{"name":"boot","slug":"boot","permalink":"https://system-thoughts.github.io/tags/boot/"},{"name":"initramfs","slug":"initramfs","permalink":"https://system-thoughts.github.io/tags/initramfs/"}]},{"title":"Understanding gzip - Huffman coding","slug":"Understanding gzip - Huffman coding","date":"2022-03-07T06:37:32.000Z","updated":"2023-01-18T05:32:06.152Z","comments":true,"path":"posts/bbc4c4ba/","link":"","permalink":"https://system-thoughts.github.io/posts/bbc4c4ba/","excerpt":"DEFLATE算法首先通过LZ77算法对数据流压缩，压缩数据流中仅包含literal、length、distance三种类型的数据。","text":"DEFLATE算法首先通过LZ77算法对数据流压缩，压缩数据流中仅包含literal、length、distance三种类型的数据。 数据是通过字符表(alphabet)中的编码表示，如ASCII编码的纯文本文件中的数据都来源于ASCII字符表。字母表中的字符在计算机中以二进制形式存储，如ASCII表中的字符A的二进制编码是长度为1字节的1000001B。DEFLATE算法定义了两张字符表编码上述三种类型的数据：literal和length使用一张字符表，distance单独一张字符表。 alphabetliteral和length使用一张285个编码(codes)的字符表。(0..255)是literal的编码，直接使用ASCII编码。length的取值范围是(3..258)，使用(257..285)编码区间，字符256代表end-of-block，DEFLATE算法的压缩数据以block形式组织，end-of-block是block的结束标识。literal这种一一对应的编码很好理解，length的取值范围明显大于编码范围，详细看看DEFLATE算法如何编码length：DEFLATE将length的取值从(3..258)编码到(257..285)的编码范围，因此，一些length会共用同一编码。紧随编码之后的Extra bits解决了同一编码共享的问题。以length的取值11、12为例，它们共享同一编码265，如果编码265在计算机中以3-bit的二进制编码110B存储，则length 11的二进制编码是1100B,length 12的二进制编码是1101B。literal &amp; length字符表中，length越长，Extra bits越长；同时也意味着字符串匹配的长度越长，出现的概率越小。可见，DEFLATE算法在字符长度和计算复杂度之间做了trade off的。不过，285这个字符Extra bits长度为0，可能因为285作为DEFLATE算法规定的最大匹配长度，出现的概率也会更高。 distance的字符表如下所示，不再过多解释： Huffman coding字符表中的编码有两种二进制编码方式：定长(fixed-length)编码、变长(variable-length)编码。ASCII编码是定长编码，每个字符都用长度为1字节的二进制表示。定长编码具有明确易解析的优点，每读取一个字节的数据，便可解析(decode)得到相应的字符，如读取到1字节的数据1000001B，便可解析得到字符A。Huffman编码是变长编码的代表，基于字符实际出现的频次，出现频次高的字符的编码长度越短，反之则更长。Huffman编码要求所有编码具有prefix property：任一编码不能是另一更长编码的前缀。Huffman编码稍微复杂一些，但整体的编码长度更短。DEFLATE算法选择Huffman编码表示LZ77压缩数据。 DEFLATE算法将根据字符在LZ77编码字符流中出现的实际频次而构建的Huffman树，称为dynamic Huffman codes。dynamic Huffman codes模式下，两张字符表的字符Huffman编码预先是不确定的，而是在压缩过程中，读取LZ77压缩字符流、统计字符出现的实际频次而构建的。因此，需要将两张字符表的Huffman编码信息加入到最终的压缩数据流中，以便后续解压缩过程中的解码。fixed Huffman codes是DEFLATE算法预先定义的字符表的Huffman编码。 fixed Huffman codesfixed Huffman codes编码模式下，literal/length字符表、distance字符表的Huffman编码都是固定的，下图是literal &amp; length字符表的Huffman编码：distance字符表(0..29)使用固定长度的5-bit编码(编码范围：0-31)。到这，您可能会问fixed Huffman codes存在的意义？它并不是根据字符出现的实际频次而产生的Huffman编码，肯定不适用于任何输入数据集。前面我们提到dynamic Huffman code还需要将两张字符表对应的Huffman编码信息加入到压缩数据流以支持后续的解压操作。那么，待压缩的数据量较小时，dynamic Huffman codes编码会额外存储的这些metadata，从而比直接使用fixed Huffman codes的编码长度更长。 dynamic Huffman codesRun Length Encodingdynamic Huffman codes根据字符在LZ77压缩字符流中出现的实际频次，构建Huffman树、对字符Huffman编码。直接保存字符表中每个字符的Huffman编码会极度浪费空间，这让LZ77算法的压缩变得毫无意义。DEFLATE算法约束Huffman编码： 相同长度的Huffman编码在数值上是连续的，编码顺序与字符在字符表中的先后顺序保持一致 长度更短的Huffman编码，其编码值更小 如下的字符表只有四个字符：ABCD，字符表中的字符顺序以及相应的Huffman编码如表所示： Symbol Code A 10 B 110 C 0 D 111 字符B和字符D的Huffman编码长度都是3，两者的Huffman编码是连续的，且编码顺序与字符在字符表中出现的先后顺序保持一致。按照Huffman编码长度排序：0、10、110、111。长度更短的Huffman编码，其编码值也更小。若不考虑上述两个约定，字符表的字符在相同编码长度下，可以有多种编码，如ABCD的Huffman编码也可以是00、011、1、010。但是这种Huffman编码就未遵守上述约定。上述两个约定的目的是，仅通过Huffman编码长度(code length)便可以确定整个Huffman树。因此，ABCD字符表的Huffman编码可以使用(2,3,1,3)来表示。gzip通过build_tree对字符表中出现的字符Huffman编码： 按照字符表中的字符出现的频次构建Huffman树 调用gen_bitlen函数获取各出现字符的编码长度，如果节点超出MAX_BITS（15），调整节点的位置 调用gen_codes函数根据Huffman树中叶子节点的编码长度，遵循DEFLATE算法的Huffman编码约束进行编码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#define HEAP_SIZE (2*L_CODES+1)/* maximum heap size *local int near heap[2*L_CODES+1]; /* heap used to build the Huffman trees *//* =========================================================================== * Compares to subtrees, using the tree depth as tie breaker when * the subtrees have equal frequency. This minimizes the worst case length. */#define smaller(tree, n, m) \\ (tree[n].Freq &lt; tree[m].Freq || \\ (tree[n].Freq == tree[m].Freq &amp;&amp; depth[n] &lt;= depth[m]))local void build_tree(desc) tree_desc near *desc; /* the tree descriptor */&#123; ct_data near *tree = desc-&gt;dyn_tree; ct_data near *stree = desc-&gt;static_tree; int elems = desc-&gt;elems; int n, m; /* iterate over heap elements */ // 字符表中出现过的最大字符 int max_code = -1; /* largest code with non zero frequency */ int node = elems; /* next internal node of the tree */ heap_len = 0, heap_max = HEAP_SIZE; // heap数组中按照字符表中的字符顺序存储出现过的字符 for (n = 0; n &lt; elems; n++) &#123; if (tree[n].Freq != 0) &#123; heap[++heap_len] = max_code = n; depth[n] = 0; &#125; else &#123; // 忽略字符表中未出现的字符，Huffman编码长度为0，即未参与Huffman编码 tree[n].Len = 0; &#125; &#125; ... desc-&gt;max_code = max_code; /* The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree, * establish sub-heaps of increasing lengths: */ // 将heap构建为按照字符出现频次比较的小顶堆 for (n = heap_len/2; n &gt;= 1; n--) pqdownheap(tree, n); /* Construct the Huffman tree by repeatedly combining the least two * frequent nodes. */ do &#123; pqremove(tree, n); /* n = node of least frequency */ m = heap[SMALLEST]; /* m = node of next least frequency */ // m和n是Huffman树的兄弟节点 heap[--heap_max] = n; /* keep the nodes sorted by frequency */ heap[--heap_max] = m; /* Create a new node father of n and m */ tree[node].Freq = tree[n].Freq + tree[m].Freq; // 同Freq的中间节点和叶子节点，按照smaller比较，叶子节点比中间节点小 depth[node] = (uch) (MAX(depth[n], depth[m]) + 1); tree[n].Dad = tree[m].Dad = (ush)node;... /* and insert the new node in the heap */ heap[SMALLEST] = node++; pqdownheap(tree, SMALLEST); &#125; while (heap_len &gt;= 2); // heap[heap_max..HEAP_SIZE]包含了Huffman树的中间节点和叶子节点（字符表中的字符） heap[--heap_max] = heap[SMALLEST]; /* At this point, the fields freq and dad are set. We can now * generate the bit lengths. */ gen_bitlen((tree_desc near *)desc); /* The field len is now set, we can generate the bit codes */ gen_codes ((ct_data near *)tree, max_code);&#125; build_tree首先for循环调用pqdownheap完成小顶堆的堆化(heapify)操作，小顶堆中的字符是按照字符的频次排序的（详情见smaller宏）。随后的do-while循环完成Huffman树的构建。当前得到的是一棵“编码不明”的Huffman树，这里的“编码不明”指兄弟节点的左右顺序未确定，对Huffman树的叶子节点编码不是通过从根节点到叶子节点的路径所确定的。 gen_bitlen函数为了获取各出现字符的编码长度，因为最终字符的Huffman编码是根据字符的编码长度确定的。gen_bitlen函数会调整build_tree生成的Huffman树的编码过长(&gt; MAX_BITS)节点的位置。gen_bitlen还会统计dynamic Huffman codes编码之后的长度opt_len以及fixed Huffman codes编码后的长度static_len。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354local void gen_bitlen(desc) tree_desc near *desc; /* the tree descriptor */&#123;... for (bits = 0; bits &lt;= MAX_BITS; bits++) bl_count[bits] = 0; // root节点的Huffman编码长度为0，root节点是中间节点 tree[heap[heap_max]].Len = 0; /* root of the heap */ for (h = heap_max+1; h &lt; HEAP_SIZE; h++) &#123; n = heap[h]; bits = tree[tree[n].Dad].Len + 1; if (bits &gt; max_length) bits = max_length, overflow++; tree[n].Len = (ush)bits; if (n &gt; max_code) continue; /* not a leaf node */ bl_count[bits]++; xbits = 0; if (n &gt;= base) xbits = extra[n-base]; f = tree[n].Freq; // 以dynamic Huffman codes编码的编码长度 opt_len += (ulg)f * (bits + xbits); // 以fixed Huffman codes编码的编码长度 if (stree) static_len += (ulg)f * (stree[n].Len + xbits); &#125; if (overflow == 0) return; // 调整编码长度过长节点的位置 do &#123; bits = max_length-1; while (bl_count[bits] == 0) bits--; bl_count[bits]--; /* move one leaf down the tree */ bl_count[bits+1] += 2; /* move one overflow item as its brother */ bl_count[max_length]--; /* The brother of the overflow item also moves one step up, * but this does not affect bl_count[max_length] */ overflow -= 2; &#125; while (overflow &gt; 0); for (bits = max_length; bits != 0; bits--) &#123; n = bl_count[bits]; while (n != 0) &#123; m = heap[--h]; if (m &gt; max_code) continue; if (tree[m].Len != (unsigned) bits) &#123; // 调整overflow节点之后，根据实际编码长度重新计算dynamic Huffman codes编码长度 opt_len += ((long)bits-(long)tree[m].Len)*(long)tree[m].Freq; tree[m].Len = (ush)bits; &#125; n--; &#125; &#125;&#125; gen_bitlen函数最后的do-while循环和for循环完成超长节点的调整，其实现主要是调整bl_count数组和调整节点m的实际编码长度tree[m].Len。可见，build_tree最初生成的Huffman树确实是一棵“编码不明”的Huffman树，即无需确定叶子节点的具体位置（无法确定是左/右子节点），只要该节点的编码长度正确即可。下图展示了超长节点的调整过程： 字符表中字符出现的频率是(2, 3, 3, 4, 5, 7, 10)，为简化描述，后面用频次代指相应的编码 build_tree构建Huffman树后，节点的父子关系确定，各个节点的编码长度确定。假设当前的MAX_BITS=4，则叶子节点3、2超出了最大编码长度 gen_bitlen将超长编码2调整到和编码7所在同一层，那么编码7和编码2称为兄弟节点，则编码7要下移一层，原来编码7的位置变为中间节点。超长编码2的兄弟节点3，挪到其父节点的位置。因为，Huffman树的节点要么不存在子节点，要么就是两个子节点。所以移动完一个子节点，另一个子节点移动到父节点位置才符合Huffman编码，所以do-while循环是overflow -= 2。注意，前面描述的节点移动只是一个逻辑过程，代码中并未通过改变节点的Dad指代新的父节点，更不谈改变父节点的实际频次。因为后面的gen_codes仅关心节点的编码长度便可生成正确的Huffman编码，而不是实际的Huffman树长啥样，所以，我反复强调这颗Huffman树是一个“编码不明”的Huffman树 最后，gen_codes函数根据字符表的Huffman编码长度数组(code length sequence)对字符表进行Huffman编码，这个过程是RFC 1951, Section 3.2.2算法的实现。字符表中字符m的长度存储在tree[m].Len中，Huffman编码存储在tree[m].Code中。 1234567891011121314151617181920212223242526272829303132// bl_count[i]: Huffman编码长度为i的个数// tree[i].Code: 字符表中的字符i对应的Huffman编码// tree[i].Len: 字符表中的字符i对应的Huffman编码长度#define MAX_BITS 15/* All codes must not exceed MAX_BITS bits */// max_code是字符表中频次非0的最大字符，即max_code + 1至字符表最后一个字符在数据流中出现次数都为0local void gen_codes (tree, max_code) ct_data near *tree; /* the tree to decorate */ int max_code; /* largest code with non zero frequency */&#123; ush next_code[MAX_BITS+1]; /* next code value for each bit length */ ush code = 0; /* running code value */ int bits; /* bit index */ int n; /* code index */ // next_code[bits]是长度为bits的所有Huffman编码的第一个编码 for (bits = 1; bits &lt;= MAX_BITS; bits++) &#123; // 遵守约束2，bits+1的第一个编码 会是(bits的最后一个编码+1)的2倍 next_code[bits] = code = (code + bl_count[bits-1]) &lt;&lt; 1; &#125; ... for (n = 0; n &lt;= max_code; n++) &#123; int len = tree[n].Len; // 不对未出现的字符编码 if (len == 0) continue; /* Now reverse the bits */ // 遵守约束1 tree[n].Code = bi_reverse(next_code[len]++, len); ... &#125; &#125; 可以注意到，literal/length字符表、distance字符表的Huffman编码的最大长度是15。基于上述两个约束，可以通过字符表中各个字符的编码长度(code length)来表示整个字符表的Huffman编码。实际上，DEFLATE算法通过Run Length Encoding进一步编码code length数组。如字符表的code length数组是(5, 5, 5, 5, 6, 6, 6, 6, 6, 6)，经过RLE编码后的表示是((5,4),(6,6))，即code length 5连续出现4次，code length 6连续出现6次。DEFLATE算法将literal/length字符表、distance字符表的code length数组的REL编码保存到压缩数据流中以表示这两张字符表的Huffman编码。同样，REL编码也需要一张字符表来表示，REL编码有两种类型的数据： code length：Huffman编码长度，取值范围是(0..15) repeat times: code length重复次数 DEFLATE算法设计了REL编码的字符表： code extra bits meaning 0-15 0 code lengths of 0-15 16 2 Copy the previous code length 3 - 6 timesThe next 2 bits indicate repeat length(0 = 3, … , 3 = 6) 17 3 Repeat a code length of 0 for 3 - 10 times 18 7 Repeat a code length of 0 for 11 - 138 times 举个例子，8, 16(+2 bits 11), 16(+2 bits 10)会展开成12(1 + (3 + 3) + (3 + 2))个code length为8的数据流。code length为0表示literal/length字符表、distance字符表中的该字符未出现过，这个字符是不参与Huffman树构建的。 Huffman on RLE alphabet至此，literal/length、distance字符表中字符的Huffman编码可以使用两个RLE序列表示。上一节也给出了RLE编码的字符表，RLE字符表中的字符也是使用Huffman编码，和对literal/length、distance字符表中的字符进行Huffman编码一样。因此，DEFLATE也要将RLE字符表的Huffman编码加入到压缩数据流，以解析literal/length、distance字符表的Huffman编码的RLE序列表示。到这一步，DEFLATE算法貌似陷入了“无限循环”，其实不然，第一次Huffman编码，将literal/length、distance字符表中字符的Huffman编码以RLE序列表示，字符表的编码范围从(0..285)|(0..29)缩小到(0..18)。再对RLE字符表进行Huffman编码，编码范围会从(0..18)继续缩减。可见，第二次Huffman编码可以将字符表的编码范围缩短的更小，因此就没有无限“套娃”的必要了！DEFLATE算法规定对RLE字符表的字符的最大Huffman编码长度限制为7。因此，对RLE字符表进行性Huffman编码得到的code length序列的取值范围为(0..7)，DEFLATE使用固定长度的3-bit编码表示这些code length。这里，DEFLATE算法对于RLE字符表的字符排序做了优化，RLE字符表中的字符并非按照(0..18)顺序排序，而是实际分析RLE字符表中字符出现的频率，按照出现频率从高往低排序。DEFLATE算法规定RLE字符表的字符实际顺序：(16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15)。这个优化可以缩短RLE字符表的code length数组长度，如literal/length、distance字符表的两个RLE序列中所有REL字符在REL字符表中的最大索引（max index）是REL字符13所在的位置。则2, 14, 1, 15不需要出现在RLE字符表的code length数组中，可以参考前面介绍gen_codes函数的max_code参数的意义。我只能感叹，DEFLATE算法为了极致压缩，有太多trick了！！ 所以，前面提及的dynamic Huffman codes的”metadata”包含： RLE字符表对应的Huffman编码，以code length数组表示 literal/length、distance字符表的Huffman编码，以REL序列表示 Implementation Details ct_init初始化全局变量base_length、length_code、base_dist、dist_code方便length、distance与literal/length、distance字符表中的编码进行相互转换，同时完成literal &amp; length字符表的fixed huffman编码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#define LENGTH_CODES 29/* number of length codes, not counting the special END_BLOCK code */#define LITERALS 256/* number of literal bytes 0..255 */#define L_CODES (LITERALS+1+LENGTH_CODES)/* number of Literal or Length codes, including the END_BLOCK code */#define D_CODES 30/* number of distance codes */local int near extra_lbits[LENGTH_CODES] /* extra bits for each length code */ = &#123;0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0&#125;;local int near extra_dbits[D_CODES] /* extra bits for each distance code */ = &#123;0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13&#125;;/* Data structure describing a single value and its code string. */typedef struct ct_data &#123; union &#123; ush freq; /* frequency count */ ush code; /* bit string */ &#125; fc; union &#123; ush dad; /* father node in Huffman tree */ ush len; /* length of bit string */ &#125; dl;&#125; ct_data;local ct_data near static_ltree[L_CODES+2];/* The static literal tree. Since the bit lengths are imposed, there is no * need for the L_CODES extra codes used during heap construction. However * The codes 286 and 287 are needed to build a canonical tree (see ct_init * below). */local ct_data near static_dtree[D_CODES];/* The static distance tree. (Actually a trivial tree since all codes use * 5 bits.) */local uch length_code[MAX_MATCH-MIN_MATCH+1];/* length code for each normalized match length (0 == MIN_MATCH) */local uch dist_code[512];/* distance codes. The first 256 values correspond to the distances * 3 .. 258, the last 256 values correspond to the top 8 bits of * the 15 bit distances. */local int near base_length[LENGTH_CODES];/* First normalized length for each code (0 = MIN_MATCH) */local int near base_dist[D_CODES];/* First normalized distance for each code (0 = distance of 1) */void ct_init(attr, methodp) ush *attr; /* pointer to internal file attribute */ int *methodp; /* pointer to compression method */&#123;... if (static_dtree[0].Len != 0) return; /* ct_init already called */ /* Initialize the mapping length (0..255) -&gt; length code (0..28) */ // base_length[i]：literal/length字符表中的第i个length code表示范围的第一个length // length_code[i]: 长度i在literal/length字符表对应的length code的顺序 length = 0; for (code = 0; code &lt; LENGTH_CODES-1; code++) &#123; base_length[code] = length; for (n = 0; n &lt; (1&lt;&lt;extra_lbits[code]); n++) &#123; length_code[length++] = (uch)code; &#125; &#125;... length_code[length-1] = (uch)code; // dist_code[i]: 距离i属于(0..255)时,dist_code[i]表示distance字符表中的distance code，范围是(0..15) // 当i属于(256..511)时，每个i代表128个distance数据，如dist_code[258] = 16 dist_code[259] = 16 // dist_code[260] = 18 dist_code[260] = 18；因为编码16、17的distance数据有128个，编码18的distance数据有256个；dist_code的256和257索引预留 /* Initialize the mapping dist (0..32K) -&gt; dist code (0..29) */ dist = 0; for (code = 0 ; code &lt; 16; code++) &#123; base_dist[code] = dist; for (n = 0; n &lt; (1&lt;&lt;extra_dbits[code]); n++) &#123; dist_code[dist++] = (uch)code; &#125; &#125; Assert (dist == 256, &quot;ct_init: dist != 256&quot;); dist &gt;&gt;= 7; /* from now on, all distances are divided by 128 */ for ( ; code &lt; D_CODES; code++) &#123; base_dist[code] = dist &lt;&lt; 7; for (n = 0; n &lt; (1&lt;&lt;(extra_dbits[code]-7)); n++) &#123; dist_code[256 + dist++] = (uch)code; &#125; &#125; Assert (dist == 256, &quot;ct_init: 256+dist != 512&quot;); /* Construct the codes of the static literal tree */ // 将literal/length字符表的fixed huffman code通过code length sequence表示 for (bits = 0; bits &lt;= MAX_BITS; bits++) bl_count[bits] = 0; n = 0; while (n &lt;= 143) static_ltree[n++].Len = 8, bl_count[8]++; while (n &lt;= 255) static_ltree[n++].Len = 9, bl_count[9]++; while (n &lt;= 279) static_ltree[n++].Len = 7, bl_count[7]++; while (n &lt;= 287) static_ltree[n++].Len = 8, bl_count[8]++; /* Codes 286 and 287 do not exist, but we must include them in the * tree construction to get a canonical Huffman tree (longest code * all ones) */ // 对literal/length字符表进行Huffman编码 gen_codes((ct_data near *)static_ltree, L_CODES+1); // distance字符表的固定编码使用5-bit长度的顺序编码 for (n = 0; n &lt; D_CODES; n++) &#123; static_dtree[n].Len = 5; static_dtree[n].Code = bi_reverse(n, 5); &#125; /* Initialize the first block of the first file: */ init_block();&#125; ct_tally统计literal &amp; length字符表中literal、length字符出现的频率，并将literal、length保存到l_buf中；统计distance字符表中的distance字符出现的频率，并将distance保存到d_buf中，其中一个buffer满时，将两个buffer中保存的LZ77压缩字符流组织成block压缩块。l_buf、d_buf保存literal、length、distance的方式在随后介绍compress_block函数会详细讲解。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950local ct_data near dyn_ltree[HEAP_SIZE]; /* literal and length tree */local ct_data near dyn_dtree[2*D_CODES+1]; /* distance tree */// 完成distance到distance字符表中的code映射#define d_code(dist) \\ ((dist) &lt; 256 ? dist_code[dist] : dist_code[256+((dist)&gt;&gt;7)])/* Mapping from a distance to a distance code. dist is the distance - 1 and * must not have side effects. dist_code[256] and dist_code[257] are never * used. */// 编码literal: dist = 0, lc = literal// 编码&lt;length, distance&gt;: dist = distance, lc = length - MIN_MATCHint ct_tally (dist, lc) int dist; /* distance of matched string */ int lc; /* match length-MIN_MATCH or unmatched char (if dist==0) */&#123; // l_buf保存literal、length l_buf[last_lit++] = (uch)lc; if (dist == 0) &#123; /* lc is the unmatched char */ // 统计literal/length字符表中相应的literal code出现频率 dyn_ltree[lc].Freq++; &#125; else &#123; /* Here, lc is the match length - MIN_MATCH */ dist--; /* dist = match distance - 1 */ Assert((ush)dist &lt; (ush)MAX_DIST &amp;&amp; (ush)lc &lt;= (ush)(MAX_MATCH-MIN_MATCH) &amp;&amp; (ush)d_code(dist) &lt; (ush)D_CODES, &quot;ct_tally: bad match&quot;); // 统计literal/length字符表中相应的length code出现频率 dyn_ltree[length_code[lc]+LITERALS+1].Freq++; // 统计distance字符表中相应的distance code出现频率 dyn_dtree[d_code(dist)].Freq++; // d_buf保存distance d_buf[last_dist++] = (ush)dist; flags |= flag_bit; &#125; flag_bit &lt;&lt;= 1; /* Output the flags if they fill a byte: */ if ((last_lit &amp; 7) == 0) &#123; flag_buf[last_flags++] = flags; flags = 0, flag_bit = 1; &#125; ... return (last_lit == LIT_BUFSIZE-1 || last_dist == DIST_BUFSIZE);&#125; flush_block完成整个block的编码 调用build_tree完成对literal &amp; length字符表、distance字符表Huffman编码。 调用build_bl_tree对literal &amp; length字符表、distance字符表的Huffman编码的REL表示所在的REL字符表进行Huffman编码 根据情况判断是直接将数据未经压缩输出还是以不同type的block形式输出 no compression block：调用copy_block直接输出数据 compressed with fixed Huffman codes：compress_block根据static Huffman tree对LZ77压缩数据进行Huffman编码 compressed with dynamic Huffman codes：send_all_trees将REL字符表的code length sequence、literal &amp; length字符表、distance字符表的Huffman编码的REL序列输出；compress_block根据dynamic Huffman tree对LZ77压缩数据编码 调用init_block初始化下一block DEFLATE算法规定block有3bit的头部信息： first bit: BFINAL(last block set) next 2 bits: BTYPE BTYPE表示block的压缩类型： 00 - no compression 01 - compressed with fixed Huffman codes 10 - compressed with dynamic Huffman codes 11 - reserved (error) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#define FLUSH_BLOCK(eof) \\ flush_block(block_start &gt;= 0L ? (char*)&amp;window[(unsigned)block_start] : \\ (char*)NULL, (long)strstart - block_start, flush-1, (eof))off_t flush_block(buf, stored_len, pad, eof) char *buf; /* input block, or NULL if too old */ ulg stored_len; /* length of input block */ int pad; /* pad output to byte boundary */ int eof; /* true if this is the last block for a file */&#123; ulg opt_lenb, static_lenb; /* opt_len and static_len in bytes */ int max_blindex; /* index of last bit length code of non zero freq */ flag_buf[last_flags] = flags; /* Save the flags for the last 8 items */ /* Check if the file is ascii or binary */ if (*file_type == (ush)UNKNOWN) set_file_type(); /* Construct the literal and distance trees */ build_tree((tree_desc near *)(&amp;l_desc)); build_tree((tree_desc near *)(&amp;d_desc)); // 对literal|length字符表以及distance字符表的REL编码的REL字符表进行Huffman编码，max_blindex是出现过自大的REL字符的索引 max_blindex = build_bl_tree(); // 3 header bits + 7 = (8 - 1)，(x + 7) &gt;&gt; 3表示容纳x bit需要多少字节 opt_lenb = (opt_len+3+7)&gt;&gt;3; static_lenb = (static_len+3+7)&gt;&gt;3; input_len += stored_len; /* for debugging only */ if (static_lenb &lt;= opt_lenb) opt_lenb = static_lenb; /* If compression failed and this is the first and last block, * and if we can seek through the zip file (to rewrite the local header), * the whole file is transformed into a stored file: */ // 整个文件都是未经压缩处理的文件，即stored file if (stored_len &lt;= opt_lenb &amp;&amp; eof &amp;&amp; compressed_len == 0L &amp;&amp; seekable()) &#123; ... // 相比下一个if分支，它都不是以block形式组织数据，直接将数据原样输出 copy_block(buf, (unsigned)stored_len, 0); /* without header */ compressed_len = stored_len &lt;&lt; 3; *file_method = STORED; &#125; else if (stored_len+4 &lt;= opt_lenb &amp;&amp; buf != (char*)0) &#123; // 4: LEN + NLEN // 当前block未经压缩，即00(no compress) send_bits((STORED_BLOCK&lt;&lt;1)+eof, 3); /* send block type */ compressed_len = (compressed_len + 3 + 7) &amp; ~7L; compressed_len += (stored_len + 4) &lt;&lt; 3; copy_block(buf, (unsigned)stored_len, 1); /* with header */ &#125; else if (static_lenb == opt_lenb) &#123; // block使用Fixed Huffman codes编码 send_bits((STATIC_TREES&lt;&lt;1)+eof, 3); compress_block((ct_data near *)static_ltree, (ct_data near *)static_dtree); compressed_len += 3 + static_len; &#125; else &#123; // block使用dynamic Huffman codes编码 send_bits((DYN_TREES&lt;&lt;1)+eof, 3); send_all_trees(l_desc.max_code+1, d_desc.max_code+1, max_blindex+1); compress_block((ct_data near *)dyn_ltree, (ct_data near *)dyn_dtree); compressed_len += 3 + opt_len; &#125; Assert (compressed_len == bits_sent, &quot;bad compressed size&quot;); init_block(); if (eof) &#123; Assert (input_len == bytes_in, &quot;bad input size&quot;); bi_windup(); compressed_len += 7; /* align on byte boundary */ &#125; else if (pad &amp;&amp; (compressed_len % 8) != 0) &#123; send_bits((STORED_BLOCK&lt;&lt;1)+eof, 3); /* send block type */ compressed_len = (compressed_len + 3 + 7) &amp; ~7L; copy_block(buf, 0, 1); /* with header */ &#125; return compressed_len &gt;&gt; 3;&#125; 3.1 build_bl_tree首先调用scan_tree扫描literal &amp; length、distance字符表的Run Length Encoding得到REL字符表的字符出现频次(bl_tree[m].Freq)。随后调用build_tree对REL字符表进行Huffman编码。并返回Huffman编码长度不为0的REL字符在RLE字符表中的最大索引max_blindex。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162local void scan_tree (tree, max_code) ct_data near *tree; /* the tree to be scanned */ int max_code; /* and its largest code of non zero frequency */&#123; int n; /* iterates over all tree elements */ int prevlen = -1; /* last emitted length */ int curlen; /* length of current code */ int nextlen = tree[0].Len; /* length of next code */ int count = 0; /* repeat count of the current code */ int max_count = 7; /* max repeat count */ int min_count = 4; /* min repeat count */ if (nextlen == 0) max_count = 138, min_count = 3; tree[max_code+1].Len = (ush)0xffff; /* guard */ for (n = 0; n &lt;= max_code; n++) &#123; curlen = nextlen; nextlen = tree[n+1].Len; if (++count &lt; max_count &amp;&amp; curlen == nextlen) &#123; continue; &#125; else if (count &lt; min_count) &#123; bl_tree[curlen].Freq += count; &#125; else if (curlen != 0) &#123; if (curlen != prevlen) bl_tree[curlen].Freq++; bl_tree[REP_3_6].Freq++; &#125; else if (count &lt;= 10) &#123; bl_tree[REPZ_3_10].Freq++; &#125; else &#123; bl_tree[REPZ_11_138].Freq++; &#125; count = 0; prevlen = curlen; if (nextlen == 0) &#123; max_count = 138, min_count = 3; &#125; else if (curlen == nextlen) &#123; max_count = 6, min_count = 3; &#125; else &#123; max_count = 7, min_count = 4; &#125; &#125;&#125;local int build_bl_tree()&#123; int max_blindex; /* index of last bit length code of non zero freq */ /* Determine the bit length frequencies for literal and distance trees */ scan_tree((ct_data near *)dyn_ltree, l_desc.max_code); scan_tree((ct_data near *)dyn_dtree, d_desc.max_code); /* Build the bit length tree: */ build_tree((tree_desc near *)(&amp;bl_desc)); /* opt_len now includes the length of the tree representations, except * the lengths of the bit lengths codes and the 5+5+4 bits for the counts. */ // max_blindex: REL字符表中Huffman编码长度不为0的最大字符在RLE字符表中的索引 for (max_blindex = BL_CODES-1; max_blindex &gt;= 3; max_blindex--) &#123; if (bl_tree[bl_order[max_blindex]].Len != 0) break; &#125; /* Update opt_len to include the bit length tree and counts */ opt_len += 3*(max_blindex+1) + 5+5+4; return max_blindex;&#125; 3.2 send_all_trees首先填充dynamic Huffman codes编码的block要求的头部bits，下表是dynamic Huffman codes编码的block格式。随后调用send_tree将literal &amp; length字符表Huffman编码的REL表示以及distance字符表Huffman编码的REL表示输出到block中。 length Meaning 5bits HLIT(literal &amp; length max code + 1) - 257 5bits HDIST(distance max code + 1) - 1 4bits HCLEN(REL max code index + 1) - 4 (HCLEN + 4) x 3 bits REL字符表的Huffman编码的code length sequence表示，每个code length以固定3bit表示 (HLIT + 257) 编码个数 literal &amp; length字符表Huffman编码的REL表示 (HDIST + 1) 编码个数 distance字符表Huffman编码的REL表示 LZ77压缩数据使用literal&amp;length字符表、distance字符表的Huffman编码 The literal/length symbol 256 (end of data) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071local uch near bl_order[BL_CODES] = &#123;16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15&#125;;local void send_tree (tree, max_code) ct_data near *tree; /* the tree to be scanned */ int max_code; /* and its largest code of non zero frequency */&#123; int n; /* iterates over all tree elements */ int prevlen = -1; /* last emitted length */ int curlen; /* length of current code */ int nextlen = tree[0].Len; /* length of next code */ int count = 0; /* repeat count of the current code */ int max_count = 7; /* max repeat count */ int min_count = 4; /* min repeat count */ /* tree[max_code+1].Len = -1; */ /* guard already set */ if (nextlen == 0) max_count = 138, min_count = 3; for (n = 0; n &lt;= max_code; n++) &#123; curlen = nextlen; nextlen = tree[n+1].Len; if (++count &lt; max_count &amp;&amp; curlen == nextlen) &#123; continue; &#125; else if (count &lt; min_count) &#123; // code length的重复没有达到最小重复次数要求，将code length以REL字符表中的(0-15)的Huffman编码输出 do &#123; send_code(curlen, bl_tree); &#125; while (--count != 0); &#125; else if (curlen != 0) &#123; // 当前重复的code length和之前的code length不同，则先输出code length if (curlen != prevlen) &#123; send_code(curlen, bl_tree); count--; &#125; Assert(count &gt;= 3 &amp;&amp; count &lt;= 6, &quot; 3_6?&quot;); // 随后输出编码REP_3_6 Huffman编码，以及2bit的重复次数 send_code(REP_3_6, bl_tree); send_bits(count-3, 2); &#125; else if (count &lt;= 10) &#123; // code length 0重复3-10次，输出REPZ_3_10 Huffman编码，以及3bit的重复次数 send_code(REPZ_3_10, bl_tree); send_bits(count-3, 3); &#125; else &#123; // code length 0重复11-128次，输出REPZ_11_138 Huffman编码，以及7bit的重复次数 send_code(REPZ_11_138, bl_tree); send_bits(count-11, 7); &#125; count = 0; prevlen = curlen; if (nextlen == 0) &#123; max_count = 138, min_count = 3; &#125; else if (curlen == nextlen) &#123; max_count = 6, min_count = 3; &#125; else &#123; max_count = 7, min_count = 4; &#125; &#125;&#125;local void send_all_trees(lcodes, dcodes, blcodes) int lcodes, dcodes, blcodes; /* number of codes for each tree */&#123; int rank; /* index in bl_order */ // 存在至少长度为3的length编码；存在至少距离为2的distance编码；存在至少长度为为4的code length REL编码 Assert (lcodes &gt;= 257 &amp;&amp; dcodes &gt;= 1 &amp;&amp; blcodes &gt;= 4, &quot;not enough codes&quot;); Assert (lcodes &lt;= L_CODES &amp;&amp; dcodes &lt;= D_CODES &amp;&amp; blcodes &lt;= BL_CODES, &quot;too many codes&quot;); // HLIT HDIST HCLEN send_bits(lcodes-257, 5); /* not +255 as stated in appnote.txt */ send_bits(dcodes-1, 5); send_bits(blcodes-4, 4); /* not -3 as stated in appnote.txt */ // REL字符表Huffman编码的code length sequence表示 for (rank = 0; rank &lt; blcodes; rank++) &#123; send_bits(bl_tree[bl_order[rank]].Len, 3); &#125; send_tree((ct_data near *)dyn_ltree, lcodes-1); /* send the literal tree */ send_tree((ct_data near *)dyn_dtree, dcodes-1); /* send the distance tree */&#125; 3.3 compress_block对LZ77算法压缩的字符流进行Huffman编码。literal &amp; length字符流保存在l_buf中，使用ltree中字符的Huffman编码进行编码，distance字符流保存在d_buf中，使用dtree中字符的Huffman编码进行编码。对字符流中所有字符Huffman编码完成后，加上END_BLOCK的Huffman编码，标志该block结束。 123456789101112131415161718192021222324252627282930313233343536373839404142434445local void compress_block(ltree, dtree) ct_data near *ltree; /* literal tree */ ct_data near *dtree; /* distance tree */&#123; unsigned dist; /* distance of matched string */ int lc; /* match length or unmatched char (if dist == 0) */ unsigned lx = 0; /* running index in l_buf */ unsigned dx = 0; /* running index in d_buf */ unsigned fx = 0; /* running index in flag_buf */ uch flag = 0; /* current flags */ unsigned code; /* the code to send */ int extra; /* number of extra bits to send */ if (last_lit != 0) do &#123; if ((lx &amp; 7) == 0) flag = flag_buf[fx++]; lc = l_buf[lx++]; if ((flag &amp; 1) == 0) &#123; send_code(lc, ltree); /* send a literal byte */ Tracecv(isgraph(lc), (stderr,&quot; &#x27;%c&#x27; &quot;, lc)); &#125; else &#123; /* Here, lc is the match length - MIN_MATCH */ code = length_code[lc]; send_code(code+LITERALS+1, ltree); /* send the length code */ extra = extra_lbits[code]; if (extra != 0) &#123; lc -= base_length[code]; send_bits(lc, extra); /* send the extra length bits */ &#125; dist = d_buf[dx++]; /* Here, dist is the match distance - 1 */ code = d_code(dist); Assert (code &lt; D_CODES, &quot;bad d_code&quot;); send_code(code, dtree); /* send the distance code */ extra = extra_dbits[code]; if (extra != 0) &#123; dist -= base_dist[code]; send_bits(dist, extra); /* send the extra distance bits */ &#125; &#125; /* literal or match pair ? */ flag &gt;&gt;= 1; &#125; while (lx &lt; last_lit); // 使用ltree字符表的Huffman编码，编码END_BLOCK send_code(END_BLOCK, ltree);&#125; 以LZ77压缩的字符流a(3,4)cd(4,7)bef为例，相应的数值(字符使用ASCII编码表示)是97,3,4,99,100,4,7,98,101,102。实际存储在flag_buf和d_buf中的数据(见ct_tally的调用点)是97,3-3,4,99,100,4-3,7,98,101,102即97,0,4,99,100,1,7,98,101,102。下图展示了字符流在l_buf和d_buf中的存储：l_buf存储了literal和length - 3，以字节为单位存储。为了区分l_buf中的literal和length，使用flag_buf中的flagbit位区分。bit位为0，代表l_buf相应位置存储的是literal，若为1，则存储的是length。因此每处理完l_buf中的1个字符，flag要向右移动一位；每处理完l_buf中的8个字符，需要读取flag_buf中的下一个flag。 3.4 init_block为新的block做初始化工作： 12345678910111213141516local void init_block()&#123; int n; /* iterates over tree elements */ // 初始化literal&amp;length、distance、REL字符表字符的频次为0 for (n = 0; n &lt; L_CODES; n++) dyn_ltree[n].Freq = 0; for (n = 0; n &lt; D_CODES; n++) dyn_dtree[n].Freq = 0; for (n = 0; n &lt; BL_CODES; n++) bl_tree[n].Freq = 0; dyn_ltree[END_BLOCK].Freq = 1; // 初始化dynamic Huffman codes、static Huffman codes编码长度为0 opt_len = static_len = 0L; // 将l_buf、d_buf、flag_buf的索引重置 last_lit = last_dist = last_flags = 0; flags = 0; flag_bit = 1; &#125; SummaryDEFLATE算法的Huffman编码的压缩过程可以用下图表示： 统计LZ77算法压缩数据流中literal、length出现的频次，构建literal &amp; length字符表的Huffman树，并以RLE表示；同样得到distance字符表的Huffman编码的RLE表示 统计literal &amp; length字符表、distance字符表Huffman编码的RLE表示中RLE字符出现的频次，构建RLE字符表的Huffman树，得到RLE字符表Huffman编码的code length sequence表示 将第2步的code length sequence以固定3bit编码输出到压缩数据流中；将第1步的2个RLE以第2步得到的REL字符表Huffman编码进行编码，并输出到压缩数据流中 将LZ77算法压缩数据流中的所有字符以第1步得到的两个字符表的Huffman编码进行编码，并输出到压缩数据流中","categories":[{"name":"Base Service","slug":"base-service","permalink":"https://system-thoughts.github.io/categories/base-service/"}],"tags":[{"name":"gzip","slug":"gzip","permalink":"https://system-thoughts.github.io/tags/gzip/"},{"name":"deflate","slug":"deflate","permalink":"https://system-thoughts.github.io/tags/deflate/"}]},{"title":"Understanding gzip - LZ77","slug":"Understanding gzip - LZ77","date":"2022-03-02T11:34:59.000Z","updated":"2023-01-18T05:32:06.156Z","comments":true,"path":"posts/fb8cd772/","link":"","permalink":"https://system-thoughts.github.io/posts/fb8cd772/","excerpt":"gzip是一种压缩格式也是类Unix上的文件压缩/解压缩软件，通常指GNU计划的实现，此处gzip代表GNU zip。gzip文件格式在RFC 1952 GZIP file format specification version 4.3中标准化，gzip基于DEFLATE算法实现数据压缩，DEFLATE算法在RFC 1951 DEFLATE Compressed Data Format Specification version 1.3中标准化。","text":"gzip是一种压缩格式也是类Unix上的文件压缩/解压缩软件，通常指GNU计划的实现，此处gzip代表GNU zip。gzip文件格式在RFC 1952 GZIP file format specification version 4.3中标准化，gzip基于DEFLATE算法实现数据压缩，DEFLATE算法在RFC 1951 DEFLATE Compressed Data Format Specification version 1.3中标准化。 DEFLATE算法基于LZ77算法和Huffman编码实现流数据压缩。LZ77算法是Abraham Lempel和Jacob Ziv于1977年发布的无损数据压缩算法。LZ77算法是字典压缩算法的一种。字典是encoder维护的包含一组字符串的数据结构，字典压缩过程中，encoder将待压缩的文本在字典中搜索匹配字符串，若找到匹配，则将当前待压缩的字符串用字典中匹配字符串的位置索引来替代，达到缩减数据的效果。LZ77算法的字典是encoder之前已经编码的字节序列。 LZ77算法基本原理LZ77算法利用文本中字符串具有重复的特点，将后续重复出现的字符串使用&lt;length, distance&gt;二元组表示，length表示匹配字符串的长度，distance表示到之前出现的相同字符串的距离。文本中的重复字符串越多、重复字符串长度越长，LZ77算法则会取得更好的压缩效果。如下图所示，LZ77算法基于滑动窗口实现。滑动窗口包含两部分：前半部分是已经编码的字符流，称为字典或者search buffer；后半部分是待编码的字符流，称为look-ahead buffer。LZ77算法编码look-ahead buffer中的字符时，会在search buffer中寻找最长匹配字符串，若无匹配则直接输出字符(literal)，若存在匹配字符串，则将匹配字符串通过&lt;length, distance&gt;编码。DEFLATE算法规定匹配字符串的长度范围是[3, 258]。这个范围是压缩率和算法的时间复杂度之间的平衡。 由图可知，LZ77编码的字符流仅包含三种类型的数据：literal、length、distance。实际上，look-ahead buffer长度小于MIN_LOOKAHEAD时，滑动窗口便会向前移动以填充后续数据流从而扩大look-ahead buffer。上图所示look-ahead buffer被匹配完的情况只有在滑动窗口到达字节流末尾，无法向前滑动时出现。fill_window函数表示滑动窗口的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#define WSIZE 0x8000#define MAX_DIST (WSIZE-MIN_LOOKAHEAD)#define EOF (-1)static ulg window_size = (ulg)2*WSIZE; unsigned near strstart; /* start of string to insert */local unsigned near match_start; /* start of matching string */local int eofile; /* flag set at end of input file */local unsigned lookahead; /* number of valid bytes ahead in window */long block_start;/* window position at the beginning of the current output block. Gets * negative when the window is moved backwards. */local void fill_window()&#123; register unsigned n, m; //当strstart遍历完滑动窗口时，more = EOF；否则more = 0 unsigned more = (unsigned)(window_size - (ulg)lookahead - (ulg)strstart); if (more == (unsigned)EOF) &#123; more--; &#125; else if (strstart &gt;= WSIZE+MAX_DIST) &#123; // strstart仍在滑动窗口内部，lookahead &lt; MIN_LOOKAHEAD // 滑动窗口向前移动WSIZE memcpy((char*)window, (char*)window+WSIZE, (unsigned)WSIZE); match_start -= WSIZE; strstart -= WSIZE; /* we now have strstart &gt;= MAX_DIST: */ ... block_start -= (long) WSIZE; // 更新Search buffer中的hash表 for (n = 0; n &lt; HASH_SIZE; n++) &#123; m = head[n]; head[n] = (Pos)(m &gt;= WSIZE ? m-WSIZE : NIL); &#125; for (n = 0; n &lt; WSIZE; n++) &#123; m = prev[n]; prev[n] = (Pos)(m &gt;= WSIZE ? m-WSIZE : NIL); &#125; more += WSIZE; &#125; /* At this point, more &gt;= 2 */ if (!eofile) &#123; n = read_buf((char*)window+strstart+lookahead, more); if (n == 0 || n == (unsigned)EOF) &#123; eofile = 1; /* Don&#x27;t let garbage pollute the dictionary. */ memzero (window + strstart + lookahead, MIN_MATCH - 1); &#125; else &#123; lookahead += n; &#125; &#125; &#125; 主要解释下几个全局变量： window_size：滑动窗口大小，默认为64KB lookahead: look-ahead buffer大小 strstart: 当前待编码的字符在滑动窗口中的位置 当lookahead &lt; MIN_LOOKAHEAD &amp;&amp; !eofile时会调用fill_window更新滑动窗口。会将滑动窗口向前移动WSIZE，并更新match_start、strstart、block_start以及search buffer中的Hash表中hash chain上的索引。DEFLATE算法使用hash表优化匹配字符串的查找，hash表的实现会在最后介绍。最后从字符流中读入数据填充到滑动窗口的后半部分：window+strstart+lookahead起始位置。 惰性匹配（lazy matching）上图所示的LZ77算法并非最优压缩，当strstart = 8，look-ahead buffer中的内容为abcda时，即便abc在search buffer中能找到匹配字符串，但是紧邻的bcda可以在search buffer中找到更长的匹配串，得到的编码结果是abcda(3,3)a(4,8)。DEFLATE针对这种情况，设计了惰性匹配（lazy matching）的优化机制：当前匹配的字符串长度为N(N &gt;= MIN_MATCH)，会尝试在下一个字符寻找更长的匹配，若在下一个字符能找到更长的匹配(&gt; N)，则将前一个字符直接输出到编码流中，即literal；重复这一过程直至找不到更长的字符串匹配，则将前一个字符找到的匹配以&lt;length, distance&gt;二元组输出到编码流中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879local unsigned int near prev_length;/* Length of the best match at previous step. Matches not greater than this * are discarded. This is used in the lazy match evaluation. */local unsigned int max_lazy_match;/* Attempt to find a better match only when the current match is strictly * smaller than this value. This mechanism is used only for compression * levels &gt;= 4. */off_tdeflate (int pack_level)&#123;... /* Process the input block. */ while (lookahead != 0) &#123; // 将字符串window[strstart .. strstart+2]插入到hash表 INSERT_STRING(strstart, hash_head); /* Find the longest match, discarding those &lt;= prev_length. */ prev_length = match_length, prev_match = match_start; match_length = MIN_MATCH-1; // search buffer中存在匹配字符串；lazy match过程中之前的最长匹配字符串长度 &lt; max_lazy_match； // 当前字符与匹配字符串之间的距离 &lt;= MAX_DIST if (hash_head != NIL &amp;&amp; prev_length &lt; max_lazy_match &amp;&amp; strstart - hash_head &lt;= MAX_DIST &amp;&amp; strstart &lt;= window_size - MIN_LOOKAHEAD) &#123; // 通过hash表，找到当前字符串的最长匹配字符串 match_length = longest_match (hash_head); // 如果匹配的字符串长度超过look-ahead buffer大小，则将匹配字符串的长度设置为lookahead if (match_length &gt; lookahead) match_length = lookahead; ... &#125; // lazy match结束，strstart-1存在有效匹配，但是strstart的匹配长度 &lt;= strstart-1的最长匹配长度 if (prev_length &gt;= MIN_MATCH &amp;&amp; match_length &lt;= prev_length) &#123; // double check，确认strstart-1的匹配无误 check_match(strstart-1, prev_match, prev_length); // 将strstart-1字符以&lt;length, distance&gt;编码 flush = ct_tally(strstart-1-prev_match, prev_length - MIN_MATCH); // 因为这里用的是前一个字符的匹配，到当前字符匹配时lookahead已经-1，所以此处是-(prev_length-1) lookahead -= prev_length-1; // strstart-1以及strstart开始的字符串已经插入到hash表中，所以不需要对这两个字符开始的字符串求hash prev_length -= 2; // 求匹配字符串中每个字符开始的长度为3的字符串的hash值 do &#123; strstart++; INSERT_STRING(strstart, hash_head); &#125; while (--prev_length != 0); // 不存在前一个字符的匹配，开始lazy match的最开始匹配 match_available = 0; match_length = MIN_MATCH-1; strstart++; ... if (flush) FLUSH_BLOCK(0), block_start = strstart; &#125; else if (match_available) &#123; // lazy match过程中存在有效的前一个字符匹配的字符串，当前字符串匹配更长；或者前一个字符在search buffer中无匹配的字符串 // 将strstart-1字符以literal编码 flush = ct_tally (0, window[strstart-1]); ... if (flush) FLUSH_BLOCK(0), block_start = strstart; strstart++; lookahead--; &#125; else &#123; // search buffer中无匹配的字符串 match_available = 1; strstart++; lookahead--; &#125; // 当look-ahead buffer空间不足时，滑动窗口 while (lookahead &lt; MIN_LOOKAHEAD &amp;&amp; !eofile) fill_window(); &#125; // 如果前一个字符在search buffer中无匹配字符串，将strstart-1字符以literal编码 if (match_available) ct_tally (0, window[strstart-1]); return FLUSH_BLOCK(1); /* eof */&#125; lazy match的实际实现，我们可以发现： 当前字符与匹配字符串的距离不超过MAX_DIST(32768 - 258 - 3 - 1)，DEFLATE算法规定最大距离为32768 当前字符的最长匹配长度不超过look-ahead buffer长度 match_available = 0表示lazy match过程结束，即当前字符的匹配字符串比前一个字符的匹配字符串要段，重新开始查找最初的匹配字符串。match_available = 1在重新开始lazy match进行第一次匹配时设置。因此，lazy match过程中存在有效的前一个字符匹配的字符串，或者当前字符在search buffer中无匹配的字符串的场景下，match_available都为1。 Hash优化DEFLATE算法通过链式hash表加速search buffer中的重复字符串查找，链式hash表上存储的是长度为3的字符串的索引。DEFLATE算法的散列函数设计的非常简单、高效： 123456789101112131415161718192021222324252627local unsigned ins_h; /* hash index of string to be inserted */// 初始化hash keyfor (j=0; j&lt;MIN_MATCH-1; j++) UPDATE_HASH(ins_h, window[j])// 更新hash key/* =========================================================================== * Update a hash value with the given input byte * IN assertion: all calls to UPDATE_HASH are made with consecutive * input characters, so that a running hash key can be computed from the * previous key instead of complete recalculation each time. */#define UPDATE_HASH(h,c) (h = (((h)&lt;&lt;H_SHIFT) ^ (c)) &amp; HASH_MASK)// 将偏移s处的长度为3的字符串插入到hash表中/* =========================================================================== * Insert string s in the dictionary and set match_head to the previous head * of the hash chain (the most recent string with same hash key). Return * the previous length of the hash chain. * IN assertion: all calls to INSERT_STRING are made with consecutive * input characters and the first MIN_MATCH bytes of s are valid * (except for the last MIN_MATCH-1 bytes of the input file). */#define INSERT_STRING(s, match_head) \\ (UPDATE_HASH(ins_h, window[(s) + MIN_MATCH-1]), \\ prev[(s) &amp; WMASK] = match_head = head[ins_h], \\ head[ins_h] = (s)) 当前字符开始长度为3的字符串的hash key可以通过之前的hash key与当前的字符进行异或运算，在O(1)时间内求得。因此，整个字符流的所有长度为3的字符串的hash key的计算时间复杂度为O(n)。 整个链式hash表的实现也很简单： head[HASH_SIZE]数组按照hash key索引，相应位置存储的是最近一次计算得到的hash key的字符位置 prev[WSIZE]数组存储的是当前字符位置s前一个重复字符串的字符位置 因此遍历hash chain可以用如下循环： 123456INSERT_STRING(strstart, cur_match);// cur_match &lt;= limit时，匹配字符串超过MAX_DISTIPos limit = strstart &gt; (IPos)MAX_DIST ? strstart - (IPos)MAX_DIST : NIL;do &#123; ...&#125; while ((cur_match = prev[cur_match &amp; WMASK]) &gt; limit); fill_window滑动窗口向前移动WSIZE更新hash表时，hash chain中小于WSIZE的索引被更新为NIL，因为这个索引位置的数据已经从滑动窗口移除；其他索引m被更新为m - WSIZE。","categories":[{"name":"Base Service","slug":"base-service","permalink":"https://system-thoughts.github.io/categories/base-service/"}],"tags":[{"name":"gzip","slug":"gzip","permalink":"https://system-thoughts.github.io/tags/gzip/"},{"name":"deflate","slug":"deflate","permalink":"https://system-thoughts.github.io/tags/deflate/"}]},{"title":"开机过程分析--BIOS阶段","slug":"开机过程分析--BIOS阶段","date":"2021-12-09T13:27:09.000Z","updated":"2023-01-18T05:32:06.168Z","comments":true,"path":"posts/cbbcdbd9/","link":"","permalink":"https://system-thoughts.github.io/posts/cbbcdbd9/","excerpt":"无论是Linux还是其他操作系统，开机启动最开始的流程由BIOS完成。当电脑上电后，BIOS首先会初始化BIOS内部状态、外部接口、检测并setup硬件。这个最开始的阶段称为开机自检(POST, Power On Self Test)。随后BIOS进入启动阶段，会检查启动介质，找到bootloader，将其加载至内存并跳转至bootloader执行。本文以SeaBIOS为例，介绍x86架构下BIOS在启动流程所做的工作。SeaBIOS是16bit x86 BIOS的开源实现，也是qemu和kvm默认的BIOS。","text":"无论是Linux还是其他操作系统，开机启动最开始的流程由BIOS完成。当电脑上电后，BIOS首先会初始化BIOS内部状态、外部接口、检测并setup硬件。这个最开始的阶段称为开机自检(POST, Power On Self Test)。随后BIOS进入启动阶段，会检查启动介质，找到bootloader，将其加载至内存并跳转至bootloader执行。本文以SeaBIOS为例，介绍x86架构下BIOS在启动流程所做的工作。SeaBIOS是16bit x86 BIOS的开源实现，也是qemu和kvm默认的BIOS。 实模式x86实模式出现于Intel 8088时期，8088 CPU公有20位地址总线，8个16进制通用寄存器以及4个段寄存器(CS DS SS ES)以及3个专用寄存器(IP SP FLAGS)。要通过16位寄存器寻址20位地址空间，8088引入了分段的方法： 物理地址 = 段寄存器 &lt;&lt; 4 + 段内偏移 如此，通过16bit的段寄存器和段内偏移便能寻址20位地址空间，计算出的地址便是实际物理地址，这也是“实”模式的由来。 First Instruction系统上电后，BIOS最初便在16bit实模式下工作。x86-64环境下，BIOS的第一条指令位于CS(0xF000h):IP(0xFFF0h)所指向的地址。刚才提及，上电之初，BIOS在16bit实模式下工作，最大寻址1MB，按照实模式下的寻址规则：(0xF000h &lt;&lt; 4) + (0xFFF0h) = 0xFFFF0h。那么开机启动之后，第一条指令会在0xFFFF0h执行？其实不然，开机执行的第一条指令在0xfffffff0h处执行。分段模式下的每个段寄存器寻址的实际物理地址缓存在段描述符高速缓冲寄存器中，这个寄存器对于程序员是不可见的，段描述符高速缓冲寄存器就是通过硬件加速分段模式下的寻址速度。CS段寄存器对应的段描述符高速缓冲寄存器存储的是物理地址0xFFFFFFF0h，该物理地址称为Reset vector。 执行qemu-kvm -monitor stdio -S命令查看机器启动执行的第一条指令： 1234567891011121314151617181920[root@192 lab1]# qemu-kvm -monitor stdio -SQEMU 2.12.0 monitor - type &#x27;help&#x27; for more information(qemu) VNC server running on ::1:5901(qemu) info registers EAX=00000000 EBX=00000000 ECX=00000000 EDX=000006d3ESI=00000000 EDI=00000000 EBP=00000000 ESP=00000000EIP=0000fff0 EFL=00000002 [-------] CPL=0 II=0 A20=1 SMM=0 HLT=0ES =0000 00000000 0000ffff 00009300CS =f000 ffff0000 0000ffff 00009b00SS =0000 00000000 0000ffff 00009300DS =0000 00000000 0000ffff 00009300FS =0000 00000000 0000ffff 00009300GS =0000 00000000 0000ffff 00009300LDT=0000 00000000 0000ffff 00008200TR =0000 00000000 0000ffff 00008b00GDT= 00000000 0000ffffIDT= 00000000 0000ffffCR0=60000010 CR2=00000000 CR3=00000000 CR4=00000000... CS寄存器为0xf000，EIP寄存器为0000fff0，CS寄存器对应的段基址是0xffff0000，该段最能容纳0x0000ffff字节。如此，起始物理地址便是0xfffffff0，便是Reset vector。 但是0xFFFFFFF0h仍然高于实模式下的最大物理地址空间1MB，为啥BIOS可以访问到了？0xFFFFFFF0h实际是BIOS ROM映射到地址空间的地址，而非在实模式寻址RAM的物理地址： 0xFFFE_0000 - 0xFFFF_FFFF: 128 kByte ROM mapped into address space 查看SeaBIOS源码，BIOS第一条指令会执行什么： 1234 ORG 0xfff0 // Power-up Entry Point .global reset_vectorreset_vector: ljmpw $SEG_BIOS, $entry_post ORG是一个宏： 1234// Specify a location in the fixed part of bios area..macro ORG addr.section .fixedaddr.\\addr.endm ORG 0xfff0会定义一个名为.fixedaddr.0xfff0的ELF section，构建阶段，layoutrom.py脚本会检测名称中包含”.fixedaddr.”的section，并在最终的链接脚本中指定该section加载到的物理地址。可见，第一条指令会执行一个长跳转（普通跳转只会更新EIP寄存器，长跳转还会更新CS寄存器）至0xf000:0xe05b 123456789101112src/config.h：// Important real-mode segments#define SEG_IVT 0x0000#define SEG_BDA 0x0040#define SEG_BIOS 0xf000src/romlayout.S: ORG 0xe05bentry_post: cmpl $0, %cs:HaveRunPost // Check for resume/reboot jnz entry_resume ENTRY_INTO32 _cfunc32flat_handle_post // Normal entry point 第一条指令便是跳转到1MB以下的0xfe05b处执行，如下图所示，该地址处于BIOS ROM区域。BIOS ROM内存区域是BIOS shadow内存区域，当前该内存区域是BIOS在ROM/flash实际存储中的一份只读拷贝。由于CPU访问flash/ROM的速度/带宽要慢于CPU访问RAM的速度，BIOS shadow可以加快CPU访问BIOS程序的速度。 首先通过HaveRunPost全局变量判断是否经历过POST阶段，若经过POST阶段，则跳过POST阶段执行resume。否则切换到32bit保护模式执行handle_post函数进入POST阶段。 12// Indicator if POST phase has been started (and if it has completed).int HaveRunPost VARFSEG; POST Phase切换到32bit保护模式我们首先看下进入32bit保护模式是如何实现的： 12345678910111213src/entryfuncs.S: // Reset stack, transition to 32bit mode, and call a C function. .macro ENTRY_INTO32 cfunc xorw %dx, %dx movw %dx, %ss movl $ BUILD_STACK_ADDR , %esp movl $ \\cfunc , %edx jmp transition32 .endmsrc/config.h：// Various memory addresses used by the code.#define BUILD_STACK_ADDR 0x7000 首先设置堆栈段寄存器ss为0，BIOS ROM的程序堆栈处于low memory地址空间(0x7000)。这里的cfunc是函数Label，被传递到edx寄存器，transition32切换到32bit保护模式之后，会跳转到该地址执行。 transition32将CPU转换成32bit： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455src/entryfuncs.S: // Declare a function .macro DECLFUNC func .section .text.asm.\\func .global \\func .endmsrc/romlayout.S:// Place CPU into 32bit mode from 16bit mode.// %edx = return location (in 32bit mode)// Clobbers: ecx, flags, segment registers, cr0, idt/gdt DECLFUNC transition32 .global transition32_nmi_offtransition32: // Disable irqs (and clear direction flag) cli cld // Disable nmi movl %eax, %ecx movl $CMOS_RESET_CODE|NMI_DISABLE_BIT, %eax outb %al, $PORT_CMOS_INDEX inb $PORT_CMOS_DATA, %al // enable a20 inb $PORT_A20, %al orb $A20_ENABLE_BIT, %al outb %al, $PORT_A20 movl %ecx, %eax transition32_nmi_off: // Set segment descriptors lidtw %cs:pmode_IDT_info lgdtw %cs:rombios32_gdt_48 // Enable protected mode movl %cr0, %ecx andl $~(CR0_PG|CR0_CD|CR0_NW), %ecx orl $CR0_PE, %ecx movl %ecx, %cr0 // start 32bit protected mode code ljmpl $SEG32_MODE32_CS, $(BUILD_BIOS_ADDR + 1f) .code32 // init data segments1: movl $SEG32_MODE32_DS, %ecx movw %cx, %ds movw %cx, %es movw %cx, %ss movw %cx, %fs movw %cx, %gs jmpl *%edx DECLFUNC宏定义名为.text.asm.transition32的section，transition32以及transition32_nmi_off都在该section，这两个符号通过.global对链接器可见。 首先关中断并清空方向标志位。过去，为了节省存储空间，很多功能都被合并集成在一个有“空间”的芯片上，控制NMI中断使能、CMOS控制器、RTC时钟都放在CMOS中。 12345678src/hw/rtc.h:#define PORT_CMOS_INDEX 0x0070#define PORT_CMOS_DATA 0x0071// PORT_CMOS_INDEX nmi disable bit#define NMI_DISABLE_BIT 0x80...#define CMOS_RESET_CODE 0x0f 关闭NMI中断的步骤如下： 向0x70端口，写入NMI diable bit(0x80)以及选择CMOS寄存器，接着要通过0x71端口从同一选择CMOS寄存器读取才算完成关闭NMI操作：1outb (0x70, (NMI_disable_bit &lt;&lt; 7) | (selected CMOS register number)); 从0x71端口读取选择CMOS寄存器完成关闭NMI中断：1inb (0x71, (NMI_disable_bit &lt;&lt; 7) | (selected CMOS register number)); 随后开启A20总线以便访问1MB以上的物理地址空间。8086/8088实模式下，最大能够访问的物理地址是0xFFFF:0xFFFF即0x10FFEF。访问该物理地址需要21根地址线，然而8086/8088仅有20根地址总线，因此改地址会被截断成0x0FFEF。后续80x86 CPU为了兼容这种回环现象，设计了A20总线，当A20总线为1，第21位以及更高位都有效；反之，高位为0，兼容回环现象。123// PORT_A20 bitdefs#define PORT_A20 0x0092#define A20_ENABLE_BIT 0x02 可见通过往A20 0x92I/O端口置位第2 bit位开启A20总线。随后通过lidtw和lgdtw两条命令加载idtr和gdtr寄存器，设定中断描述符表和全局描述符表。32bit保护模式下的分段寻址和实模式有较大差异。偏移值同实模式一样，只不过变成了32bit。段值仍然放在以前的16bit寄存器，不过寄存器存放的不是段基址，而是段选择符。通过段选择符不仅能够索引全局/局部描述符表获取段描述符中的基址，还能够描述当前访问操作的特权级实现段保护。 段描述符表rombios32_gdt_48如代码所示，对比段描述符结构，则一目了然。 123456789101112131415161718192021222324252627282930313233// Dummy IDT that forces a machine shutdown if an irq happens in// protected mode.u8 dummy_IDT VARFSEG;// Protected mode IDT descriptorstruct descloc_s pmode_IDT_info VARFSEG = &#123; .length = sizeof(dummy_IDT) - 1, .addr = (u32)&amp;dummy_IDT,&#125;;// GDTu64 rombios32_gdt[] VARFSEG __aligned(8) = &#123; // First entry can&#x27;t be used. 0x0000000000000000LL, // 32 bit flat code segment (SEG32_MODE32_CS) GDT_GRANLIMIT(0xffffffff) | GDT_CODE | GDT_B, // 32 bit flat data segment (SEG32_MODE32_DS) GDT_GRANLIMIT(0xffffffff) | GDT_DATA | GDT_B, // 16 bit code segment base=0xf0000 limit=0xffff (SEG32_MODE16_CS) GDT_LIMIT(BUILD_BIOS_SIZE-1) | GDT_CODE | GDT_BASE(BUILD_BIOS_ADDR), // 16 bit data segment base=0x0 limit=0xffff (SEG32_MODE16_DS) GDT_LIMIT(0x0ffff) | GDT_DATA, // 16 bit code segment base=0xf0000 limit=0xffffffff (SEG32_MODE16BIG_CS) GDT_GRANLIMIT(0xffffffff) | GDT_CODE | GDT_BASE(BUILD_BIOS_ADDR), // 16 bit data segment base=0 limit=0xffffffff (SEG32_MODE16BIG_DS) GDT_GRANLIMIT(0xffffffff) | GDT_DATA,&#125;;// GDT descriptorstruct descloc_s rombios32_gdt_48 VARFSEG = &#123; .length = sizeof(rombios32_gdt) - 1, .addr = (u32)rombios32_gdt,&#125;; 随后通过设置CR0寄存器：关闭分页模式、使能CPU cache、设置CPU cache Write-through、并开启保护模式： 123456src/x86.h:// CR0 flags#define CR0_PG (1&lt;&lt;31) // Paging#define CR0_CD (1&lt;&lt;30) // Cache disable#define CR0_NW (1&lt;&lt;29) // Not Write-through#define CR0_PE (1&lt;&lt;0) // Protection enable 最终，通过长跳转ljmpl跳转至32bit保护模式，CS寄存器存储的段选择符为01000B,即RPL = 0,执行在特权级0上；TI = 0，段选择符索引GDT；Index = 1，索引GDT中的第一个段描述符。段描述符中基址是0x0，Segment Limit是0xfffff，G(Granularity)flag置位，表示该段的范围是0x100000 * 4KB = 4GB。 1234src/config.h:// Segment definitions in protected mode (see rombios32_gdt in misc.c)#define SEG32_MODE32_CS (1 &lt;&lt; 3)#define SEG32_MODE32_DS (2 &lt;&lt; 3) 这里的1f要区分清楚。指的是前方第一个标签为“1”的位置，而不是代表十六进制数0x1F。下一个标签“1”就是这个指令的下一条。所以，看起来这个跳转是没有价值的。实际上，在cr0寄存器被设定好之前，下一条指令已经被放入流水线。而再放入的时候这条指令还是在实模式下的。所以这个ljmp指令是为了清空流水线，确保下一条指令在保护模式下执行。[1] 随后初始化所有的数据段寄存器ss、ds、es、fs、gs为$SEG32_MODE32_DS。段描述符中基址是0x0，Segment Limit是0xfffff，G(Granularity)flag置位，段的大小都是4GB。进入实模式后，所有段寻址的地址空间都是[0, 4G),当前地址空间不再是分段的，而是完整的一大块，即“平坦模型”。 随后跳转到32bit保护模式下的handle_post函数。 handle_post12345678910111213141516171819202122src/post.c:// Entry point for Power On Self Test (POST) - the BIOS initilization// phase. This function makes the memory at 0xc0000-0xfffff// read/writable and then calls dopost().void VISIBLE32FLAThandle_post(void)&#123; if (!CONFIG_QEMU &amp;&amp; !CONFIG_COREBOOT) return; serial_debug_preinit(); debug_banner(); // Check if we are running under Xen. xen_preinit(); // Allow writes to modify bios area (0xf0000) make_bios_writable(); // Now that memory is read/writable - start post process. dopost();&#125; post阶段最开始的启动串口调试等细节我们就忽略，着重关注make_bios_writable和dopost。 前面提到BIOS ROM内存区域是BIOS shadow内存区域，该内存区域是BIOS ROM/flash在内存中的只读拷贝。make_bios_writable就是用于让这段内存可写，以便后续更改一些静态分配的全局变量。 1234567891011121314// Setup for code relocation and then relocate.void VISIBLE32INITdopost(void)&#123; code_mutable_preinit(); // Detect ram and setup internal malloc. qemu_preinit(); coreboot_preinit(); malloc_preinit(); // Relocate initialization code and call maininit(). reloc_preinit(maininit, NULL);&#125; code_mutable_preinit通过设置全局变量HaveRunPost为1，防止重复进入POST阶段。 根据SeaBIOS官方文档[2]描述，POST阶段可以分为如下四个子阶段： preinit: 代码重定位之前的初始化操作 init: 初始化内部变量和接口 setup: setup硬件和驱动 preboot: 所有接口初始化工作完成，准备启动 SeaBIOS的代码重定位是为了释放部分占用的BIOS ROM空间，将原本很小的内存空间留给Option ROM、BIOS table以及运行时的存储空间。直接看maininit的最后代码部分startBoot准备启动： 12345678910111213// Begin the boot process by invoking an int0x19 in 16bit mode.void VISIBLE32FLATstartBoot(void)&#123; // Clear low-memory allocations (required by PMM spec). memset((void*)BUILD_STACK_ADDR, 0, BUILD_EBDA_MINIMUM - BUILD_STACK_ADDR); dprintf(3, &quot;Jump to int19\\n&quot;); struct bregs br; memset(&amp;br, 0, sizeof(br)); br.flags = F_IF; call16_int(0x19, &amp;br);&#125; bootloader工作在16bit的实模式，call16_int切换至实模式并调用int 0x19h软件中断(software-generated interrupt)，进入BIOS的BOOT阶段。 The INT n instruction permits interrupts to be generated from within software by supplying an interrupt vector number as an operand. 软件（生成）中断源自CPU主动执行特定的指令（x86下的int指令）产生中断，而非源自CPU接收的外部硬件产生的中断。 1234567891011121314151617181920212223242526src/stacks.h:#define call16_int(nr, callregs) do &#123; \\ extern void irq_trampoline_ ##nr (void); \\ __call16_int((callregs), (u32)&amp;irq_trampoline_ ##nr ); \\ &#125; while (0)src/romlayout.S:// IRQ trampolines .macro IRQ_TRAMPOLINE num DECLFUNC irq_trampoline_0x\\num irq_trampoline_0x\\num : int $0x\\num lretw .endm IRQ_TRAMPOLINE 02 IRQ_TRAMPOLINE 05 IRQ_TRAMPOLINE 10 IRQ_TRAMPOLINE 13 IRQ_TRAMPOLINE 15 IRQ_TRAMPOLINE 16 IRQ_TRAMPOLINE 18 IRQ_TRAMPOLINE 19 IRQ_TRAMPOLINE 1b IRQ_TRAMPOLINE 1c IRQ_TRAMPOLINE 4a 可见irq_trampoline_0x19实际执行: 12int $0x19lretw maininit-&gt;interface_init-&gt;ivt_init初始化中断向量表： 1234567891011121314151617181920212223242526src/post.c: // Initialize software handlers. SET_IVT(0x02, FUNC16(entry_02)); SET_IVT(0x05, FUNC16(entry_05)); SET_IVT(0x10, FUNC16(entry_10)); SET_IVT(0x11, FUNC16(entry_11)); SET_IVT(0x12, FUNC16(entry_12)); SET_IVT(0x13, FUNC16(entry_13_official)); SET_IVT(0x14, FUNC16(entry_14)); SET_IVT(0x15, FUNC16(entry_15_official)); SET_IVT(0x16, FUNC16(entry_16)); SET_IVT(0x17, FUNC16(entry_17)); SET_IVT(0x18, FUNC16(entry_18)); SET_IVT(0x19, FUNC16(entry_19_official)); SET_IVT(0x1a, FUNC16(entry_1a_official)); SET_IVT(0x40, FUNC16(entry_40));src/romlayout.S: // int 18/19 are special - they reset stack and call into 32bit mode. DECLFUNC entry_19entry_19: ENTRY_INTO32 _cfunc32flat_handle_19... .global entry_19_officialentry_19_official: jmp entry_19 0x19软件中断会执行handle_19，BIOS进入了BOOT阶段。 BOOT Phase123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051src/boot.c:// Determine next boot method and attempt a boot using it.static void do_boot(int seq_nr)&#123; if (! CONFIG_BOOT) panic(&quot;Boot support not compiled in.\\n&quot;); if (seq_nr &gt;= BEVCount) boot_fail(); // Boot the given BEV type. struct bev_s *ie = &amp;BEV[seq_nr]; switch (ie-&gt;type) &#123; case IPL_TYPE_FLOPPY: printf(&quot;Booting from Floppy...\\n&quot;); boot_disk(0x00, CheckFloppySig); break; case IPL_TYPE_HARDDISK: printf(&quot;Booting from Hard Disk...\\n&quot;); boot_disk(0x80, 1); break; case IPL_TYPE_CDROM: boot_cdrom((void*)ie-&gt;vector); break; case IPL_TYPE_CBFS: boot_cbfs((void*)ie-&gt;vector); break; case IPL_TYPE_BEV: boot_rom(ie-&gt;vector); break; case IPL_TYPE_HALT: boot_fail(); break; &#125; // Boot failed: invoke the boot recovery function struct bregs br; memset(&amp;br, 0, sizeof(br)); br.flags = F_IF; call16_int(0x18, &amp;br);&#125;// INT 19h Boot Load Service Entry Pointvoid VISIBLE32FLAThandle_19(void)&#123; debug_enter(NULL, DEBUG_HDL_19); BootSequence = 0; do_boot(0);&#125; do_boot从第一个启动项进行启动，以常见的硬盘(IPL_TYPE_HARDDISK)为例: 123456789101112131415161718192021222324252627282930313233343536373839src/boot.c// Boot from a disk (either floppy or harddrive)static void boot_disk(u8 bootdrv, int checksig)&#123; u16 bootseg = 0x07c0; // Read sector struct bregs br; memset(&amp;br, 0, sizeof(br)); br.flags = F_IF; br.dl = bootdrv; br.es = bootseg; br.ah = 2; br.al = 1; br.cl = 1; call16_int(0x13, &amp;br); if (br.flags &amp; F_CF) &#123; printf(&quot;Boot failed: could not read the boot disk\\n\\n&quot;); return; &#125; if (checksig) &#123; struct mbr_s *mbr = (void*)0; if (GET_FARVAR(bootseg, mbr-&gt;signature) != MBR_SIGNATURE) &#123; printf(&quot;Boot failed: not a bootable disk\\n\\n&quot;); return; &#125; &#125; tpm_add_bcv(bootdrv, MAKE_FLATPTR(bootseg, 0), 512); /* Canonicalize bootseg:bootip */ u16 bootip = (bootseg &amp; 0x0fff) &lt;&lt; 4; bootseg &amp;= 0xf000; call_boot_entry(SEGOFF(bootseg, bootip), bootdrv);&#125; int 0x13H从硬盘读取第一个扇区(MBR)至ES:BX,BX初始化为0，因此MBR的内容读取到0x07c0:0x0。 int 0x13H相关寄存器参数[3]:GET_FARVAR(bootseg, mbr-&gt;signature)便是校验MBR签名0xaa55，确认读取到的内容就是MBR扇区。最后的规范化(Canonicalize)操作为了让后续调用bootloader时，段地址:偏移地址为0x0:0x7c00而非0x07c0:0x0。最后调用call_boot_entry跳转至0x0:0x7c00地址，转移至bootloader执行，此时系统仍处于16bit实模式。 我们写一个简单的bootloader，看看BIOS启动跳转到bootloader的效果： 12345678910111213141516boot.S:.global _start.text.code16_start: mov $0x21, %al mov $0x0e, %ah mov $0x00, %bh mov $0x07, %bl int $0x10 jmp ..space 510-(.-_start).word 0xaa55 构建[4]并运行： 12# gcc -Wl,--oformat=binary -Wl,-Ttext=0x7c00 -Wl,--build-id=none -nostartfiles -nostdlib -m32 -o boot.bin boot.S# qemu-kvm -nographic -drive format=raw,file=boot.bin bootloader程序很简单，就是向屏幕输出!。 Reference[1] SeaBIOS实现简单分析[2] Execution_and_code_flow[3] INT 13H Wikipedia[4] Calculating padding length with GAS AT&amp;T directives for a boot sector?","categories":[{"name":"boot","slug":"boot","permalink":"https://system-thoughts.github.io/categories/boot/"}],"tags":[{"name":"boot","slug":"boot","permalink":"https://system-thoughts.github.io/tags/boot/"},{"name":"BIOS","slug":"bios","permalink":"https://system-thoughts.github.io/tags/bios/"}]},{"title":"shell命令行参数处理","slug":"shell命令行参数处理","date":"2021-04-09T16:15:04.000Z","updated":"2023-01-18T05:32:06.164Z","comments":true,"path":"posts/c0186fb6/","link":"","permalink":"https://system-thoughts.github.io/posts/c0186fb6/","excerpt":"我使用Linux已有8年有余，经常会编写shell脚本进行自动化处理。然而，到目前为止，我依然不能像熟练使用C语言一样编写shell脚本。确实，我的主力编程语言是C语言，仅在做自动化脚本或者编写自动化测试用例的时候才会使用shell。另外一方面，shell脚本的语法的变种太多，例如，if语句在做字符串、数值、文件比较时的判断语句都相差很大；特殊符号多，$#、$@、$?等等，如果你是第一次接触shell脚本，必然会手足无措，更坑爹的是，这些特殊符号使用的场景相差很大，记忆负担真的大！！还有，shell脚本会依赖太多小程序，正如unix哲学所言：一个工具肩负单一使命，这些程序的各自用途、各自选项差异很大，你根本没有办法一下子就记住所有用法！！！","text":"我使用Linux已有8年有余，经常会编写shell脚本进行自动化处理。然而，到目前为止，我依然不能像熟练使用C语言一样编写shell脚本。确实，我的主力编程语言是C语言，仅在做自动化脚本或者编写自动化测试用例的时候才会使用shell。另外一方面，shell脚本的语法的变种太多，例如，if语句在做字符串、数值、文件比较时的判断语句都相差很大；特殊符号多，$#、$@、$?等等，如果你是第一次接触shell脚本，必然会手足无措，更坑爹的是，这些特殊符号使用的场景相差很大，记忆负担真的大！！还有，shell脚本会依赖太多小程序，正如unix哲学所言：一个工具肩负单一使命，这些程序的各自用途、各自选项差异很大，你根本没有办法一下子就记住所有用法！！！ 上面就是对自己写不好shell脚本的一些反思，破局还是有办法的。既然shell脚本的用法诡谲多变、充满奇淫技巧，依靠大脑的记忆肯定是不靠谱的，应该建立codebase记录那些不太好记忆的shell语法、指令的典型应用示例。当忘记了相关的shell命令时，便可翻阅codebase唤醒代码记忆。当然，那些已深刻在你记忆中的知识就冗余无需记录。本篇文章是shell codebase的第一篇文章，主要介绍shell命令行参数的处理。 命令行参数基础向shell脚本传输数据最基本的方法是使用命令行参数。传入的命令行参数通过位置参数(positional parameter)的特殊变量进行区分：$0表示程序名，$1、$2分别表示第一、第二个参数，依次类推。需要注意的是$0表示的是命令行中执行shell脚本的路径，使用相对路径和绝对路径，$0中的内容会相应改变。可使用basename提取文件名。shell将空格作为参数的分割符，若参数中需要包含空格，则需要用引号（单引号、双引号均可）完整地包含参数。 有个小聪明啊，可以编写基于脚本名来执行不同功能的脚本: 123456789101112# cat filename_as_func.sh #!/bin/bash# implement the corresponding function according to the file namename=$(basename $0)if [ $name = &quot;add&quot; ]; then total=$[ $1 + $2 ]elif [ $name = &quot;mul&quot; ]; then total=$[ $1 * $2 ]fiecho The caculation value is $total 将filename_as_func.sh链接到不同的文件名，查看运行结果： 123456# ln -s filename_as_func.sh add# ln -s filename_as_func.sh mul# ./add 2 3The caculation value is 5# ./mul 2 3The caculation value is 6 检查预期的命令行参数是否存在是一种良好的编码风格，让脚本直接报错不可取。如下是检查第一个参数是否存在： 1234if [ -z &quot;$1&quot; ]; then echo parameter is needed! exit 1fi bash shell中有些特殊变量记录命令行参数。$#表示命令行参数的个数。很直观地，我们会考虑借助$#表示最后一个命令行参数：$&#123;$#&#125;。然而这种表示并不正确，不能在花括号中使用美元符，必须将美元符替换为感叹号，即$&#123;!#&#125;。 1234567[root@localhost parameters]# cat last_parameter.sh #!/bin/bash# use $# represent the last parameterecho The last parameter is $&#123;!#&#125;[root@localhost parameters]# ./last_parameter.sh 1 2 3 4The last parameter is 4 $@和$*特殊变量都能表示所有参数。 $*会将命令行提供的所有参数当作单个单词进行访问。 $@会将命令行上提供的所有参数当作同一个字符串中多个独立的单词。它允许你遍历所有值。1234567891011121314151617181920212223[root@localhost parameters]# cat all_parameter.sh #!/bin/bash# test $* and $@ difference, they both represent all the parameterscount=1for param in &quot;$*&quot;do echo &quot;\\$* parameter #$count = $param&quot; count=$[ $count + 1 ]donecount=1for param in &quot;$@&quot;do echo &quot;\\$@ parameter #$count = $param&quot; count=$[ $count + 1 ]done[root@localhost parameters]# ./all_parameter.sh 1 2 3 4$* parameter #1 = 1 2 3 4$@ parameter #1 = 1$@ parameter #2 = 2$@ parameter #3 = 3$@ parameter #4 = 4 处理命令行选项执行脚本通常会指定命令行选项，实际上，可以像处理命令行参数一样，处理命令行选项。我们先来看看最硬核的“手撕shell命令行选项”的处理方式。 12345678910111213141516171819[root@localhost parameters]# cat basic_options.sh #!/bin/bash# handle options by handwhile [ -n &quot;$1&quot; ]do case &quot;$1&quot; in -a) echo &quot;Found the -a option&quot; ;; -b) echo &quot;Found the -b option&quot; ;; -c) echo &quot;Found the -c option&quot; ;; *) echo &quot;$1 is not an option&quot; ;; esac shiftdone[root@localhost parameters]# ./basic_options.sh -a -b -c 1Found the -a optionFound the -b optionFound the -c option1 is not an option shift命令会将每个参数变量减一。所以变量$2会移动到$1，而原来的$1会被删除，依次类推。注意：变量$0的值是不会改变，即程序名不会改变。所以通过while循环配合shift命令便能够处理所有命令行参数。通过case语句判断命令行选项，并做相应处理。 上面的脚本可以识别选项，但同时使用选项和参数，则对参数无法很好地处理。Linux中处理这个问题的标准方法是使用特殊字符（双破折线–）将选项和参数分开，特殊字符会告诉脚本，选项何时结束以及普通参数何时开始。 123456789101112131415161718192021222324252627282930[root@localhost parameters]# cat extract_parameters.sh #!/bin/bash# extract options and parameterswhile [ -n &quot;$1&quot; ]do case &quot;$1&quot; in -a) echo &quot;Found the -a option&quot; ;; -b) echo &quot;Found the -b option&quot; ;; -c) echo &quot;Found the -c option&quot; ;; --) shift break ;; *) echo &quot;$1 is not an option&quot; esac shiftdonecount=1for param in $@do echo &quot;parameter #$count is $param&quot; count=$[ $count + 1 ]done[root@localhost parameters]# ./extract_parameters.sh -a -b -c -- 1 2 3Found the -a optionFound the -b optionFound the -c optionparameter #1 is 1parameter #2 is 2parameter #3 is 3 当脚本遇到双破折线时，就停止处理选项，将剩下的参数都作为命令行参数。然而，此种方式将命令行选项和参数泾渭分明。如果命令行选项会带有额外的参数，此种方式便无法区分，需要手动处理选项参数： 12345678910111213141516171819202122232425262728293031[root@localhost parameters]# cat basic_option_parameter.sh #!/bin/bash# extract option parameter by handwhile [ -n &quot;$1&quot; ]do case &quot;$1&quot; in -a) echo &quot;Found the -a option&quot; ;; -b) param=&quot;$2&quot; echo &quot;Found the -b option, with parameter value $param&quot; shift ;; -c) echo &quot;Found the -c option&quot; ;; --) shift break ;; *) echo &quot;$1 is not an option&quot; esac shiftdonecount=1for param in $@do echo &quot;parameter #$count is $param&quot; count=$[ $count + 1 ]done[root@localhost parameters]# ./basic_option_parameter.sh -a -b 2 -c -- 56 78Found the -a optionFound the -b option, with parameter value 2Found the -c optionparameter #1 is 56parameter #2 is 78 当前shell脚本已经具备处理命令行选项的基本能力，但是还有一些限制，如无法区分合并的命令行选项。另外，没有用户愿意通过输入”–”区分选项和参数，这个工作最好由shell脚本自动完成。下面介绍的getopt命令就是为了摆脱这种最硬核的选项解析方式。 getopt命令getopt命令是处理命令行选项和参数的一个非常强有力的工具，在CentOS中，其由util-linux提供。getopt命令参数可以分为两部分：1.命令行选项[options] 2. getopt待解析的命令行参数parameters，parameters是从第一个非getopt命令行选项开始的，或者在--之后。根据getopt命令第一部分的状态，getopt的调用方式可以分为三种： 无命令行选项，此种选项解析最为简单，也是最常用的，但是只能解析短选项：1getopt optstring parameters parameters：getopt要解析的命令行参数12# getopt &quot;ab:cd&quot; -a 1 -b 2 -cd 3 4 -a -b 2 -c -d -- 1 3 4 有命令行选项，但是没有-o|--options选项，-o选项比较特殊，用来指定短选项(shortopts)：1getopt [options] [--] optstring parameters options表示所有的非-o选项，如果没有--，则第一个非getopt选项的参数就是shortopts，随后便是待解析参数。1234567891011[root@localhost ~]# getopt &quot;ab:cd&quot; -c 1 -b 2 -ade 3 4getopt: invalid option -- &#x27;e&#x27; -c -b 2 -a -d -- 1 3 4[root@localhost ~]# getopt -q &quot;ab:cd&quot; -c 1 -b 2 -ade 3 4 -c -b &#x27;2&#x27; -a -d -- &#x27;1&#x27; &#x27;3&#x27; &#x27;4&#x27;[root@localhost ~]# echo $?1[root@localhost ~]# getopt -q -- &quot;ab:cd&quot; -c 1 -b 2 -ade 3 4 -c -b &#x27;2&#x27; -a -d -- &#x27;1&#x27; &#x27;3&#x27; &#x27;4&#x27;[root@localhost ~]# echo $?1 如果指定了一个不存在optstring的选项，默认情况下，getopt会报错，通过-q选项会忽略这条错误信息，但是getopt还是会返回错误值。上面例子的最后两条指令表明了shortopts的位置。这种隐式指明shortopts位置的方式在有-l|--longoptions参数的时候很容易造成误解。同shortopts指定参数的方式，唯一不同的是，longopts的每个参数通过逗号分隔。1234[root@localhost ~]# getopt -l extract:,tar:,help,directory -- file --extract a.tar --extract &#x27;a.tar&#x27; --[root@localhost ~]# getopt -l extract:,tar:,help,directory -- file --extract a.tar -f -i abc --extract &#x27;a.tar&#x27; -f -i -- &#x27;abc&#x27; 上面这个示例，我们打算只定义长命令行选项。然而第一条shell命令未解析到参数file。再看看后一条命令，大概就心里有数了。如果getopt命令带有选项，但是未带有-o选项，getopt会将命令第二部分的第一个参数即file作为shortopts。这说明getopt默认总是会解析短选项，其必须指定shortopts。然而，这种隐式的指定，对于命令的理解极其不友好。 若要指定长命令选项，最好通过-o|--options显式地指明短命令选项：1getopt [options] -o|--options optstrin [options] [--] parameters 还是上面的例子，但同时指明短命令选项：1234[root@localhost ~]# getopt -o e:t:hd -l extract:,tar:,help,directory -- file --extract a.tar --extract &#x27;a.tar&#x27; -- &#x27;file&#x27;[root@localhost ~]# getopt -o &#x27;&#x27; -l extract:,tar:,help,directory -- file --extract a.tar --extract &#x27;a.tar&#x27; -- &#x27;file&#x27; 可见，即便你不想指定短选项，显式地通过将-o选项指定为空。也能够正确地解析出参数file。 使用getopt处理脚本的命令行参数： 123456789101112131415161718192021222324252627282930313233[root@localhost parameters]# cat basic_getopt.sh #!/bin/bash# use getopt handle parametersset -- $(getopt -q &quot;ab:c&quot; &quot;$@&quot;)while [ -n &quot;$1&quot; ]do case &quot;$1&quot; in -a) echo &quot;Found the -a option&quot; ;; -b) param=&quot;$2&quot; echo &quot;Found the -b option, with parameter value $param&quot; shift ;; -c) echo &quot;Found the -c option&quot; ;; --) shift break ;; *) echo &quot;$1 is not an option&quot; esac shiftdonecount=1for param in $@do echo &quot;parameter #$count is $param&quot; count=$[ $count + 1 ]done[root@localhost parameters]# ./basic_getopt.sh -c 1 -b 2 -ad 3 4Found the -c optionFound the -b option, with parameter value &#x27;2&#x27;Found the -a optionparameter #1 is &#x27;1&#x27;parameter #2 is &#x27;3&#x27;parameter #3 is &#x27;4&#x27; 其中最为关键的是set与getopt的配合使用。前面，我们已经提到--是选项和参数的分界符，--之后都代表set命令的参数，即便其中包含-，也不会被识别为set命令的选项。上述set命令会将当前环境变量$@设置为getopt -q &quot;ab:c&quot; &quot;$@&quot;的输出。那么，这条set命令就是为了用getopt格式化后的命令行参数来替换原始的命令行参数。后续while循环处理的便是格式化的命令行参数即： 12[root@localhost parameters]# getopt -q &quot;ab:c&quot; -c 1 -b 2 -ad 3 4 -c -b &#x27;2&#x27; -a -- &#x27;1&#x27; &#x27;3&#x27; &#x27;4&#x27; getopts命令bash shell包含了getopts命令。与getopt将命令行上找到的选项和参数处理后只生成一个输出不同。每次调用getopts，它只处理一个命令行上检测到的参数。处理完所有参数后，它会退出并返回一个大于零的退出状态码。因此，getopts非常适合用于解析命令行所有参数的循环中。getopts命令的格式如下： 1getopts optstring variable optstring同getopt命令的shortopts。若getopts要忽略错误信息，可以在optstring之前加上冒号。variable表示待解析的命令行参数。 getopts会用到两个环境变量。如果选项后面跟参数，OPTARG环境变量保存该参数值。OPTIND环境变量保存了参数列表中getopts正在处理的参数位置。 1234567891011121314151617181920212223242526272829[root@localhost parameters]# cat getopts_OPTIND.sh #!/bin/bash# processing options and prameters with getopts, show OPTIND and shift combination to get parameterswhile getopts :ab:cd optdo case &quot;$opt&quot; in a) echo &quot;Found the -a option&quot; ;; b) echo &quot;Found the -b option, with value $OPTARG&quot; ;; c) echo &quot;Found the -c option&quot; ;; d) echo &quot;Found the -d option&quot; ;; *) echo &quot;Unknown option $opt&quot; ;; esacdoneshift $[ $OPTIND - 1 ]count=1for param in &quot;$@&quot;do echo &quot;Parameter $count: $param&quot; count=$[ $count + 1 ]done[root@localhost parameters]# ./getopts_OPTIND.sh -a -btest1 -d -f &quot;test2 test3&quot; Found the -a optionFound the -b option, with value test1Found the -d optionUnknown option ?Parameter 1: test2 test3 由上面的示例可知，getopts处理每个选项时，它会将OPTIND环境变量的值增1。在getopts完成处理后，可以将OPTIND和shift命令一起使用移动参数。与getopt命令不同的是：getopts解析命令行选项时，会移除开头的破折号。它能够将命令行上找到的所有未定义的选项统一输出问号。同时getopts不支持长选项的解析。但是getopts命令并不灵活： 123456[root@localhost parameters]# ./getopts_OPTIND.sh -a -btest1 -d &quot;test2 test3&quot; -cFound the -a optionFound the -b option, with value test1Found the -d optionParameter 1: test2 test3Parameter 2: -c 如果参数出现在选项之前，getopts便不能够解析到选项了。 因此getopt提供了较为强大且定制的功能，getopts提供了快捷的命令行参数选项解析功能，但并不灵活。 解析选项冲突同一命令的不同选项存在冲突语义的情况，例如tar命令的-x选项表示解压tar包，-t选项表示打包操作。显然，这两个选项的语义互相冲突。getopt和getopts并未定义选项之间的关系，因此我们必须手动解析选项之间的关系，可参考下面的例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@localhost parameters]# cat option-relation.sh #!/bin/bash# handle options&#x27; relationshipset -- $(getopt -q &quot;t:x:h&quot; &quot;$@&quot;)while [ -n &quot;$1&quot; ]do case &quot;$1&quot; in -t) tar=true tar_param=&quot;$2&quot; shift ;; -x) extract=true extract_param=&quot;$2&quot; shift ;; --) shift break ;; *) echo &quot;$1 is unrecognized&quot; esac shiftdoneif [[ $tar == true &amp;&amp; $extract == true ]]; then echo &quot;Cannot specify -t -x options at the same time&quot; exit 1elif [[ $tar == true ]]; then echo &quot;Exec $(basename $0) -t $tar_param ...&quot;elif [[ $extract == true ]]; then echo &quot;Exec $(basename $0) -x $extract_param ...&quot;ficount=1for param in $@do echo &quot;parameter #$count is $param&quot; count=$[ $count + 1 ]done[root@localhost parameters]# ./option-relation.sh -x a.tar -t file file2Cannot specify -t -x options at the same time[root@localhost parameters]# ./option-relation.sh -x a.tar file2Exec option-relation.sh -x &#x27;a.tar&#x27; ...parameter #1 is &#x27;file2&#x27;[root@localhost parameters]# ./option-relation.sh -t file file2Exec option-relation.sh -t &#x27;file&#x27; ...parameter #1 is &#x27;file2&#x27; 这不一定是最好的方法，但是代码较为清晰。前半部分解析选项，标记相应的flag。然后根据flag情况判断相应的依赖关系，进行实际的命令行选项处理。","categories":[{"name":"shell","slug":"shell","permalink":"https://system-thoughts.github.io/categories/shell/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://system-thoughts.github.io/tags/shell/"},{"name":"codebase","slug":"codebase","permalink":"https://system-thoughts.github.io/tags/codebase/"}]},{"title":"Head first for mutt","slug":"mutt","date":"2021-03-31T11:21:52.000Z","updated":"2023-01-18T05:32:06.156Z","comments":true,"path":"posts/48e1f01b/","link":"","permalink":"https://system-thoughts.github.io/posts/48e1f01b/","excerpt":"给社区发送邮件讨论补丁时，选择一个趁手的客户端会极大提高沟通效率。曾经我通过”git send-email + thunderbird”的工具组合进行邮件的发送和读取，thunderbird如同outlook的clone版本，对于使用GUI客户端的用户极为友好。然而大多数内核开发者还是会选用mutt邮件客户端，其可配置性极佳，完全命令行的交互方式对于kernel hacker来说是极为友好的。","text":"给社区发送邮件讨论补丁时，选择一个趁手的客户端会极大提高沟通效率。曾经我通过”git send-email + thunderbird”的工具组合进行邮件的发送和读取，thunderbird如同outlook的clone版本，对于使用GUI客户端的用户极为友好。然而大多数内核开发者还是会选用mutt邮件客户端，其可配置性极佳，完全命令行的交互方式对于kernel hacker来说是极为友好的。 what is mutt and how dose it work? “All mail clients suck. This one just sucks less.” – Michael Elkins, circa 1995 mutt是一个邮件客户端，直接与终端用户进行交互，Internet规范和RFC使用术语MUA(Message User Agent)描述邮件客户端。MUA可以是桌面应用程序，如Microsoft Outlook、Thunderbird等，也可以是基于Web的应用程序，如Gmail、Hotmail等（后者也称为Webmail）。用户使用mutt应该能够完成基本的邮件编写、接收、发送。但mutt将这些基本功能都模块化并交给其他程序完成，如mutt可以配置环境中的编辑器作为撰写邮件的工具，比如我会配置趁手的vim。为了确定还需要哪些辅助程序帮助mutt完成基本的邮件收发功能。我们需要了解email的传送过程：为了将邮件从发送者通过Internet传递给接收者，还需要MTA(Message Transfer Agent)进行邮件转发，一个简略的邮件传送流程： 12sender -&gt; transfer -&gt; recipientMUA → MTA → … → MTA → MUA 可以将上述流程进行细化： 123push steps: →pull steps: →→MUA → MSA → MTA → … → MTA → MDA →→ MRA →→ MUA 这里对上述术语做一个清晰的解释： MUA(Message User Agent): MUA是终端用户管理和读取存储到用户邮箱的电子邮件的前端，并可在其中进行邮件编辑(compose)且通过MSA发送出去。 MTA(Message Transfer Agent)：MTA对邮件进行排队(queue)、接收(receive from)、并发送(send)给下一MTA。这包括邮件路由(routing mail)、排队(queuing)和重试(retrying)，如果下一MTA未能立即接收或者处理email或者便向原始发件人发送通知。 MSA(Message Submission Agent)：接收来自MUA发送的邮件，作为SMTP client，仅能发送email，而不能像Full-fledged MTA接收email进行转发。MTA使用端口25，MSA不仅可以使用端口25，还有offical port 587。MSA使用ESMTP(SMTP协议的变种)。MSA有时候也形象地称为Mail Sending Agent。 MDA(Message Delivery Agent)：MDA收到邮件之后不会往下转发，即邮件已经投递到位。MDA将邮件放入收件箱(incoming mailbox)，MDA可以调用procmail MRA(Mail Retrieval Agent)：与远程邮箱建立连接并获取邮件到本地使用，MRA是从邮件接收者的视角来命名，IETF不支持该术语，认为其是MUA[1]。 若是要通过mutt完成邮件的收发，还需要具备MSA和MRA功能的软件配合mutt。显然，在我们工作的客户端不需要Full-fledeged MTA完成邮件的中转，我们仅需将邮件发出即可。另外，我们也不需要MDA对邮件进行投递（如果您是为个人或者公司搭建邮件服务器，就当我没说🙊），因为我们使用的邮箱，诸如Gmail的邮件服务器已经完成邮件投递工作，我们仅需通过POP3/IMAP协议接收邮件。然而，我们通过搜索引擎配置搜索mutt的配置，经常会出现各种mutt + x + y + ...的搜索结果令人眼花缭乱。这是因为同一功能，你的选择很多，就拿MSA来说，您可以选择postfix、sendmail、msmtp等[2]。而且，同一软件具备的多种功能，如sendmail、postfix不仅具有MTA功能，还集成了MDA功能。😤害，这不是违背了Unix哲学”one task per tool”！是的，甚至连mutt也背离初心: mutt was developed with the concept of “one task per tool”, enabling performance through combination with other high quality modular programs. 但是mutt现在实际变成了当初它讨厌的样子😅： … or why mutt should not but slowly becomes an “all-in-1” program. mutt已经引入了最简单的MRA、MSA功能支持SMTP、POP3、IMAP进行邮件收发。为何会背离初心： “This entire concept is rubbish and the mutt developers are just plain lazy [to add all the good stuff].” 好吧，看来群众的力量是很难承受的……另外有些功能的界限实际难以区分，比如MDA和MRA。 OK, 说了这么多关于邮件的基本概念，let’s get hands dirty，第一步先安装mutt（本文使用CentOS8环境，Ubuntu用户应该会更方便）: 1yum install mutt Basic Configurationmutt默认从系统范围的配置文件（“/etc/Muttrc”）读取其配置的默认值，该文件通常控制系统设置并为所有用户提供可行的默认配置。然后读取个人配置文件（“/.muttrc”或“/.mutt/muttrc”），这样，个人设置会根据需要覆盖系统设置。我们采用~/.mutt/muttrc对mutt进行配置。 mutt中的变量通过set var=value方式配置。存在仅需设置yes/no的toggle var（布尔变量），你可以为toggle var设置”ask-yes”或者”ask-no”以指定每次使用时给定默认答案进行提示。也可以通过 “unset”、”set var”、”set novar”简化布尔变量的设置。需要注意的是，你配置的mutt变量对应的功能在编译mutt时已启用才会成功设置，否则你会得到“unknown variable”的告警。所有的mutt配置参数分类可参考ConfigList。下面给出最基本的mutt配置： 123456# Basic configurationset ssl_force_tls = yesset abort_nosubject = noset timeout = 10set mail_check = 60set sort = &quot;reverse-date-received&quot; ssl_force_tls表示mutt与所有的远端服务器的连接需要通过TLS协议加密，如果不能成功建立连接，中断通信。mutt -v | grep tls能够打印--with-gnutls表示mutt支持TLS。 abort_nosubject的默认值是”ask-yes”，表示我们发送邮件还未写邮件主题时，该配置将会提示，默认值为”yes”。将该项设置为”no”，便无需确认。 mutt每次接收到键盘输入时便会更新所有目录的状态。我们也希望即使在空闲时也能收到新邮件的通知，而不需要按下按键。控制这种行为的变量是timeout。它表示等待用户输入的最大时间，以秒为单位。如果在指定的时间内没有接收到用户输入，便执行更新操作。变量的默认值是600秒，表示在没有输入的情况下，每10分钟接收一次更新。默认值太高，我们设置为10。 如前所述，每次收到用户输入时，mutt都会查找更新。键盘活动太频繁会导致过多的访问操作，为了限制这个频率，使用mail check变量。该变量表示两次扫描之间的最小时间(以秒为单位)。该变量的默认值是5，即使经常按下键，mutt也将每5秒搜索一次新邮件。该值还是太小，尤其是在多邮箱的场景下，可能因为频繁访问降低速度。 默认情况下，索引菜单(显示消息列表)中的电子邮件按日期升序排序，因此更新的电子邮件将显示在底部。要更改电子邮件的排序方式，我们可以使用和设置sort变量的值。在本例中，我们设置reverse-data-received让更新的电子邮件出现在列表的顶部。其他参数也可以用作排序因子，例如subject和size。 Retrieve emailMUA使用POP3/IMAP协议从邮件服务器下载邮件。两者的区别如下[3]： POP3(Post Office Protocol 3)：仅仅下载邮件服务器的inbox目录中的邮件到本地，不会下载sent、draft、deleted目录下的邮件。并且POP3不会同步，并且当email被下载到一台设备上时，email会从邮件服务器中删除。 IMAP(Internet Message Access Protocol)：允许在多个客户端上查看邮件（同步），IMAP会将邮件缓存到本地。IMAP还会同步各个设备的目录结构 上图展示了两台电脑都从同一email账号下载邮件（均使用POP3协议），两台电脑上的目录结构截然不同，因为POP3不会同步两台电脑中的目录。当有新邮件到来时，第一台电脑先下载了邮件，邮件便会从邮件服务器中删除，第二胎电脑是获取不到新邮件的。不过后面这个问题还好，很多邮件客户端可以设置leave a copy of messages on the server。 POP3和IMAP的比较，如下表所示： metrics POP3 IMAP view without Internet Yes NO All the folders can be seen NO YES All the folders and emails are synchronized NO YES Email stored on the mail server NO YES 由于IMAP默认在本地仅缓存(cache)邮件，并不下载邮件，所以默认在无网络的条件下，使用IMAP的MUA是无法阅读邮件的，但是现在很多使用IMAP的MUA都可以设置将邮件下载到本地，而非仅仅缓存。POP3协议由于会将邮件下载到本地（下载会删除邮件服务器中的邮件），从而能够节约邮件服务器的空间，然而本地下载的邮件需要备份以免磁盘损坏邮件丢失。 mutt -v | grep IMAP能够打印+USE_IMAP表示mutt支持IMAP。当前mutt版本已经支持IMAP。那么，我们直接使用mutt自带的IMAP功能下载邮件，关于IMAP相关的配置如下： 12345678910111213set from = &quot;foo.bar@gmail.com&quot;set realname = &quot;Foo Bar&quot;# Imap settingsset imap_user = &quot;foo.bar@gmail.com&quot;set imap_pass = &quot;&lt;mutt-app-specific-password&gt;&quot;# Remote gmail foldersset folder = &quot;imaps://imap.gmail.com/&quot;set spoolfile = &quot;+INBOX&quot;set postponed = &quot;+[Gmail]/Drafts&quot;set record = &quot;+[Gmail]/Sent Mail&quot;set trash = &quot;+[Gmail]/Trash&quot; from指定的是email header，此处填写你的邮箱地址。realname填写你的真实姓名。 imap_user是在IMAP服务器上访问其邮件的用户名，和from变量保持一致，此处以gmail账户为例。imap_pass是IMAP账户的密码，谷歌要求不使用Oauth2身份验证方法的应用必须使用特定于应用程序的密码。为了能够从mutt访问我们的gmail帐户，我们必须打开2-Step Verification，随后生成特定于应用程序的密码。 folder：mailbox的默认位置 spoolfile:新邮件到达mailbox时，归档的目录 postponed：存储待发送的邮件(草稿)的文件夹 record：存储已发送的邮件的文件夹 trash：存储已删除邮件的文件夹 在客户端执行mutt打开邮箱查看gmail邮件： Send emailMTA进行邮件转发使用SMTP协议(Simple Mail Transfer Protocol)。如下这段话，我认为是对SMTP协议的功能的一个良好概括[4]。 SMTP is basically a set of commands that authenticates and directs the transfer of email 更简单方式的记住S(ending) M(ail) T(o) P(eople)。下图展示了通过SMTP协议将邮件从SMTP client途径SMTP server传递到收件人的SMTP server，最终收件用户登录信箱通过POP3/IMAP下载邮件。 MTA可以分为两类：仅转发(relay-only)、全功能(full-fledged)[5]。 Relay-only MTAs: 或者称为Send-only MTAs、small MTAs(SMTP clients)[6]，此类MTA仅将你的email转发到另一个服务器，如果你像我一样仅仅想发送自己的Gmail邮件，此类MTA是最好的选择。SMTP client仅执行某些特定的功能，而不像Full-fledged MTA一样运行完成的SMTP服务器，占用大量的资源开销。这样的MTA不会监听传入的消息，尽在需要发送邮件的时候运行。small MTA通常作为MSA即邮件发送的第一站。 Full-fledged MTAs：也称为mail hub，能够处理Internet邮件传送的所有细节，通常这类MTA从Relay-Only MTA接收邮件再进行转发。邮件在Internet的中间MTA转发漫游时，这些MTA使用full-fledged MTA比较合适。 本文仅考虑MSA即Relay-only MTA，选取软件作为MSA应该考虑如下因素： MTA是否可以对邮件进行排队，以便在出现故障时稍后发送 MTA可以取代MDA?如果可以，它将处理来自系统的所有邮件。 MTA是否支持连接到ISP SMTP服务器的要求？这些要求可能包括特定的身份验证或TLS。 mutt早已支持ESMTP/SMTP，mutt -v | grep SMTP能够打印+USE_SMTP表示mutt支持SMTP。当前mutt版本已经支持SMTP。那么，我们直接使用mutt自带的SMTP功能发送邮件，此时，mutt自己可以作为MSA。如果您需要选择功能更为复杂的MSA，请参考SendmailAgents。关于SMTP相关的配置如下： 123# smtpset smtp_url = &quot;smtp://foo.bar@smtp.gmail.com:587&quot;set smtp_pass = $imap_pass 测试邮件发送: 123456[root@localhost ~]# proxychains4 echo &quot;mail test&quot; | mutt -s &quot;test email&quot; buweilv@qq.com[proxychains] config file found: /etc/proxychains.conf[proxychains] preloading /usr/local/lib/libproxychains4.so[proxychains] DLL initCould not connect to smtp.gmail.com (Connection refused).Could not send the message. 邮件发送失败。使用mutt -d选项输出调试信息，调试级别从15，日志详细级别相应提高。调试信息输出到’/.muttdebug*’。上面的发送失败很可能是因为网络不稳定。gmail smtp使用更为安全的TLS协议，端口为587。ssl_ca_certificates_file指定的文件包含了所有受信任的CA证书。使用这些CA证书之一签名的任何服务器证书也会被自动接受(仅GnuTLS)。使用mutt -D查看默认配置： 1234[root@localhost ~]# mutt -D | grep ssl_ca_certificates_filessl_ca_certificates_file=&quot;/etc/ssl/certs/ca-bundle.crt&quot;[root@localhost ~]# rpm -qf /etc/ssl/certs/ca-bundle.crtca-certificates-2020.2.41-80.0.el8_2.noarch 故使用TLS协议的SMTP服务应该安装ca-certificates。Ubuntu环境下的文件命名不同，包名也不同。 Interact with mutt之前我们使用简单的mutt命令行完成邮件的收发工作。但是，进入mutt交互界面之后，我们应该如何读取邮件，对邮件分类，并且在mutt客户端内编辑邮件、回复邮件呢？首先，我们得了解mutt界面的功能区域。mutt提供不同的窗口(menu)与用户进行交互，这些窗口大多基于行(line-based)/条目(entry-based)或基于页面(page-based)。 基于行的窗口是所谓的“索引”(index)窗口（列出当前打开的文件夹的所有邮件）或“别名”(alias)窗口（允许您从列表中选择收件人）。 基于页面的窗口的例子是“pager”（一次显示一封邮件）或“帮助”窗口，其中列出了所有可用的绑定键。下图以索引窗口为例，展示mutt交互界面的基本构成。图中的context senstive表示此处的内容和窗口类型有关。交互界面主要由以下元素构成： context sensitive help line 窗口具体内容 context sensitive status line 命令行：显示信息和错误消息以及提示和输入交互式命令 mutt共存在如下窗口(menu)： index: 启动Mutt时最先看到的窗口，展示当前打开邮箱中的email。index窗口是line-based，每一行从左到右分别表示邮件编号、标志（新电子邮件，重要电子邮件，已转发或回复的电子邮件，已标记电子邮件，…）、邮件发送日期、email大小、主题。如果mutt配置set sort = &quot;threads&quot;，邮件按照thread（对话）的形式层级展开：当您回复的电子邮件，被对方回复，您可以在下面的“子树”中看到对方的电子邮件。如果您订阅了邮件列表，这种显示方式非常有效。 pager：负责显示电子邮件内容。pager的顶部有email header中的主要信息，如发件人，收件人，主题等。你可以配置mutt展示更多email header内容。email header下方便是邮件正文，如果邮件包含附件，会在邮件正文下方显示。如果附件就是文本文件，其内容会直接在pager中显示。为了有更好的观感，可以在mutt中配置在pager中为不同内容显示不同颜色。实际上，任何可以用正则表达式描述的内容都可以着色，例如网址、邮箱地址或表情符号。 file browser：是本地或远程文件系统的接口，尚未遇到。 sidebar：显示了所有邮箱的列表。该列表可以打开和关闭，它可以主题化，列表样式可以配置。 help：旨在为用户提供快速帮助。它列出了键绑定的当前配置及其相关命令(commands)，包括简短的描述，以及当前未绑定函数(或者，可以通过Mutt命令提示符调用它们)。 compose menu：撰写窗口具有一个拆分窗口，其中包含收件人、抄送人的信息。另外用户还可以对邮件进行加密、签名。 attachment menu：mutt支持发送和接收任意MIME类型的消息，附件窗口详细地展示了邮件的结构。 alias menu：帮助用户查找消息的收件人。对于需要联系很多人的用户来说，不需要完全记住地址或名字。mutt的别名机制以及别名窗口还具有按更短的别名(实际别名)对多个地址进行分组的功能，这样用户就不必手动选择每个收件人。 mutt作为文本邮件客户端，需要完全依赖键盘完成基本操作。当前介绍基于行/条目窗口的常规按键，以index窗口为例： 移动：k/j 上下移动, Z/z 上下翻页, =/* 跳转到第一封/最后一封邮件， 跳至序号处（不进入邮件） 基本操作：q退出当前窗口，打开选中邮件，? 查看当前窗口的键绑定 /在当前文件夹搜索 针对index窗口有些专有功能的按键： d:删除当前邮件, s:将邮件移动至指定文件夹, m:创建新邮件, r:回复当前邮件 Reference[1] Email agent (infrastructure) https://en.wikipedia.org/wiki/Email_agent_(infrastructure)#cite_note-modularmonolithic-schroder-1[2] SendmailAgents https://gitlab.com/muttmua/mutt/-/wikis/SendmailAgents[3] POP3 vs IMAP - What’s the difference? https://www.youtube.com/watch?v=SBaARws0hy4&amp;t=337s[4] What is SMTP - Simple Mail Transfer Protocol https://www.youtube.com/watch?v=PJo5yOtu7o8[5] Postfix vs. Sendmail vs. Exim https://blog.mailtrap.io/postfix-sendmail-exim/?amp=1[6] MTA: Mail Transport Agent (SMTP server) https://gitlab.com/muttmua/mutt/-/wikis/MailConcept","categories":[{"name":"tools","slug":"tools","permalink":"https://system-thoughts.github.io/categories/tools/"}],"tags":[{"name":"mutt","slug":"mutt","permalink":"https://system-thoughts.github.io/tags/mutt/"},{"name":"社区","slug":"社区","permalink":"https://system-thoughts.github.io/tags/%E7%A4%BE%E5%8C%BA/"}]},{"title":"【译文】Memory Ordering at Compile Time","slug":"【译文】Memory Ordering at Compile Time","date":"2021-03-22T11:21:52.000Z","updated":"2023-01-18T05:32:06.164Z","comments":true,"path":"posts/6c068df6/","link":"","permalink":"https://system-thoughts.github.io/posts/6c068df6/","excerpt":"我们编写的C/C++代码在处理器上实际的执行顺序和其在源码中的顺序可能并不相同。编译器会通过指令重排优化编译效果，CPU也会通过乱序执行优化执行效率。本文将介绍编译时的内存重排。","text":"我们编写的C/C++代码在处理器上实际的执行顺序和其在源码中的顺序可能并不相同。编译器会通过指令重排优化编译效果，CPU也会通过乱序执行优化执行效率。本文将介绍编译时的内存重排。 原文链接：https://preshing.com/20120625/memory-ordering-at-compile-time/ 您写的C/C++源码与其实际在CPU上执行的内存操作顺序可能不同，内存操作可能会根据某些规则重新排序。为了让代码运行得更快，编译器(在编译时)和处理器(在运行时)都会对内存顺序进行更改。编译器开发人员和CPU供应商普遍遵循的内存重排的基本规则可以表述为： Thou shalt not modify the behavior of a single-threaded program. 依据单线程程序行为不可修改的原则，程序员在写单线程的代码时基本不会注意到内存重排。在多线程编程中，它也经常被忽略，因为互斥(mutexes)、信号量(semaphores)和事件(events)都是为了防止在它们的调用位置附近进行内存重排而设计的。只有在使用无锁技术时（线程之间共享内存而没有任何相互排斥的情况），内存重排的效果才能够被明显地观察到。 注意，在为多核平台编写无锁代码时，有些情况可以避免内存重排的麻烦，正如我在introduction to lock-free programming中提到的那样，可以利用顺序一致(sequentially consistent)的类型，例如Java的volatile变量或C ++ 11原子变量，这可能会牺牲一点性能。本文我不会细究这些情况，我将重点讨论编译器对常规、非顺序一致性类型的内存排序的影响。 Compiler Instruction Reordering如您所知，编译器的工作是将人类可读的源代码转换为CPU可读的机器代码。在此转换过程中，编译器有很大的自由度。编译器在保证单线程行为不变的情况下有指令重排的自由。指令重排通常在启用编译器优化时发生，考虑以下函数： 1234567int A, B;void foo()&#123; A = B + 1; B = 0;&#125; 使用GCC 4.6.1在没有编译优化的情况下，会生成如下机器代码： 12345678$ gcc -S -masm=intel foo.c$ cat foo.s ... mov eax, DWORD PTR _B (redo this at home...) add eax, 1 mov DWORD PTR _A, eax mov DWORD PTR _B, 0 ... 对全局变量B的内存存储发生在对A的内存存储之后，和源码中一样。-O2编译优化之后的机器代码如下： 12345678$ gcc -O2 -S -masm=intel foo.c$ cat foo.s ... mov eax, DWORD PTR B mov DWORD PTR B, 0 add eax, 1 mov DWORD PTR A, eax ... 这一次，编译器将全局变量B的存储放到全局变量A的存储之前。这并未打破内存排序的基本规则，单线程永远感知不到差别。 然而，在编写无锁代码时，此类编译器重新排序可能会导致问题。下面的代码是一个经常被引用的示例，全局变量IsPublished用于指示全局变量Value的修改已经完成： 12345678int Value;int IsPublished = 0; void sendValue(int x)&#123; Value = x; IsPublished = 1;&#125; 想象一下，如果编译器将IsPublished的内存写重排到Value内存写之前，会发生什么？即使是在单处理器系统上，也会遇到问题:一个线程的两次内存写操作可能会被OS抢占，让其他线程相信Value已经更新，而实际却没有。当然，编译器可能未对这些操作进行重新排序，生成的机器代码作为无锁操作可以在任何强内存模型(strong memory model)的多核CPU（例如x86/64）上或在单处理器环境中正常运行。如果没有发生内存重排，我们会很幸运。然而，更好的做法是认识到共享变量存在内存重新排序的可能性，并确保正确的执行顺序。 Explicit Compiler Barriers防止编译器内存重排最简单的方法是使用编译器屏障(compiler barrier)指令。我们在上一篇文章中已经提及编译器屏障。下面是GCC的完全编译器屏障(full compiler barrier)。Microsoft C++的_ReadWriteBarrier具有相同功能。 12345678int A, B;void foo()&#123; A = B + 1; asm volatile(&quot;&quot; ::: &quot;memory&quot;); B = 0;&#125; 加上完全编译器屏障并保持编译器优化，观察内存存储指令并未重排： 12345678$ gcc -O2 -S -masm=intel foo.c$ cat foo.s ... mov eax, DWORD PTR _B add eax, 1 mov DWORD PTR _A, eax mov DWORD PTR _B, 0 ... 同样，如果我们要保证sendMessage示例在单处理器系统数正常工作，那么我们至少必须在此处引入编译器屏障。不仅发送操作需要编译器屏障防止内存写操作重排，接收方也需要在内存读操作之间加入屏障。 123456789101112131415161718192021#define COMPILER_BARRIER() asm volatile(&quot;&quot; ::: &quot;memory&quot;)int Value;int IsPublished = 0;void sendValue(int x)&#123; Value = x; COMPILER_BARRIER(); // prevent reordering of stores IsPublished = 1;&#125;int tryRecvValue()&#123; if (IsPublished) &#123; COMPILER_BARRIER(); // prevent reordering of loads return Value; &#125; return -1; // or some other value to mean not yet received&#125; 如前所述，编译器屏障足以防止单处理器系统上的内存重排。如今在多核计算已经成为常态。如果我们想要确保我们的指令交互在任何架构的多处理器环境中都以期望的顺序发生，那么编译器屏障是不够的。我们需要发送CPU fence指令，或执行任何在运行时充当内存屏障的操作。我将在下一篇文章中会更多地介绍这块内容，内存屏障就像源代码版本控制操作一样。 Linux内核以宏的形式提供了多个CPU fence指令，例如smb_rmb。这些宏在单处理器系统中会被编译成简单的编译器屏障。 Implied Compiler Barriers还有其他方法防止编译器指令重排。刚刚提及的CPU fence指令也可以充当编译器屏障。这是PowerPC的CPU fence指令，在GCC中定义为宏： 1#define RELEASE_FENCE() asm volatile(&quot;lwsync&quot; ::: &quot;memory&quot;) 在代码中加入RELEASE_FENCE不仅可以防止某些类型的处理器重排，而且能够确保阻止编译器重排。在sendValue函数中使用RELEASE_FENCE可以确保其在多处理器环境中安全。 123456void sendValue(int x)&#123; Value = x; RELEASE_FENCE(); IsPublished = 1;&#125; 在C++11原子标准库中，每个non-releaxed的原子操作都可以作为编译器屏障： 123456789int Value;std::atomic&lt;int&gt; IsPublished(0);void sendValue(int x)&#123; Value = x; // &lt;-- reordering is prevented here! IsPublished.store(1, std::memory_order_release);&#125; 如您所料，每个包含编译器屏障的函数(即使是内联函数)也可充当编译器屏障。（但是，Microsoft文档表明，早期版本的Visual C++编译器中可能不是这种情况。Tsk，tsk！） 123456void doSomeStuff(Foo* foo)&#123; foo-&gt;bar = 5; sendValue(123); // prevents reordering of neighboring assignments foo-&gt;bar2 = foo-&gt;bar;&#125; 事实上，不论函数中是否包含编译器屏障指令，大多数函数调用可以作为编译器屏障。也有函数调用不会作为编译器屏障：内联函数、使用pure属性声明的函数以及链接时生成的代码。除此之外，对外部函数的调用甚至比编译器屏障更为强大，因为编译器不知道外部函数的副作用。仔细想想，还是很有道理。假设上面代码片段中sendValue的实现在外部库中。编译器如何知道sendValue不依赖于foo-&gt;bar的值?它如何知道sendValue将不会修改foo-&gt;bar的内存?编译器无法做出此类假设，因此，为了遵守内存排序的基本规则，它不能对sendValue周围的任何内存操作重排。同样，即便开启了编译优化，sendValue函数调用完成之后，不能假设foo-&gt;bar的值仍然为5，需要从内存中读取foo-&gt;bar的值。 12345678910$ gcc -O2 -S -masm=intel dosomestuff.c$ cat dosomestuff.s ... mov ebx, DWORD PTR [esp+32] mov DWORD PTR [ebx], 5 // Store 5 to foo-&gt;bar mov DWORD PTR [esp], 123 call sendValue // Call sendValue mov eax, DWORD PTR [ebx] // Load fresh value from foo-&gt;bar mov DWORD PTR [ebx+4], eax ... 如您所见，在许多情况下，编译器指令重排是被禁止的，甚至编译器需要从内存重新加载某些值。我想，正是因为这些隐藏规则导致人们长期以来一直认为volatile数据类型在正确编写的多线程代码中不是必需的。 Out-Of-Thin-Air Stores指令重排会让无锁编程变得棘手吗?在c++ 11标准化之前，技术上，没有任何规则可以阻止编译器使用更糟糕的技巧。特别是，在以前没有对共享内存写的情况下，编译器可以自由地引入共享内存写操作。下面这个例子在Hans Boehm在多篇文章中均有提及： 1234567int A, B;void foo()&#123; if (A) B++;&#125; 尽管实际上不太可能写这样的代码，但是没有什么可以阻止编译器在检查A之前，将B提升到寄存器，从而会有以下的等效内容： 1234567void foo()&#123; register int r = B; // Promote B to a register before checking A. if (A) r++; B = r; // Surprise! A new memory store where there previously was none.&#125; 上述代码仍然遵守了最基本的内存排序规则。单线程应用程序对“将B提升到寄存器”毫无感知。但是在多线程环境中，foo函数会清除在其他线程中所做的任何修改–即便是A为0的情况下。foo函数的本意并非如此。尽管我们数十年来一直在使用C/++写多线程和无锁代码，因为这种晦涩、技术上的不可能性让人们一直说C++不支持线程。 我不知道是否有人在实践中成为这种“out-of-thin-air”的受害者。或许是我们通常编写的无锁代码类型没有这样的优化模式。如果我遇到了这种编译器转换，我想我得好好调教下我的编译器。无论如何，在会引入数据竞争的情况下，新的C++11标准明确禁止编译器的此类行为。C++11工作草案的§1.10.22中可以找到： Compiler transformations that introduce assignments to a potentially shared memory location that would not be modified by the abstract machine are generally precluded by this standard. Why Compiler Reordering?正如我在文章开头提到的，编译器修改内存交互顺序的原因与处理器进行性能优化的原因相同。这种优化是现代CPU复杂性的直接结果。我有个大胆的怀疑：在80年代早期，当cpu最多只有几十万个晶体管的时候，编译器做了大量的指令重排。但从那以后，摩尔定律为CPU设计者提供了大约10000倍数量的晶体管，而这些晶体管被花费在诸如流水线、内存预取、ILP以及最近的多核等技巧上。由于这些特性，我们已经看到某些架构中程序指令的顺序会对性能产生显著的影响。1993年Intel发布的第一款奔腾处理器，带有所谓的U和v管道，是我记得的第一个流水线和指令顺序的重要性的处理器。然而，最近，我在Visual Studio中执行x86反汇编时，我惊讶地发现指令的重排是如此之少。另一方面，我在Playstation 3上进行SPU拆解的时候，发现编译器真的很厉害。这些只是轶事。它可能无法反映其他人的经验，也不应该影响我们在无锁代码中强制执行内存排序的方式。","categories":[{"name":"translation","slug":"translation","permalink":"https://system-thoughts.github.io/categories/translation/"},{"name":"lock-free","slug":"translation/lock-free","permalink":"https://system-thoughts.github.io/categories/translation/lock-free/"}],"tags":[{"name":"lock-free","slug":"lock-free","permalink":"https://system-thoughts.github.io/tags/lock-free/"},{"name":"memory-reordering","slug":"memory-reordering","permalink":"https://system-thoughts.github.io/tags/memory-reordering/"}]},{"title":"【译文】当场抓获内存重排","slug":"当场抓获内存重排","date":"2021-03-22T03:29:29.000Z","updated":"2023-01-18T05:32:06.168Z","comments":true,"path":"posts/8d2fe256/","link":"","permalink":"https://system-thoughts.github.io/posts/8d2fe256/","excerpt":"","text":"原文链接：https://preshing.com/20120515/memory-reordering-caught-in-the-act/ 用C/C++编写无锁代码时，必须特别注意强制执行正确的内存顺序。否则，可能会发生令人惊讶的事情。Intel SDM卷3第8.2.3节举了几个例子。这是最简单的例子之一。假设您在内存中保存了两个整数X和Y，初始值都为0。两个并行运行的处理器执行以下机器代码：这是一个绝佳的例子说明CPU排序(CPU ordering)。每个处理器将1存储到其中一个整数中，然后将另外一个整数加载到寄存器中。很自然地我们期望:无论哪个处理器先将1写入内存，另一个处理器可以将该值读回来，这意味着我们最终应该得到r1 = 1, r2 = 1，或者两者都有。然而Intel规范表明r1和r2都等于0也是一种合法的结果。Intel x86/64处理器与大多数处理器系列一样，允许根据某些规则对内存操作的机器指令进行重新排序，只要不改变单个线程的执行结果即可。具体地说，允许每个处理器将其上的内存写操作(store)推迟(delay)到不同位置的内存加载(load)操作之后。每个处理器上的指令可以重排如下： Let’s Make It Happen眼见为实，我编写了一个小示例程序来展示这种重新排序。你可以在此下载源码。示例代码包含Win32版本和POSIX版本。它产生两个工作线程，它们无限期地重复图中的例子，而主线程则同步它们的工作并检查每个结果。下面是第一个工作线程的源代码。X, Y, r1和r2都是全局变量，POSIX信号量用于协调每个循环的开始和结束以及主线程的检查工作。 1234567891011121314151617181920212223sem_t beginSema1;sem_t endSema;int X, Y;int r1, r2;void *thread1Func(void *param)&#123; MersenneTwister random(1); // Initialize random number generator for (;;) // Loop indefinitely &#123; sem_wait(&amp;beginSema1); // Wait for signal from main thread while (random.integer() % 8 != 0) &#123;&#125; // Add a short, random delay // ----- THE TRANSACTION! ----- X = 1; asm volatile(&quot;&quot; ::: &quot;memory&quot;); // Prevent compiler reordering r1 = Y; sem_post(&amp;endSema); // Notify transaction complete &#125; return NULL; // Never returns&#125;; 在每个事务之前添加一个短暂的随机延迟，以错开线程事务开始执行的时间。我们尽量让两个线程的指令执行重叠，随机延迟通过MersenneTwister实现，我们在测量锁竞争以及验证递归互斥量时用到过。不要被代码中的asm volatile行吓到。这只是一个伪指令，告诉GCC编译器在生成机器代码时不要重排存储和加载。我们可以通过汇编代码验证。如下所示，正如预期的那样，存储和加载按照预期的顺序进行。随后的指令将寄存器eax中的内容写入到全局变量r1中。 1234567$ gcc -O2 -c -S -masm=intel ordering.cpp$ cat ordering.s ... mov DWORD PTR _X, 1 mov eax, DWORD PTR _Y mov DWORD PTR _r1, eax ... 主线程源代码如下所示。它执行所有管理工作。初始化后，它将无限循环，在每次迭代启动线程之前，将X和Y重置为0。要特别注意:所有对共享内存的写操作都在sem_post之前发生，而所有对共享内存的读操作都在sem_wait之后发生。 与主线程通信时，工作线程赢遵循相同的规则。可以通过信号量让我们在所有平台上支持获取和释放语义(acquire and release semantics)。这样就可以保证X = 0和Y = 0的初始值将完全传播到工作线程，并且r1和r2的结果值也会传播到主线程。换言之，信号量可以防止内存重排，使我们可以完全专注于实验本身！ 12345678910111213141516171819202122232425262728293031323334int main()&#123; // Initialize the semaphores sem_init(&amp;beginSema1, 0, 0); sem_init(&amp;beginSema2, 0, 0); sem_init(&amp;endSema, 0, 0); // Spawn the threads pthread_t thread1, thread2; pthread_create(&amp;thread1, NULL, thread1Func, NULL); pthread_create(&amp;thread2, NULL, thread2Func, NULL); // Repeat the experiment ad infinitum int detected = 0; for (int iterations = 1; ; iterations++) &#123; // Reset X and Y X = 0; Y = 0; // Signal both threads sem_post(&amp;beginSema1); sem_post(&amp;beginSema2); // Wait for both threads sem_wait(&amp;endSema); sem_wait(&amp;endSema); // Check if there was a simultaneous reorder if (r1 == 0 &amp;&amp; r2 == 0) &#123; detected++; printf(&quot;%d reorders detected after %d iterations\\n&quot;, detected, iterations); &#125; &#125; return 0; // Never returns&#125; 我们看下在CentOS8 AMD Ryzen 5 4600H环境上的运行结果假设您现在想消除内存重排。至少有两个方法可以做到，一种方法是设置线程亲和性，使得两个线程在同一核上工作。没有一种可移植的方法可以设置pthread的亲和性，但在Linux上可以如下完成： 12345cpu_set_t cpus;CPU_ZERO(&amp;cpus);CPU_SET(0, &amp;cpus);pthread_setaffinity_np(thread1, sizeof(cpu_set_t), &amp;cpus);pthread_setaffinity_np(thread2, sizeof(cpu_set_t), &amp;cpus); 更改之后，内存重排消失。处理器不会看到自身的操作乱序，即便线程会在任意时间被抢占和重新调度回来。当然将两个线程都绑定到同一CPU core上会导致其他CPU core未被使用。值得一提的是，我在Playstation 3上编译并运行了这个示例，没有检测到内存重排。这表明(但没有证实)PPU内部的两个硬件线程可以有效地充当单个处理器支持非常细粒度的硬件调度。 使用StoreLoad屏障防止内存重排此示例中防止内存重排的另一种方法是在两条指令之间引入CPU屏障(CPU barrier)。我们需要StoreLoad屏障防止对load之后的store进行重排。在x86/64处理器上，没有特定的StoreLoad屏障指令，但是有一些指令可以做到这一点，甚至更多。mfence指令是一个完全的内存屏障，可防止任何类型的内存重新排序。在GCC中可以实现如下： 123456789101112for (;;) // Loop indefinitely&#123; sem_wait(&amp;beginSema1); // Wait for signal from main thread while (random.integer() % 8 != 0) &#123;&#125; // Add a short, random delay // ----- THE TRANSACTION! ----- X = 1; asm volatile(&quot;mfence&quot; ::: &quot;memory&quot;); // Prevent memory reordering r1 = Y; sem_post(&amp;endSema); // Notify transaction complete&#125; 同样地，可以通过查看汇编代码验证内存屏障的存在： 123456...mov DWORD PTR _X, 1mfencemov eax, DWORD PTR _Ymov DWORD PTR _r1, eax... 经过这样的修改，内存重排消失了，且允许两个线程在不同的CPU核上运行。 其他硬件平台上的类似指令mfence并不是x86/64平台上唯一的完全内存屏障的指令。任何锁定的指令（例如xchg）也将充当完全内存屏障-前提是您不使用本示例不使用的SSE指令或write-combined memory。在Visual Studio 2008中，当您使用MemoryBarrier内部函数时，Microsoft C ++编译器会生成xchg指令。mfence指令是x86/64架构独有的。可以通过预处理宏编写更具可移植性的代码。Linux内核将其封装在smp_mb宏中，相关的宏还有smp_rmb和smp_wmb，以及其他架构的实现。例如，在PowerPC上，smp_mb通过sync实现。 不同的CPU系列具有特定的指令强制内存排序，每个编译器通过不同的指令公开它们，每个跨平台项目都实现自己的可移植层……这些都不能简化无锁编程！这也是最近引入了C++ 11标准库的部分原因。这是一种使事情标准化的尝试，目的是使编写可移植的无锁代码更加容易。","categories":[{"name":"translation","slug":"translation","permalink":"https://system-thoughts.github.io/categories/translation/"},{"name":"lock-free","slug":"translation/lock-free","permalink":"https://system-thoughts.github.io/categories/translation/lock-free/"}],"tags":[{"name":"lock-free","slug":"lock-free","permalink":"https://system-thoughts.github.io/tags/lock-free/"},{"name":"memory-reordering","slug":"memory-reordering","permalink":"https://system-thoughts.github.io/tags/memory-reordering/"}]},{"title":"【译文】Atomic vs. Non-Atomic Operations","slug":" Non-Atomic Operations","date":"2021-03-17T15:21:36.000Z","updated":"2023-01-18T05:32:06.128Z","comments":true,"path":"posts/cc000ee5/","link":"","permalink":"https://system-thoughts.github.io/posts/cc000ee5/","excerpt":"在阅读内核源码spin_lock的实现时，发现有大量关于lock-free编程的知识，如smp_cond_load_relaxed、atomic_try_cmpxchg_acquire的实现。延展阅读，发现了这些涉及到memory order、atomic、cache consistency等知识点。经过google，我发现Preshing on Programming这个博客对lock-free的方方面面介绍的较为详细，并且作者将这些知识点在Mintomic(C/C++ lock-free programming API)项目中付诸实践。","text":"在阅读内核源码spin_lock的实现时，发现有大量关于lock-free编程的知识，如smp_cond_load_relaxed、atomic_try_cmpxchg_acquire的实现。延展阅读，发现了这些涉及到memory order、atomic、cache consistency等知识点。经过google，我发现Preshing on Programming这个博客对lock-free的方方面面介绍的较为详细，并且作者将这些知识点在Mintomic(C/C++ lock-free programming API)项目中付诸实践。 原文链接： https://preshing.com/20130618/atomic-vs-non-atomic-operations/ 网络上对原子操作的介绍过多集中在原子读-修改-写（RMW）操作上。然而，原子读(atomic load)和写(atomic store)同样重要。在这篇文章中，我将在处理器级别和C/C++语言级别比较原子读和原子写以及它们的非原子操作。在此过程中我们将阐明C++ 11的“数据竞争”(data race)的概念。![](nonatomic.png atomic)在共享内存上的一个操作相对于其他线程而言是单步完成的，那么这个操作就是原子的(atomic)。当在共享变量上执行原子存储(atomic store)时，其他线程无法观察到修改到一半的状态(modification half-complete)。当对共享变量执行原子加载(atomic load)时，它读取在某个时刻出现的完整值(entire value)。非原子加载和存储不能提供这些保证。没有这些保证，就不可能进行无锁编程(lock-free programming)，因为您永远不可能让不同的线程同时操作一个共享变量。我们可以把它制定为一条规则： 任何时候，两个线程并发地操作一个共享变量，其中一个操作执行写操作，两个线程都必须使用原子操作。 如果违反了这一规则，即任何一个线程都使用了非原子操作，那么就会出现C++ 11标准所称的数据竞争(data race，不要与Java的数据竞争概念混淆，这是不同的，是一种更通用的竞争条件)。C++ 11标准并没有告诉你为什么数据竞争是糟糕的，只是存在数据竞争时，会产生一个未定义的行为(1.10.21)。此类数据竞争不佳的真正原因实际上很简单：它们导致读取损坏(torn reads)和写入损坏(torn writes)。一个内存操作可以是非原子的，因为它使用多条CPU指令；即便是使用单个CPU指令的内存操作也可能是非原子的。亦或您在编写可移植的代码时你无法做出假设认为其实原子操作，则该内存操作有可能也是非原子的。让我们看几个例子。 由于多条CPU指令导致的非原子操作假设有一个初始值为0的64位全局变量。 1uint64_t sharedValue = 0; 某个时候，你可以为该变量赋64位的数值。 1234void storeValue()&#123; sharedValue = 0x100000002;&#125; 使用GCC将此函数编译为32位x86程序，它将生成以下机器代码。 1234567$ gcc -O2 -S -masm=intel test.c$ cat test.s ... mov DWORD PTR sharedValue, 2 mov DWORD PTR sharedValue+4, 1 ret ... 如您所见，编译器使用两条单​​独的机器指令实现了64位赋值操作。第一条指令将低32位设置为0x00000002，第二条指令将高32位设置为0x00000001。显然，此赋值操作不是原子的。如果sharedValue被不同的线程并发访问，则可能会出错： 线程正在执行storeValue操作期间的两条mov指令被其他线程抢断，此时共享内存中保留的是0x0000000000000002 - 写损坏。此时，如果另一个线程读取sharedValue，它将接收到这个完全错误的值。 更糟糕的是，线程正在执行storeValue操作期间的两条mov指令被其他线程抢断，另外一个线程在第一个线程恢复之前修改了sharedValue，这将导致永久的写损坏：一个线程写入了高32位，另一个线程写入了低32位。 在多核环境上，甚至不需要抢占就会导致写损坏。一个核上的线程正在执行storeValue，同时另一个核上的线程正在读sharedValue，其会看到共享变量被部分修改的状态 并发读`sharedValue``会带来一系列问题： 123456789101112uint64_t loadValue()&#123; return sharedValue;&#125;$ gcc -O2 -S -masm=intel test.c$ cat test.s ... mov eax, DWORD PTR sharedValue mov edx, DWORD PTR sharedValue+4 ret ... 编译器也使用两条机器指令实现了加载操作:第一个将较低的32位读取到eax中，第二个将较高的32位读取到edx中。在这种情况下，如果对sharedValue的并发存储在两条指令之间变得可见，即使并发存储是原子的，也会导致读取损坏。 上述问题不仅理论上存在。Mintomic的测试套件包括一个称为test_load_store_64_fail的测试用例，其中一个线程使用普通赋值运算符将64位值存储到单个变量，而另一个线程从同一变量重复执行普通读取，以验证每个结果。如预期的那样，在多核x86-32环境上，该测试始终失败。 非原子CPU指令单指令的内存操作也可能是非原子的。例如，ARMv7指令集包含strd指令，该指令将两个32位源寄存器的内容存储到内存中的单个64位值。 1strd r0, r1, [r2] 某些ARMv7处理器上，这条指令不是原子的。当处理器看到这条指令时，它实际上会在幕后执行两个单独的32位存储(A3.5.3)。另一个核上运行的线程可能会观察到写损坏。甚至在单核设备上也可能发生写入中断：在两个内部32位存储之间可能会发生系统中断（例如，用于计划的线程上下文切换）！ 在这种情况下，当线程从中断中恢复时，它将再次重新启动strd指令。再举一个例子，在x86上，如果内存操作数是自然对齐的，则32位mov指令是原子的，否则是非原子的。换句话说，仅当32位整数位于4的精确倍数的地址上时，原子性才能得到保证。Mintomic的另一个测试用例test_load_store_32_fail可以验证。此测试在x86上一直成功，但如果将sharedInt强制放到未对齐的地址，它将失败。在我的Core 2 Quad Q6600上，当sharedInt越过缓存行边界时，测试失败： 12345678// Force sharedInt to cross a cache line boundary:#pragma pack(2)MINT_DECL_ALIGNED(static struct, 64)&#123; char padding[62]; mint_atomic32_t sharedInt;&#125;g_wrapper; 已经介绍了足够多处理器级别的原子性，接下来看看C/C++语言级别的原子性。 假定所有C/C++操作都是非原子的在C和C++中，所有操作都假定为非原子操作，即便是普通的32位整数赋值。除非编译器或硬件供应商另行指定。 123456uint32_t foo = 0;void storeFoo()&#123; foo = 0x80286;&#125; 语言标准并未提及内存操作的原子性。整数赋值也许是原子的，也许不是。由于非原子操作不作任何保证，根据定义，C语言中的普通整数赋值是非原子的。 实际情况下，我们通常对程序运行的目标平台有更多的了解。例如，在所有现代x86，x64，Itanium，SPARC，ARM和PowerPC处理器上，只要目标变量自然对齐，纯32位整数赋值就是原子的。您可以通过查阅处理器手册和/或编译器文档来进行验证。在游戏行业中，我可以告诉您，很多32位整数分配都依赖于此特定保证。 但是，在编写真正的可移植C/C++程序时，长期以来我们遵循“假装除了语言标准告诉我们的知识之外，一无所知”的传统。可移植的C/C++程序应该被设计在过去、现在和想象中的所有可能的计算设备上运行。我倾向于将内存操作想象为在一台摇杆机上进行摇杆，无法得知最终的结果：在这样的机器上，你肯定不希望在执行普通赋值的同时执行并发读;最终读取的可能是一个完全随机的值。 C++11终于引入了可移植的原子加载和存储:C++11原子库。使用C++11原子库执行的原子加载和存储甚至可以在上述虚拟计算机上工作，即使C++11原子库必须秘密地加互斥锁保证每个操作的原子性。我上个月发布的Mintomic库，该库不支持那么多平台，但可以在多个较老的编译器上运行，是手动优化且可以保证是无锁的。 宽松的原子操作回顾本文最开始的sharedValue示例。我们将使用Mintomic对其进行重写使其能够在Mintomic支持的所有平台上原子执行所。首先，我们必须将sharedValue声明为Mintomic的原子数据类型。 123#include &lt;mintomic/mintomic.h&gt;mint_atomic64_t sharedValue = &#123; 0 &#125;; mint_atomic64_t类型可以保证每个平台上原子访问的正确内存对齐。这很重要，例如，与Xcode 3.2.5捆绑在一起的用于ARM的GCC 4.2编译器不能保证将uint64_t8字节对齐。在storeValue中，必须执行mint_store_64_relaxed而非执行简单的非原子赋值操作。 1234void storeValue()&#123; mint_store_64_relaxed(&amp;sharedValue, 0x100000002);&#125; 类似的，loadValue必须调用mint_load_64_relaxed实现。 1234uint64_t loadValue()&#123; return mint_load_64_relaxed(&amp;sharedValue);&#125; 使用C++ 11的术语，这些函数现在不受数据竞争。并发执行时，无论代码是在ARMv6/ARMv7（Thumb或ARM模式）、x86、x64还是PowerPC上运行，读取或写入都不会被破坏。如果您想知道mint_load_64_relaxed和mint_store_64_relaxed的实现，那么这两个函数都会扩展为x86上的内联cmpxchg8b指令；其他平台查阅Mintomic的实现。这是用C++11写成的完全一样的东西: 12345678910111213#include &lt;atomic&gt;std::atomic&lt;uint64_t&gt; sharedValue(0);void storeValue()&#123; sharedValue.store(0x100000002, std::memory_order_relaxed);&#125;uint64_t loadValue()&#123; return sharedValue.load(std::memory_order_relaxed);&#125; 您会注意到，Mintomic和C++ 11示例都使用了宽松的原子操作，各种标识符的_relaxed后缀很明显地展现了这一点。_relaxed后缀提醒您几乎无法保证内存的顺序。特别地，宽松的原子操作和其之前、之后的指令重排是合法的，这可能是由于编译器的重排(compiler reordering)或者处理器上的内存重排(memory reordering on the processor)。就像非原子操作一样，编译器甚至可以对冗余的宽松原子操作进行优化。在所有情况下，该操作仍然是原子的。当并发操作共享内存时，即使您已经知道目标平台上的普通加载/存储是原子的，最好始终使用Mintomic或C++ 11原子库函数。原子库功能提醒您共享内存在其他地方会被并发数据访问。希望您现在可以更清楚地了解，为什么世界上最简单的无锁哈希表使用Mintomic库函数让不同线程同时操作共享内存。","categories":[{"name":"translation","slug":"translation","permalink":"https://system-thoughts.github.io/categories/translation/"},{"name":"lock-free","slug":"translation/lock-free","permalink":"https://system-thoughts.github.io/categories/translation/lock-free/"}],"tags":[{"name":"lock-free","slug":"lock-free","permalink":"https://system-thoughts.github.io/tags/lock-free/"},{"name":"atomic","slug":"atomic","permalink":"https://system-thoughts.github.io/tags/atomic/"}]},{"title":"【译文】 Becoming friends with NetworkManager","slug":"[译文] Becoming friends with NetworkManager","date":"2020-12-30T13:06:21.000Z","updated":"2023-01-18T05:32:06.156Z","comments":true,"path":"posts/b3973f42/","link":"","permalink":"https://system-thoughts.github.io/posts/b3973f42/","excerpt":"","text":"网上很多CentOS7网络配置的教程往往都会建议关闭Networkmanager使用network.service的方式进行网络配置：1. 配置/etc/sysconfig/network-scripts/ifcfg-&lt;net device&gt;.cfg；2. systemctl restart network重启网络生效。 3. 建议关闭NetworkManger，防止和network.service冲突。然而，network-scripts在RHEL8中已经默认不安装了。RHEL8推荐使用NetworkManager的nmcli命令进行网络配置。另外，bridge-utils项目宣布弃用,在RHEL8中无法使用brctl命令创建网桥，需要依赖NetworkManager的nmcli命令创建。RHEL8开始，越来越多的网络管理手段貌似只能通过NetworkManager进行，然而RedHat推行多年的NetworkManger却一直不温不火，究竟为何？RedHat工程师Francesco Giudici写的本篇文章就是向公众推荐NetworkManager，并试图解释NetworkManager背后的原理。 原文链接： https://www.redhat.com/sysadmin/becoming-friends-networkmanager 您对Linux主机自动配置网络感到惊讶吗？很有可能是NetworkManager帮您完成这项任务。NetworkManager是当今Linux发行版中最为广泛使用的网络配置守护程序。然而，您是否禁用了NetworkManager，并且想知道为什么您首选的Linux发行版没有使用旧的IP工具作为默认的网络配置方法？您是否认为NetworkManager仅适用于WiFi？如果您有上述疑问，这篇文章或许适合您。接下来，请抛开偏见，给NetworkManager一个公平的机会。我敢打赌，您在读完这篇文章后，会放下对NetworkManager的成见，甚至会喜欢上它。我会介绍为什么NetworkManager是许多场景（包括命令行和GUI）下的理想选择。随后，我将解释该工具的基本原理（经常被误解）。最后，我将重点介绍每个用户应该掌握关于NetworkManager的一些命令。 为什么是NetworkManager？Linux主机中配置网络的方法有很多，因此您可能会问为什么要专门使用NetworkManager。尽管已经有很多不错的答案，但我想强调一个经常被忽略的要点：NetworkManager允许用户和应用程序同时检索(retrieve)和修改网络的配置，从而确保获得一致且最新的网络视图。可通过桌面GUI（Gnome、KDE、nm-applet）、文本界面（nmtui）、命令行（nmcli）、文件和Web控制台（Cockpit）多种方式配置此工具。NetworkManager还为应用程序提供了API：D-Bus接口、libnm库。任何其他网络配置工具都没有这么灵活。 NetworkManager的原理为了理解和掌握NetworkManager，您首先需要了解其基础配置原理。以下摘自man NetworkManager： “尝试使网络配置和操作尽可能轻松，自动” 这与标准Unix守护程序原理截然不同。传统的Unix守护程序通常要求用户通过配置文件显式地提供配置，然后重启服务。没有配置，守护程序将不执行任何操作。相反，当只有部分配置或没有配置时，NetworkManager会检查可用设备并尽力提供主机的网络连接。NetworkManager的目标是满足所有人的需求：包括寻找“可以正常工作的网络”的普通用户到需要完全控制主机网络的高级网络管理员。NetworkManager希望高级网络管理员提供自己的配置以避免网络自动配置。通过配置Linux守护程序来避免执行某些操作（自动化配置）确实不常见，但这看起来是适应任何场景的合理方法。 基本的NetworkManager概念NetworkManager的配置基于设备(device)和连接(connection)两大概念。设备映射一个网络接口，大致相当于您执行ip link命令看到的接口。每个设备跟踪： 是否由NetworkManager管理 设备的可用连接 设备上的活动连接（如果有） 连接表示要在设备上应用的完整配置，就是一个属性列表。 属于同一设置区域的设置属性被划分为设置组（例如，ipv4设置组属性，包含地址，网关和路由）。在NetworkManager中，配置网络就是简单地激活设备上的连接：设备随后会被配置为连接中的所有属性。尽管前面提及的多个工具都可配置NetworkManager，但现在，我们重点关注NetworkManager自带的命令行工具nmcli。 注意：nmcli程序具有高级的自动补全功能。确保安装了bash-completion软件包以利用此优势。 nmcli基础让我们看下使用nmcli处理网络的各个方面。 设备列出NetworkManager检测到的设备： 12345$ nmcli deviceDEVICE TYPE STATE CONNECTIONenp1s0 ethernet connected ether-enp1s0enp7s0 ethernet disconnected --enp8s0 ethernet disconnected -- 由输出可见，NetworkManager已检测到系统中的三个以太网设备。仅第一个设备enp1s0上有活动连接（表示已配置）。如果您希望NetworkManager一段时间内不再管理一个设备，无需将其关闭，仅需暂时取消管理(unmanage)该设备即可： 123456$ nmcli device set enp8s0 managed no$ nmcli deviceDEVICE TYPE STATE CONNECTIONenp1s0 ethernet connected ether-ens3enp7s0 ethernet disconnected --enp8s0 ethernet unmanaged -- 此更改不是持久化的，重启不生效。查询每个设备IP配置最简单的方法就是不带参数的执行nmcli命令： 12345678910111213141516171819$ nmclienp1s0: connected to enp1s0 &quot;Red Hat Virtio&quot; ethernet (virtio_net), 52:54:00:XX:XX:XX, hw, mtu 1500 ip4 default inet4 192.168.122.225/24 route4 0.0.0.0/0 route4 192.168.122.0/24 inet6 fe80::4923:6a4f:da44:6a1c/64 route6 fe80::/64 route6 ff00::/8enp7s0: disconnected &quot;Intel 82574L&quot; ethernet (e1000e), 52:54:00:XX:XX:XX, hw, mtu 1500enp8s0: unmanaged &quot;Red Hat Virtio&quot; ethernet (virtio_net), 52:54:00:XX:XX:XX, hw, mtu 1500 连接列出可用连接： 12345$ nmcli connectionNAME UUID TYPE DEVICEether-enp1s0 23e0d89e-f56c-3617-adf2-841e39a85ab4 ethernet enp1s0Wired connection 1 fceb885b-b510-387a-b572-d9172729cf18 ethernet --Wired connection 2 074fd16d-daa6-3b6a-b092-2baf0a8b91b9 ethernet -- 从输出可见，唯一的活动连接是应用于设备enp1s0的ether-enp1s0。也存在其他两个连接，但是它们不处于活动状态。要停用连接，即取消配置关联的设备，只需指示NetworkManager断开连接即可。 例如，要停用ether-enp1s0连接： 1$ nmcli connection down ether-enp1s0 要重新激活它，即重新配置设备： 1$ nmcli connection up ether-enp1s0 要查看特定连接的详细信息，我们应该检查连接的属性： 12345678910111213$ nmcli connection show ether-enp1s0connection.id: ether-enp1s0connection.uuid: 23e0d89e-f56c-3617-adf2-841e39a85ab4connection.stable-id: --connection.type: 802-3-ethernetconnection.interface-name: enp1s0connection.autoconnect: yesconnection.autoconnect-priority: -999connection.autoconnect-retries: -1 (default)connection.auth-retries: -1connection.timestamp: 1559320203connection.read-only: no[...] 连接属性的列表很长，并且按设置分组。 实际上，每个属性都被指定为setting_name.property_name。我们重点介绍一些属于连接和IPv4设置的基本属性： 属性 描述 别名 connection.id 连接名称(nmcli connection中输出) con-name connection.uuid 全局唯一标识符UUID，唯一标识连接 (none) connection.type 连接类型 type connection.interface-name 将连接绑定到特定设备，只能在该设备上激活该连接 ifname connection.autoconnect 连接是否应该被自动激活 autoconnect ipv4.method 连接的IPv4方法：自动(auto)，禁用(disabled)，链接本地(link local)，手动(manual)或共享(shared) (none) ipv4.addresses 连接的静态IPv4地址 (none) 请注意，少数常用属性具有别名，即可以用来代替完整设置的短名称。上表第三列显示别名。所有nmcli命令都可以被截断，且能执行相同的操作。 例如，要关闭ether-enp1s0连接的自动连接，我们可以将上面的modify命令缩短为：$nmcli c m ether-ens1s0 autoconnect no autoconnect属性控制连接的自动激活。如果启用了它（= yes，默认值），interface-name设备处于就绪状态且其上无活动连接时，NetworkManager会自动激活该连接。如果将ipv4.method设置为auto，则可以通过DHCP配置IPv4。如果您更喜欢配置静态IP，则将ipv4.method设置为manual，然后在ipv4.addresses属性中设定静态IP地址和子网（以CIDR表示法）。有关所有属性及其含义的完整说明，请参见nm-settings手册页（man nm-settings）。使用nmcli connection Modify命令更改连接的属性。例如，将ether-enp1s0连接更改为静态IPv4地址（10.10.10.1），网关（10.10.10.254）和DNS（10.10.10.254）： 12$ nmcli connection modify ether-enp1s0 ipv4.method manual ipv4.addresses 10.10.10.1/24 \\ipv4.gateway 10.10.10.254 ipv4.dns 10.10.10.254 此命令将永久更改连接，但是新设置不会立即应用到设备：下次在该设备上激活连接时才会应用新设置。因此，要立即设置并运行我们的设置，请重新激活连接： 1$ nmcli connection up ether-enp1s0 您可能还想阻止NetworkManager自动激活ether-enp1s0连接： 1$ nmcli connection modify ether-ens1s0 connection.autoconnect no 从此开始，您必须自行激活ether-enp1s0连接。 使用nmcli创建新连接现在，是时候使用nmcli在NetworkManager中创建新连接了！nmcli connection子命令add的语法类似于modify子命令： 1234567$ nmcli con add type ethernet ifname enp0s1 con-name enp0s1_dhcp autoconnect no$ nmcli conNAME UUID TYPE DEVICEether-enp1s0 23e0d89e-f56c-3617-adf2-841e39a85ab4 ethernet enp1s0enp0s1_dhcp 64b499cb-429f-4e75-a54d-b3fd980c39aa ethernet --Wired connection 1 fceb885b-b510-387a-b572-d9172729cf18 ethernet --Wired connection 2 074fd16d-daa6-3b6a-b092-2baf0a8b91b9 ethernet -- 由于ipv4.method属性的默认值为auto，未指定任何IPv4属性的情况下，IPv4配置将通过DHCP检索获取。创建连接时，强制属性取决于connection.type（ethernet，wifi，bond，vpn等）。如果缺少任何强制属性，nmcli将返回错误，并打印缺少属性的名称。如果您希望获得更具交互性的体验，请在您的nmcli命令中添加--ask标志。这样，nmcli会提示您完成命令所需的内容，而不是直接失败： 123456789101112$ nmcli --ask con addConnection type: ethernetInterface name [*]: enp0s1There are 3 optional settings for Wired Ethernet.Do you want to provide them? (yes/no) [yes] noThere are 2 optional settings for IPv4 protocol.Do you want to provide them? (yes/no) [yes] noThere are 2 optional settings for IPv6 protocol.Do you want to provide them? (yes/no) [yes] noThere are 4 optional settings for Proxy.Do you want to provide them? (yes/no) [yes] noConnection &#x27;ethernet-enp0s1&#x27; (64b499cb-429f-4e75-a54d-b3fd980c39aa) successfully added. 可通过nmcli con edit访问编辑器模式。此模式提供了内联帮助和更加交互的体验。不带任何参数调用此模式会导致nmcli编辑器提示您输入要创建的连接类型。若传入连接名称，编辑器将打开该连接以对其进行修改。 nmcli备忘单总结下前面提及的nmcli connection子命令： 命令 参数 描述 down connection 断开指定的连接，取消配置关联的设备 up connection 激活指定的连接 show [connection] 当不带参数使用时，可以像默认命令一样省略show：它列出了所有可用的连接。 如果提供连接名称或UUID作为参数，则将打印连接属性 modify connection {property_name property_value}… 改变连接的属性 add connection {property_name property_value}… 创建具有指定属性的新连接。强制属性取决于连接类型，应始终指定该类型 接下来？现在，我们介绍了NetworkManager的基本原理及其基本概念（设备和连接）。我们还看到NetworkManager可以通过多种工具以多种方式管理并发请求。我们了解了如何使用NetworkManager命令行工具nmcli显示实际配置,在设备上添加，修改和激活/停用连接。这些知识为您提供了了解和掌握NetworkManager的基础。NetworkManager可以做地更多。许多功能都应提供单独的博客文章，例如调度程序脚本，连接检查器，拆分的DNS，MAC地址随机化，热点配置和自动配置。因此，请继续关注这里的下一篇博客文章。或者，如果您迫不及待，请开始在NetworkManager手册页中查找！","categories":[{"name":"translation","slug":"translation","permalink":"https://system-thoughts.github.io/categories/translation/"},{"name":"tools","slug":"translation/tools","permalink":"https://system-thoughts.github.io/categories/translation/tools/"}],"tags":[{"name":"RedHat","slug":"redhat","permalink":"https://system-thoughts.github.io/tags/redhat/"},{"name":"NetworkManager","slug":"networkmanager","permalink":"https://system-thoughts.github.io/tags/networkmanager/"},{"name":"Network","slug":"network","permalink":"https://system-thoughts.github.io/tags/network/"}]},{"title":"Travis-CI持续集成Hexo博客","slug":"Travis-CI持续集成Hexo博客","date":"2020-12-15T04:15:39.000Z","updated":"2023-01-18T05:32:06.152Z","comments":true,"path":"posts/6bc45836/","link":"","permalink":"https://system-thoughts.github.io/posts/6bc45836/","excerpt":"Hexo is a fast, simple &amp; powerful blog framework, powered by Node.js.","text":"Hexo is a fast, simple &amp; powerful blog framework, powered by Node.js. hexo不仅可以作为博客框架生成博客，更能够广泛地快捷生成任意静态页面。 hexo quick start 准备工作：安装nodejs 1$ yum install -y nodejs 安装hexo 1$ npm install hexo-cli -g 创建博客空目录，使用hexo初始化设置 1$ mkdir -p blog &amp;&amp; cd blog &amp;&amp; hexo init . 博客目录必须为空，不能包含任何文件，否则hexo init会初始化失败 启动服务器，查看博客是否初始化成功 1$ hexo server 若要创建新的博文 1$ hexo new [layout] &lt;title&gt; post模板是默认的布局，通过修改_config.yml中的default_layout项修改文章的默认布局。如果不想使用任何布局，可以在文章的Front-matter中disable layout。 使用不同模板创建的文章保存在source目录下不同的路径： layout path post source/_posts page source draft source/_drafts 默认情况下，会使用文章名字作为文件名称。也可以修改_config.yml中new_post_name项定义文件命名格式。 hexo默认安装了hexo-renderer-marked和hexo-renderer-ejs，因此hexo支持渲染markdown以及ejs格式的文本，若安装了hexo-renderer-pug，也支持使用pug模板进行文章书写除了markdown语法格式之外，若想在文章中添加引用块、代码块、youtube视频，为了让这些内容也能够很好地渲染，hexo提供了标签插件tag plugins，无论使用markdown还是其他格式进行文章书写，标签插件的格式都是不变的。在写文章的时候，往往会在文章中插入其他附件，如图片，为了让页面渲染更出色，有时候甚至会在文章中添加css、js文件。hexo中的资源（Assets）代表的就是source目录下非文章（non-post）文件。为了区分每篇文章的资源，使得文章资源更为合理地管理。需要将_config.yml中的post_asset_folder设置为true，如此，通过hexo new命令生成的每篇新文章就会创建同名的资源文件夹，将文章相关的资源都放到这个同名文件夹中。在文章中通过相对路劲即可高效地引用这些资源。 使用markdown编辑好博文之后，生成静态页面1$ hexo generate hexo目录初始化完成之后，hexo目录结构如下： 12345678910111213[root@localhost blog]# ls -alhtotal 108Kdrwxr-xr-x. 6 root root 168 Nov 20 22:46 .dr-xr-x---. 30 root root 4.0K Nov 20 22:44 ..-rw-r--r--. 1 root root 2.4K Nov 19 20:34 _config.yml-rw-r--r--. 1 root root 21K Nov 20 03:37 db.json-rw-r--r--. 1 root root 65 Nov 19 20:34 .gitignoredrwxr-xr-x. 164 root root 8.0K Nov 19 20:36 node_modules-rw-r--r--. 1 root root 581 Nov 19 20:36 package.json-rw-r--r--. 1 root root 55K Nov 19 20:36 package-lock.jsondrwxr-xr-x. 2 root root 52 Nov 19 20:34 scaffoldsdrwxr-xr-x. 3 root root 20 Nov 19 20:34 sourcedrwxr-xr-x. 3 root root 23 Nov 19 20:34 themes 各目录解释如下： 目录/文件 用途 node_modules(D) npm安装的各种依赖包 scaffolds(D) 模板文件夹，初始包括page、post、draft三种模板，模板定义了写作内容的布局 source(D) 生成静态页面的源文件，包括markdown文档、图片等 themes(D) 主题文件夹，themes目录下，每个主题都是一个文件夹，默认主题为landscape _config.yml(T) 博客配置文件 package.json(T) 应用程序信息，罗列了Hexo版本及其依赖程序的版本 package-lock.json(T) hexo init执行过程的npm install所生成，用以记录当前状态下实际安装的各个npm package的具体来源和版本号。https://docs.npmjs.com/cli/v6/configuring-npm/package-lock-json hexo blog部署hexo提供了便捷的一键部署命令： 1$ hexo deploy hexo将网站部署的目的地有多种，主要分为服务器和远端仓库。远端仓库如github page，该仓库包含静态站点的HTML、CSS和js文件，并自动地对外发布网站。 GitHub Pages 是一项静态站点托管服务，它直接从 GitHub 上的仓库获取 HTML、CSS 和 JavaScript 文件，（可选）通过构建过程运行文件，然后发布网站。 Coding.net、gitee、gitlab都有同样的服务，部署方式参考github page即可。另外一种方式，就是将静态站点部署到自己的服务器上，可以通过ftp、sftp等方式一键将静态站点发布到自己的服务器上，这样需要安装hexo-deployer-ftpsync、hexo-deployer-sftp插件，每种插件都有相关的部署配置。其他小众的部署方式参考：One-Command Deployment 本文以将静态站点部署到github page为例。 在github上创建带有自己用户名的代码仓：&lt;username&gt;.github.io 安装hexo-deployer-git插件1$ npm install hexo-deployer-git --save 配置_config.yml12345deploy: type: git repo: &lt;repository url&gt; # https://github.com/system-thoughts/system-thoughts.github.io.git branch: [branch] message: [message] deploy的各项解释如下： 选项 描述 默认值 repo 代码仓地址 branch 部署的分支名称 master (GitHub)coding-pages (Coding.net) master (others) message 自定义部署提交的信息 Site updated: 当前时间，格式：’YYYY-MM-DD HH:mm:ss’ token 验证代码仓的token 关于hexo-deploy-git相关的配置选项更多的介绍可参考：hexo-deployer-git。此处，配置type和repo即可，其他项使用默认值。4. 部署网站 1$ hexo clean &amp;&amp; hexo deploy hexo clean用来清除缓存文件(db.json) 和已生成的静态文件 (public)。在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。一般情况下，不需要运行此命令。hexo deploy命令就是部署静态站点，当然之前要使用hexo generate生成静态页面。可以将这两条命令简化为： 12345$ hexo d -g // 在部署之前生成一把or$ hexo g -d // 生成之后立马部署or$ hexo generate &amp;&amp; hexo deploy 此时会提示你输入github的用户名和密码，除非你使用token或者ssh-key的方式认证。此处简单配置下，git用户名和密码： 12$ git config --global user.name &quot;lvying&quot;$ git config --global user.email &quot;lvying.system.thoughts@gmail.com&quot; 生成sshkey就不介绍，此处做下测试，当前系统中的sshkey是否是自己的github账户： 123[root@localhost blog]# ssh -T git@github.comWarning: Permanently added the RSA host key for IP address &#x27;192.30.255.112&#x27; to the list of known hosts.Hi **system-thoughts**! You&#x27;ve successfully authenticated, but GitHub does not provide shell access. 之前的sshkey因为不是我自己的github账户，因此我又重新生成了一个。在_config.yml中我是用https的仓库地址，提交会遇到错误： 1234567remote: Permission to system-thoughts/system-thoughts.github.io.git denied to **buweilv**.fatal: unable to access &#x27;https://github.com/system-thoughts/system-thoughts.github.io.git/&#x27;: The requested URL returned error: 403FATAL &#123; err: &#123; Error: Spawn failed at ChildProcess.task.on.code (/root/blog/node_modules/hexo-deployer-git/node_modules/hexo-util/lib/spawn.js:51:21) at ChildProcess.emit (events.js:198:13) at Process.ChildProcess._handle.onexit (internal/child_process.js:248:12) code: 128 &#125; &#125; &#x27;Something\\&#x27;s wrong. Maybe you can find the solution here: %s&#x27; &#x27;\\u001b[4mhttps://hexo.io/docs/troubleshooting.html\\u001b[24m&#x27; 这个是我另外一个github账户，不知道为何会默认识别使用这个账户，我猜想这个可能是因为缓存的缘故吧。将repo配置为ssh的仓库地址，便可以正确部署站点。 Travis CI部署hexo blog当前每次部署hexo blog，都需要手动输入hexo g -d生成静态页面，并部署到github page上。这需要在当前环境安装hexo及npm，部署到github page上之后，&lt;username&gt;.github.io代码仓托管的是静态页面，如果要在不同设备上进行写作，需要拷贝最新源文件。为了能够在本地专注blog写作，不用担心环境配置、源文件托管等杂项，使用Travis CI部署hexo blog。 源文件git管理hexo generate和hexo deploy会新增文件和目录，这些目录的解释如下： 目录/文件 用途 public(D) 由hexo generate生成的静态页面，hexo clean清除。Hexo 引入了差分机制，如果 public 目录存在，那么 hexo g 只会重新生成改动的文件。若要强制重新生成，使用hexo g -f .deploy_git(D) hexo-deployer-git通过在.deploy_git中生成站点并强制将其推送到_config.yml中配置的仓库来工作。 如果.deploy_git不存在，则将初始化存储库（git init）。 否则，将使用当前的仓库（及其提交历史）。 如此看来,public目录中保存的是hexo g本地生成的静态站点页面。.deploy_git实际上就是代码仓，跟踪的就是&lt;username&gt;.github.io代码仓。当执行hexo d时，会将public目录中的内容形成一次新的提交记录，提交到&lt;username&gt;.github.io代码仓中。对比下.deploy_git与&lt;username&gt;.github.io下的历史记录，两者完全匹配： .deploy_git是&lt;uername&gt;.github.io的本地仓库，其master分支追踪&lt;uername&gt;.github.io的本地分支。在blog根目录中，在hexo init初始化时便存在.gitignore文件： .gitignore1234567.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/ 可见hexo有意要将blog也作为git repo，在此处已经为我们列好了忽略项，忽略相关环境配置文件。这样，hexo也有意保存两份git repo: 在使用hexo d -g部署的时候，将.deploy_git中的静态文件推送到.github.io的master分支 将根目录下的源文件提交到.github.io另一分支，提交会忽略静态文件和环境配置文件。我们将源文件提交到代码仓的src分支中。 在博客根目录下，创建git repo： 1234$ git init .$ git add . -A &amp;&amp; git commit -m &quot;init blog&quot;$ git remote add origin git@github.com:system-thoughts/system-thoughts.github.io.git$ git push origin master:src 当前，博文源文件已经可以同步，为了进一步方便博客自动化生成、部署，可以使用travis CI进行持续集成。 Travis CI持续集成hexo blog本地部署和travis CI部署博客的工作流程区分如图所示：Travis CI会自动部署hexo依赖的环境，一旦更新源文件，便会触发Travis CI构建、部署blog。具体步骤如下： 打开官方网站https://travis-ci.com/，使用github账号进行登录，然后 Travis CI会列出你 Github上面所有的仓库，以及你所属于的组织。点击安装Travis CI github APP，随后选择Travis CI有权限访问账号下的所有代码仓。 若要Travis CI能够构建项目，需要在代码仓根目录中添加.travis.yml配置文件。当代码仓中有新的提交时，Travis CI会根据yaml文件的配置进行构建、发布。12345678910111213141516171819language: node_jsnode_js:- &#x27;12&#x27;install:- npm installscript:- npm run clean- npm run builddeploy: provider: pages skip_cleanup: true github_token: &quot;$GITHUB_TOKEN&quot; local_dir: public on: branch: master target_branch: gh-pagesenv: global: secure: KbvbdGLy5/C3mB5dr+yCF5llN9cAS9Sy498mnz9iMf3ONgQ+oOKYVHQLdqX6eYcQv4KUCrdUQHmUCmADr5vFNEblioRqzjZ4Ftcrg+tR2JaaApxYvPN5nm8TngZIHfEw0KbF83jFFUACMIsPM+sxmFxVX06K7D25l9N27K844uWKlxIqH3g/JygXphuBPSgqSjQ0j+m7AZOADpN16SCHfOqm6b6QPjnbqkEIeqyg7FChbmlGEFuYb4C7kL1E80m0hD8j8NOxohnmHWHTDcoP8xYehPHRNQ2VvrwZSAKVUDFTmmaP2vDYetO6p9MnQafRdgVBwtx+IO0nU7eQMB4eislRWajwXidon+yd0sDiLQyQXhjcg7qqckdatJc+LrOufx/gdSnmOg0fNZB0cVM8F7Sn1rafj9Vv5js9L3/OFjnH0Sc3Aa31bvli+BthXBHH0mhnoFhFupMRDk301af904Nyx/UejzDs3zN+aFV7XedkGEnsFA8TImz7Y2NOamxUSp15cOAiKcuK8fYnEBJh93m98dVCvk9haiuD8FiwIbqNJ+yDYiGxOeriLRxVRrmYKbn3GHKW+RT7t18dljR6ffYf/38jlRbtUnruMChbQ3/gZRsuq30J4hOEDYKS82JU0q6VZKsokDWo1RjU4NlrLDiTzzUUvkNLxGbckQM8MCQ= Travis CI将构建生成的静态页面部署到github page，需要推送代码到&lt;username&gt;.github.io代码仓的权限。Github提供了Personal Access Token赋予Travis CI权限。前往 Github 帐号 Settings 页面，在左侧选择Developer settings → Personal Access Token，然后在右侧面板点击 “Generate new token” 来新建一个 Token。需要注意的是，创建完的 Token 只有第一次可见，之后再访问就无法看见（只能看见他的名称），因此要保存好这个值。之前生成 Personal Access Token时，只选择了以下权限：加密密钥：1234$ yum -y install ruby ruby-devel rubygems rpm-build$ gem install travis$ travis login --pro --github-token &#x27;&lt;Personal Access Token&gt;&#x27;$ travis encrypt --pro &#x27;GITHUB_TOKEN=&lt;Personal Access Token&gt;&#x27; --add 这里要登录https://api.travis-ci.com 而非使用travis login --github-token &#39;&lt;Personal Access Token&gt;&#39;登录https://api.travis-ci.org/。因为我们的工程在https://api.travis-ci.com 上构建。后续使用travis encrypt加密的GITHUB_TOKEN环境变量应该在travis-ci.com中。travis encrpt中自行贴入Personal Access Token的明文。之后.travis.yml的内容会自动更新。密钥添加成功之后，每次触发travis-ci构建都能观察到该环境变量： 对源文件进行修改之后，提交即可触发Travis CI构建，若要忽略某次提交，即这次提交不要触发Travis CI构建发布hexo blog，travis若要忽略一次提交，即这次提交不会触发Travis-CI构建，可以在commit msg中加入[ci skip]或者[skip-ci]关键字：1git commit -m &#x27;documentation update [ci skip]&#x27; Reference[1] https://neveryu.github.io/2019/02/05/travis-ci/[2] https://medium.com/starbugs/travis-ci-簡單事情就交給電腦去做之ci-cd-初體驗-讓-github-pages-自動更新-7647be30eb1c[3] https://segmentfault.com/a/1190000019067492[4] http://magicse7en.github.io/2016/03/27/travis-ci-auto-deploy-hexo-github/[5] https://anran758.github.io/blog/2020/06/08/github-travis-build/[6] https://hexo.io/docs/setup.html","categories":[{"name":"blog","slug":"blog","permalink":"https://system-thoughts.github.io/categories/blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://system-thoughts.github.io/tags/hexo/"}]}],"categories":[{"name":"RAS","slug":"ras","permalink":"https://system-thoughts.github.io/categories/ras/"},{"name":"blog","slug":"blog","permalink":"https://system-thoughts.github.io/categories/blog/"},{"name":"compilation","slug":"compilation","permalink":"https://system-thoughts.github.io/categories/compilation/"},{"name":"boot","slug":"boot","permalink":"https://system-thoughts.github.io/categories/boot/"},{"name":"Base Service","slug":"base-service","permalink":"https://system-thoughts.github.io/categories/base-service/"},{"name":"shell","slug":"shell","permalink":"https://system-thoughts.github.io/categories/shell/"},{"name":"tools","slug":"tools","permalink":"https://system-thoughts.github.io/categories/tools/"},{"name":"translation","slug":"translation","permalink":"https://system-thoughts.github.io/categories/translation/"},{"name":"lock-free","slug":"translation/lock-free","permalink":"https://system-thoughts.github.io/categories/translation/lock-free/"},{"name":"tools","slug":"translation/tools","permalink":"https://system-thoughts.github.io/categories/translation/tools/"}],"tags":[{"name":"APEI","slug":"apei","permalink":"https://system-thoughts.github.io/tags/apei/"},{"name":"domain","slug":"domain","permalink":"https://system-thoughts.github.io/tags/domain/"},{"name":"github page","slug":"github-page","permalink":"https://system-thoughts.github.io/tags/github-page/"},{"name":"ELF","slug":"elf","permalink":"https://system-thoughts.github.io/tags/elf/"},{"name":"compilation","slug":"compilation","permalink":"https://system-thoughts.github.io/tags/compilation/"},{"name":"link","slug":"link","permalink":"https://system-thoughts.github.io/tags/link/"},{"name":"boot","slug":"boot","permalink":"https://system-thoughts.github.io/tags/boot/"},{"name":"initramfs","slug":"initramfs","permalink":"https://system-thoughts.github.io/tags/initramfs/"},{"name":"gzip","slug":"gzip","permalink":"https://system-thoughts.github.io/tags/gzip/"},{"name":"deflate","slug":"deflate","permalink":"https://system-thoughts.github.io/tags/deflate/"},{"name":"BIOS","slug":"bios","permalink":"https://system-thoughts.github.io/tags/bios/"},{"name":"shell","slug":"shell","permalink":"https://system-thoughts.github.io/tags/shell/"},{"name":"codebase","slug":"codebase","permalink":"https://system-thoughts.github.io/tags/codebase/"},{"name":"mutt","slug":"mutt","permalink":"https://system-thoughts.github.io/tags/mutt/"},{"name":"社区","slug":"社区","permalink":"https://system-thoughts.github.io/tags/%E7%A4%BE%E5%8C%BA/"},{"name":"lock-free","slug":"lock-free","permalink":"https://system-thoughts.github.io/tags/lock-free/"},{"name":"memory-reordering","slug":"memory-reordering","permalink":"https://system-thoughts.github.io/tags/memory-reordering/"},{"name":"atomic","slug":"atomic","permalink":"https://system-thoughts.github.io/tags/atomic/"},{"name":"RedHat","slug":"redhat","permalink":"https://system-thoughts.github.io/tags/redhat/"},{"name":"NetworkManager","slug":"networkmanager","permalink":"https://system-thoughts.github.io/tags/networkmanager/"},{"name":"Network","slug":"network","permalink":"https://system-thoughts.github.io/tags/network/"},{"name":"hexo","slug":"hexo","permalink":"https://system-thoughts.github.io/tags/hexo/"}]}